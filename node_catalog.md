## Airtable_Agents 

{
  "className": "Airtable_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'Airtable Agent'\n        this.name = 'airtableAgent'\n        this.version = 2.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'airtable.svg'\n        this.description = 'Agent used to to answer queries on Airtable table'\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['airtableApi']\n        }",
  "if": "if (data.records.length === 0) {\n        return []\n    }",
  "catch": "catch (error) {\n        throw new Error(`Failed to fetch ${url}",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const baseId = nodeData.inputs?.baseId as string\n        const tableId = nodeData.inputs?.tableId as string\n        const returnAll = nodeData.inputs?.returnAll as boolean\n        const limit = nodeData.inputs?.limit as string\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Vectara chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const accessToken = getCredentialParam('accessToken', credentialData, nodeData)\n\n        let airtableData: ICommonObject[] = []\n\n        if (returnAll) {\n            airtableData = await loadAll(baseId, tableId, accessToken)\n        } else {\n            airtableData = await loadLimit(limit ? parseInt(limit, 10) : 100, baseId, tableId, accessToken)\n        }\n\n        let base64String = Buffer.from(JSON.stringify(airtableData)).toString('base64')\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        const pyodide = await LoadPyodide()\n\n        // First load the csv file and get the dataframe dictionary of column types\n        // For example using titanic.csv: {'PassengerId': 'int64', 'Survived': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Ticket': 'object', 'Fare': 'float64', 'Cabin': 'object', 'Embarked': 'object'}\n        let dataframeColDict = ''\n        try {\n            const code = `import pandas as pd\nimport base64\nimport json\n\nbase64_string = \"${base64String}\"\n\ndecoded_data = base64.b64decode(base64_string)\n\njson_data = json.loads(decoded_data)\n\ndf = pd.DataFrame(json_data)\nmy_dict = df.dtypes.astype(str).to_dict()\nprint(my_dict)\njson.dumps(my_dict)`\n            dataframeColDict = await pyodide.runPythonAsync(code)\n        } catch (error) {\n            throw new Error(error)\n        }\n\n        // Then tell GPT to come out with ONLY python code\n        // For example: len(df), df[df['SibSp'] > 3]['PassengerId'].count()\n        let pythonCode = ''\n        if (dataframeColDict) {\n            const chain = new LLMChain({\n                llm: model,\n                prompt: PromptTemplate.fromTemplate(systemPrompt),\n                verbose: process.env.DEBUG === 'true' ? true : false\n            })\n            const inputs = {\n                dict: dataframeColDict,\n                question: input\n            }\n            const res = await chain.call(inputs, [loggerHandler, ...callbacks])\n            pythonCode = res?.text\n            // Regex to get rid of markdown code blocks syntax\n            pythonCode = pythonCode.replace(/^```[a-z]+\\n|\\n```$/gm, '')\n        }\n\n        // Then run the code using Pyodide\n        let finalResult = ''\n        if (pythonCode) {\n            try {\n                const code = `import pandas as pd\\n${pythonCode}`\n                // TODO: get print console output\n                finalResult = await pyodide.runPythonAsync(code)\n            } catch (error) {\n                throw new Error(`Sorry, I'm unable to find answer for question: \"${input}\" using follwoing code: \"${pythonCode}\"`)\n            }\n        }\n\n        // Finally, return a complete answer\n        if (finalResult) {\n            const chain = new LLMChain({\n                llm: model,\n                prompt: PromptTemplate.fromTemplate(finalSystemPrompt),\n                verbose: process.env.DEBUG === 'true' ? true : false\n            })\n            const inputs = {\n                question: input,\n                answer: finalResult\n            }\n\n            if (options.socketIO && options.socketIOClientId) {\n                const result = await chain.call(inputs, [loggerHandler, handler, ...callbacks])\n                return result?.text\n            } else {\n                const result = await chain.call(inputs, [loggerHandler, ...callbacks])\n                return result?.text\n            }\n        }\n\n        return pythonCode\n    }\n}\n\ninterface AirtableLoaderResponse {\n    records: AirtableLoaderPage[]\n    offset?: string\n}\n\ninterface AirtableLoaderPage {\n    id: string\n    createdTime: string\n    fields: ICommonObject\n}\n\nconst fetchAirtableData = async (url: string, params: ICommonObject, accessToken: string): Promise<AirtableLoaderResponse> => {\n    try {\n        const headers = {\n            Authorization: `Bearer ${accessToken}`,\n            'Content-Type': 'application/json',\n            Accept: 'application/json'\n        }\n        const response = await axios.get(url, { params, headers })\n        return response.data\n    } catch (error) {\n        throw new Error(`Failed to fetch ${url} from Airtable: ${error}`)\n    }\n}\n\nconst loadAll = async (baseId: string, tableId: string, accessToken: string): Promise<ICommonObject[]> => {\n    const params: ICommonObject = { pageSize: 100 }\n    let data: AirtableLoaderResponse\n    let returnPages: AirtableLoaderPage[] = []\n\n    do {\n        data = await fetchAirtableData(`https://api.airtable.com/v0/${baseId}/${tableId}`, params, accessToken)\n        returnPages.push.apply(returnPages, data.records)\n        params.offset = data.offset\n    } while (data.offset !== undefined)\n\n    return data.records.map((page) => page.fields)\n}\n\nconst loadLimit = async (limit: number, baseId: string, tableId: string, accessToken: string): Promise<ICommonObject[]> => {\n    const params = { maxRecords: limit }\n    const data = await fetchAirtableData(`https://api.airtable.com/v0/${baseId}/${tableId}`, params, accessToken)\n    if (data.records.length === 0) {\n        return []\n    }\n    return data.records.map((page) => page.fields)\n}"
}

## AutoGPT_Agents

{
  "className": "AutoGPT_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'AutoGPT'\n        this.name = 'autoGPT'\n        this.version = 2.0\n        this.type = 'AutoGPT'\n        this.category = 'Agents'\n        this.icon = 'autogpt.svg'\n        this.description = 'Autonomous agent with chain of thoughts for self-guided task completion'\n        this.baseClasses = ['AutoGPT']\n        this.inputs = [\n            {\n                label: 'Allowed Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (executor.tools.length && writeTool) {\n                writeFilePath = (writeTool as any).store.basePath\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "while": "while (loopCount < executor.maxIterations) {\n                    loopCount += 1\n\n                    const { text: assistantReply }",
  "outsideClass_FINISH_NAME": "const FINISH_NAME = 'finish'",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseChatModel\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as VectorStoreRetriever\n        let tools = nodeData.inputs?.tools as Tool[]\n        tools = flatten(tools)\n        const aiName = (nodeData.inputs?.aiName as string) || 'AutoGPT'\n        const aiRole = (nodeData.inputs?.aiRole as string) || 'Assistant'\n        const maxLoop = nodeData.inputs?.maxLoop as string\n\n        const autogpt = AutoGPT.fromLLMAndTools(model, tools, {\n            memory: vectorStoreRetriever,\n            aiName,\n            aiRole\n        })\n\n        autogpt.maxIterations = parseInt(maxLoop, 10)\n\n        return autogpt\n    }\n\n    async run(nodeData: INodeData, input: string): Promise<string | object> {\n        const executor = nodeData.instance as AutoGPT\n        const model = nodeData.inputs?.model as BaseChatModel\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the AutoGPT agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        try {\n            let totalAssistantReply = ''\n            executor.run = async (goals: string[]): Promise<string | undefined> => {\n                const user_input = 'Determine which next command to use, and respond using the format specified above:'\n                let loopCount = 0\n                while (loopCount < executor.maxIterations) {\n                    loopCount += 1\n\n                    const { text: assistantReply } = await executor.chain.call({\n                        goals,\n                        user_input,\n                        memory: executor.memory,\n                        messages: executor.fullMessageHistory\n                    })\n\n                    // eslint-disable-next-line no-console\n                    console.log('\\x1b[92m\\x1b[1m\\n*****AutoGPT*****\\n\\x1b[0m\\x1b[0m')\n                    // eslint-disable-next-line no-console\n                    console.log(assistantReply)\n                    totalAssistantReply += assistantReply + '\\n'\n                    executor.fullMessageHistory.push(new HumanMessage(user_input))\n                    executor.fullMessageHistory.push(new AIMessage(assistantReply))\n\n                    const action = await executor.outputParser.parse(assistantReply)\n                    const tools = executor.tools.reduce((acc, tool) => ({ ...acc, [tool.name]: tool }), {} as { [key: string]: ObjectTool })\n                    if (action.name === FINISH_NAME) {\n                        return action.args.response\n                    }\n                    let result: string\n                    if (action.name in tools) {\n                        const tool = tools[action.name]\n                        let observation\n                        try {\n                            observation = await tool.call(action.args)\n                        } catch (e) {\n                            observation = `Error in args: ${e}`\n                        }\n                        result = `Command ${tool.name} returned: ${observation}`\n                    } else if (action.name === 'ERROR') {\n                        result = `Error: ${action.args}. `\n                    } else {\n                        result = `Unknown command '${action.name}'. Please refer to the 'COMMANDS' list for available commands and only respond in the specified JSON format.`\n                    }\n\n                    let memoryToAdd = `Assistant Reply: ${assistantReply}\\nResult: ${result} `\n                    if (executor.feedbackTool) {\n                        const feedback = `\\n${await executor.feedbackTool.call('Input: ')}`\n                        if (feedback === 'q' || feedback === 'stop') {\n                            return 'EXITING'\n                        }\n                        memoryToAdd += feedback\n                    }\n\n                    const documents = await executor.textSplitter.createDocuments([memoryToAdd])\n                    await executor.memory.addDocuments(documents)\n                    executor.fullMessageHistory.push(new SystemMessage(result))\n                }\n\n                return undefined\n            }\n\n            const res = await executor.run([input])\n\n            if (!res) {\n                const sentence = `Unfortunately I was not able to complete all the task. Here is the chain of thoughts:`\n                return `${await rephraseString(sentence, model)}\\n\\`\\`\\`javascript\\n${totalAssistantReply}\\n\\`\\`\\`\\n`\n            }\n\n            const sentence = `I have completed all my tasks. Here is the chain of thoughts:`\n            let writeFilePath = ''\n            const writeTool = executor.tools.find((tool) => tool.name === 'write_file')\n            if (executor.tools.length && writeTool) {\n                writeFilePath = (writeTool as any).store.basePath\n            }\n            return `${await rephraseString(\n                sentence,\n                model\n            )}\\n\\`\\`\\`javascript\\n${totalAssistantReply}\\n\\`\\`\\`\\nAnd the final result:\\n\\`\\`\\`javascript\\n${res}\\n\\`\\`\\`\\n${\n                writeFilePath\n                    ? await rephraseString(\n                          `You can download the final result displayed above, or see if a new file has been successfully written to \\`${writeFilePath}\\``,\n                          model\n                      )\n                    : ''\n            }`\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}\n\nconst rephraseString = async (sentence: string, model: BaseChatModel) => {\n    const promptTemplate = new PromptTemplate({\n        template: 'You are a helpful Assistant that rephrase a sentence: {sentence}',\n        inputVariables: ['sentence']\n    })\n    const chain = new LLMChain({ llm: model, prompt: promptTemplate })\n    const res = await chain.call({ sentence })\n    return res?.text\n}"
}

## BabyAGI_Agents

{
  "className": "BabyAGI_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'BabyAGI'\n        this.name = 'babyAGI'\n        this.version = 2.0\n        this.type = 'BabyAGI'\n        this.category = 'Agents'\n        this.icon = 'babyagi.svg'\n        this.description = 'Task Driven Autonomous Agent which creates new task and reprioritizes task list based on objective'\n        this.baseClasses = ['BabyAGI']\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel'\n            }",
  "if": "if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the BabyAGI agent\n                input = await checkInputs(moderations, input)\n            }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseChatModel\n        const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n        const taskLoop = nodeData.inputs?.taskLoop as string\n        const k = (vectorStore as any)?.k ?? 4\n\n        const babyAgi = BabyAGI.fromLLM(model, vectorStore, parseInt(taskLoop, 10), k)\n        return babyAgi\n    }\n\n    async run(nodeData: INodeData, input: string): Promise<string | object> {\n        const executor = nodeData.instance as BabyAGI\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the BabyAGI agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const objective = input\n\n        const res = await executor.call({ objective })\n        return res\n    }\n}"
}

## CSV_Agents

{
  "className": "CSV_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'CSV Agent'\n        this.name = 'csvAgent'\n        this.version = 3.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'CSVagent.svg'\n        this.description = 'Agent used to to answer queries on CSV data'\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Csv File',\n                name: 'csvFile',\n                type: 'file',\n                fileType: '.csv'\n            }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n                const result = await chain.call(inputs, [loggerHandler, handler, ...callbacks])\n                return result?.text\n            }",
  "catch": "catch (error) {\n                throw new Error(`Sorry, I'm unable to find answer for question: \"${input}",
  "for": "for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                base64String += splitDataURI.pop() ?? ''\n            }",
  "outsideClass_csvFileBase64": "const csvFileBase64 = nodeData.inputs?.csvFile as string\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        const _customReadCSV = nodeData.inputs?.customReadCSV as string\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the CSV agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        let files: string[] = []\n        let base64String = ''\n\n        if (csvFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = csvFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                base64String += fileData.toString('base64')\n            }\n        } else {\n            if (csvFileBase64.startsWith('[') && csvFileBase64.endsWith(']')) {\n                files = JSON.parse(csvFileBase64)\n            } else {\n                files = [csvFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                base64String += splitDataURI.pop() ?? ''\n            }\n        }\n\n        const pyodide = await LoadPyodide()\n\n        // First load the csv file and get the dataframe dictionary of column types\n        // For example using titanic.csv: {'PassengerId': 'int64', 'Survived': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Ticket': 'object', 'Fare': 'float64', 'Cabin': 'object', 'Embarked': 'object'}\n        let dataframeColDict = ''\n        let customReadCSVFunc = _customReadCSV ? _customReadCSV : 'read_csv(csv_data)'\n        try {\n            const code = `import pandas as pd\nimport base64\nfrom io import StringIO\nimport json\n\nbase64_string = \"${base64String}\"\n\ndecoded_data = base64.b64decode(base64_string)\n\ncsv_data = StringIO(decoded_data.decode('utf-8'))\n\ndf = pd.${customReadCSVFunc}\nmy_dict = df.dtypes.astype(str).to_dict()\nprint(my_dict)\njson.dumps(my_dict)`\n            dataframeColDict = await pyodide.runPythonAsync(code)\n        } catch (error) {\n            throw new Error(error)\n        }\n\n        // Then tell GPT to come out with ONLY python code\n        // For example: len(df), df[df['SibSp'] > 3]['PassengerId'].count()\n        let pythonCode = ''\n        if (dataframeColDict) {\n            const chain = new LLMChain({\n                llm: model,\n                prompt: PromptTemplate.fromTemplate(systemPrompt),\n                verbose: process.env.DEBUG === 'true' ? true : false\n            })\n            const inputs = {\n                dict: dataframeColDict,\n                question: input\n            }\n            const res = await chain.call(inputs, [loggerHandler, ...callbacks])\n            pythonCode = res?.text\n            // Regex to get rid of markdown code blocks syntax\n            pythonCode = pythonCode.replace(/^```[a-z]+\\n|\\n```$/gm, '')\n        }\n\n        // Then run the code using Pyodide\n        let finalResult = ''\n        if (pythonCode) {\n            try {\n                const code = `import pandas as pd\\n${pythonCode}`\n                // TODO: get print console output\n                finalResult = await pyodide.runPythonAsync(code)\n            } catch (error) {\n                throw new Error(`Sorry, I'm unable to find answer for question: \"${input}\" using following code: \"${pythonCode}\"`)\n            }\n        }\n\n        // Finally, return a complete answer\n        if (finalResult) {\n            const chain = new LLMChain({\n                llm: model,\n                prompt: PromptTemplate.fromTemplate(\n                    systemMessagePrompt ? `${systemMessagePrompt}\\n${finalSystemPrompt}` : finalSystemPrompt\n                ),\n                verbose: process.env.DEBUG === 'true' ? true : false\n            })\n            const inputs = {\n                question: input,\n                answer: finalResult\n            }\n\n            if (options.socketIO && options.socketIOClientId) {\n                const result = await chain.call(inputs, [loggerHandler, handler, ...callbacks])\n                return result?.text\n            } else {\n                const result = await chain.call(inputs, [loggerHandler, ...callbacks])\n                return result?.text\n            }\n        }\n\n        return pythonCode\n    }\n}"
}

## ConversationalAgent_Agents

{
  "className": "ConversationalAgent_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Conversational Agent'\n        this.name = 'conversationalAgent'\n        this.version = 3.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'agent.svg'\n        this.description = 'Conversational agent for a chat model. It will utilize chat specific prompts'\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Allowed Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (messageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            // Pop the `agent_scratchpad` MessagePlaceHolder\n            let messagePlaceholder = prompt.promptMessages.pop() as MessagesPlaceholder\n            if (prompt.promptMessages.at(-1) instanceof HumanMessagePromptTemplate) {\n                const lastMessage = prompt.promptMessages.pop() as HumanMessagePromptTemplate\n                const template = (lastMessage.prompt as PromptTemplate).template as string\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: template\n                    }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "for": "for (const step of steps) {\n        thoughts.push(new AIMessage(step.action.log))\n        thoughts.push(\n            new HumanMessage(\n                renderTemplate(TEMPLATE_TOOL_RESPONSE, 'f-string', {\n                    observation: step.observation\n                }",
  "outsideClass_DEFAULT_PREFIX": "const DEFAULT_PREFIX = `Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.`\n\nconst TEMPLATE_TOOL_RESPONSE = `TOOL RESPONSE:\n---------------------\n{observation}\n\nUSER'S INPUT\n--------------------\n\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.`",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the BabyAGI agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const executor = await prepareAgent(nodeData, options, { sessionId: this.sessionId, chatId: options.chatId, input })\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        let res: ChainValues = {}\n        let sourceDocuments: ICommonObject[] = []\n        let usedTools: IUsedTool[] = []\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, handler, ...callbacks] })\n            if (res.sourceDocuments) {\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', flatten(res.sourceDocuments))\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                options.socketIO.to(options.socketIOClientId).emit('usedTools', res.usedTools)\n                usedTools = res.usedTools\n            }\n            // If the tool is set to returnDirect, stream the output to the client\n            if (res.usedTools && res.usedTools.length) {\n                let inputTools = nodeData.inputs?.tools\n                inputTools = flatten(inputTools)\n                for (const tool of res.usedTools) {\n                    const inputTool = inputTools.find((inputTool: Tool) => inputTool.name === tool.tool)\n                    if (inputTool && inputTool.returnDirect) {\n                        options.socketIO.to(options.socketIOClientId).emit('token', tool.toolOutput)\n                    }\n                }\n            }\n        } else {\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, ...callbacks] })\n            if (res.sourceDocuments) {\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                usedTools = res.usedTools\n            }\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: res?.output,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        let finalRes = res?.output\n\n        if (sourceDocuments.length || usedTools.length) {\n            finalRes = { text: res?.output }\n            if (sourceDocuments.length) {\n                finalRes.sourceDocuments = flatten(sourceDocuments)\n            }\n            if (usedTools.length) {\n                finalRes.usedTools = usedTools\n            }\n            return finalRes\n        }\n\n        return finalRes\n    }\n}\n\nconst prepareAgent = async (\n    nodeData: INodeData,\n    options: ICommonObject,\n    flowObj: { sessionId?: string; chatId?: string; input?: string }\n) => {\n    const model = nodeData.inputs?.model as BaseChatModel\n    const maxIterations = nodeData.inputs?.maxIterations as string\n    let tools = nodeData.inputs?.tools as Tool[]\n    tools = flatten(tools)\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const systemMessage = nodeData.inputs?.systemMessage as string\n    const memoryKey = memory.memoryKey ? memory.memoryKey : 'chat_history'\n    const inputKey = memory.inputKey ? memory.inputKey : 'input'\n    const prependMessages = options?.prependMessages\n\n    const outputParser = ChatConversationalAgent.getDefaultOutputParser({\n        llm: model,\n        toolNames: tools.map((tool) => tool.name)\n    })\n\n    const prompt = ChatConversationalAgent.createPrompt(tools, {\n        systemMessage: systemMessage ? systemMessage : DEFAULT_PREFIX,\n        outputParser\n    })\n\n    if (llmSupportsVision(model)) {\n        const visionChatModel = model as IVisionChatModal\n        const messageContent = await addImagesToMessages(nodeData, options, model.multiModalOption)\n\n        if (messageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            // Pop the `agent_scratchpad` MessagePlaceHolder\n            let messagePlaceholder = prompt.promptMessages.pop() as MessagesPlaceholder\n            if (prompt.promptMessages.at(-1) instanceof HumanMessagePromptTemplate) {\n                const lastMessage = prompt.promptMessages.pop() as HumanMessagePromptTemplate\n                const template = (lastMessage.prompt as PromptTemplate).template as string\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: template\n                    }\n                ])\n                msg.inputVariables = lastMessage.inputVariables\n                prompt.promptMessages.push(msg)\n            }\n\n            // Add the `agent_scratchpad` MessagePlaceHolder back\n            prompt.promptMessages.push(messagePlaceholder)\n        } else {\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    /** Bind a stop token to the model */\n    const modelWithStop = model.bind({\n        stop: ['\\nObservation']\n    })\n\n    const runnableAgent = RunnableSequence.from([\n        {\n            [inputKey]: (i: { input: string; steps: AgentStep[] }) => i.input,\n            agent_scratchpad: async (i: { input: string; steps: AgentStep[] }) => await constructScratchPad(i.steps),\n            [memoryKey]: async (_: { input: string; steps: AgentStep[] }) => {\n                const messages = (await memory.getChatMessages(flowObj?.sessionId, true, prependMessages)) as BaseMessage[]\n                return messages ?? []\n            }\n        },\n        prompt,\n        modelWithStop,\n        outputParser\n    ])\n\n    const executor = AgentExecutor.fromAgentAndTools({\n        agent: runnableAgent,\n        tools,\n        sessionId: flowObj?.sessionId,\n        chatId: flowObj?.chatId,\n        input: flowObj?.input,\n        verbose: process.env.DEBUG === 'true',\n        maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n    })\n\n    return executor\n}\n\nconst constructScratchPad = async (steps: AgentStep[]): Promise<BaseMessage[]> => {\n    const thoughts: BaseMessage[] = []\n    for (const step of steps) {\n        thoughts.push(new AIMessage(step.action.log))\n        thoughts.push(\n            new HumanMessage(\n                renderTemplate(TEMPLATE_TOOL_RESPONSE, 'f-string', {\n                    observation: step.observation\n                })\n            )\n        )\n    }\n    return thoughts\n}"
}

## ConversationalRetrievalToolAgent_Agents

{
  "className": "ConversationalRetrievalToolAgent_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Conversational Retrieval Tool Agent'\n        this.name = 'conversationalRetrievalToolAgent'\n        this.author = 'niztal(falkor)'\n        this.version = 1.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'toolAgent.png'\n        this.description = `Agent that calls a vector store retrieval and uses Function Calling to pick the tools and args to call`\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.badge = 'NEW'\n        this.inputs = [\n            {\n                label: 'Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (model.bindTools === undefined) {\n        throw new Error(`This agent requires that the \"bindTools()\" method be implemented on the input model.`)\n    }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                if (isStreamable)\n                    streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        const isStreamable = options.socketIO && options.socketIOClientId\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the OpenAI Function Agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                if (isStreamable)\n                    streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const executor = await prepareAgent(nodeData, options, { sessionId: this.sessionId, chatId: options.chatId, input })\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        let res: ChainValues = {}\n        let sourceDocuments: ICommonObject[] = []\n        let usedTools: IUsedTool[] = []\n\n        if (isStreamable) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, handler, ...callbacks] })\n            if (res.sourceDocuments) {\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', flatten(res.sourceDocuments))\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                options.socketIO.to(options.socketIOClientId).emit('usedTools', res.usedTools)\n                usedTools = res.usedTools\n            }\n        } else {\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, ...callbacks] })\n            if (res.sourceDocuments) {\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                usedTools = res.usedTools\n            }\n        }\n\n        let output = res?.output as string\n\n        // Claude 3 Opus tends to spit out <thinking>..</thinking> as well, discard that in final output\n        const regexPattern: RegExp = /<thinking>[\\s\\S]*?<\\/thinking>/\n        const matches: RegExpMatchArray | null = output.match(regexPattern)\n        if (matches) {\n            for (const match of matches) {\n                output = output.replace(match, '')\n            }\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: output,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        let finalRes = res?.output\n\n        if (sourceDocuments.length || usedTools.length) {\n            const finalRes: ICommonObject = { text: output }\n            if (sourceDocuments.length) {\n                finalRes.sourceDocuments = flatten(sourceDocuments)\n            }\n            if (usedTools.length) {\n                finalRes.usedTools = usedTools\n            }\n            return finalRes\n        }\n\n        return finalRes\n    }\n}\n\nconst formatDocs = (docs: Document[]) => {\n    return docs.map((doc, i) => `<doc id='${i}'>${doc.pageContent}</doc>`).join('\\n')\n}\n\nconst prepareAgent = async (\n    nodeData: INodeData,\n    options: ICommonObject,\n    flowObj: { sessionId?: string; chatId?: string; input?: string }\n) => {\n    const model = nodeData.inputs?.model as BaseChatModel\n    const maxIterations = nodeData.inputs?.maxIterations as string\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const systemMessage = nodeData.inputs?.systemMessage as string\n    let tools = nodeData.inputs?.tools\n    tools = flatten(tools)\n    const memoryKey = memory.memoryKey ? memory.memoryKey : 'chat_history'\n    const inputKey = memory.inputKey ? memory.inputKey : 'input'\n    const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as BaseRetriever\n\n    const prompt = ChatPromptTemplate.fromMessages([\n        ['system', systemMessage ? systemMessage : `You are a helpful AI assistant.`],\n        new MessagesPlaceholder(memoryKey),\n        ['human', `{${inputKey}}`],\n        new MessagesPlaceholder('agent_scratchpad')\n    ])\n\n    if (llmSupportsVision(model)) {\n        const visionChatModel = model as IVisionChatModal\n        const messageContent = await addImagesToMessages(nodeData, options, model.multiModalOption)\n\n        if (messageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            // Pop the `agent_scratchpad` MessagePlaceHolder\n            let messagePlaceholder = prompt.promptMessages.pop() as MessagesPlaceholder\n            if (prompt.promptMessages.at(-1) instanceof HumanMessagePromptTemplate) {\n                const lastMessage = prompt.promptMessages.pop() as HumanMessagePromptTemplate\n                const template = (lastMessage.prompt as PromptTemplate).template as string\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: template\n                    }\n                ])\n                msg.inputVariables = lastMessage.inputVariables\n                prompt.promptMessages.push(msg)\n            }\n\n            // Add the `agent_scratchpad` MessagePlaceHolder back\n            prompt.promptMessages.push(messagePlaceholder)\n        } else {\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    if (model.bindTools === undefined) {\n        throw new Error(`This agent requires that the \"bindTools()\" method be implemented on the input model.`)\n    }\n\n    const modelWithTools = model.bindTools(tools)\n\n    const runnableAgent = RunnableSequence.from([\n        {\n            [inputKey]: (i: { input: string; steps: ToolsAgentStep[] }) => i.input,\n            agent_scratchpad: (i: { input: string; steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(i.steps),\n            [memoryKey]: async (_: { input: string; steps: ToolsAgentStep[] }) => {\n                const messages = (await memory.getChatMessages(flowObj?.sessionId, true)) as BaseMessage[]\n                return messages ?? []\n            },\n            context: async (i: { input: string; chatHistory?: string }) => {\n                const relevantDocs = await vectorStoreRetriever.invoke(i.input)\n                const formattedDocs = formatDocs(relevantDocs)\n                return formattedDocs\n            }\n        },\n        prompt,\n        modelWithTools,\n        new ToolCallingAgentOutputParser()\n    ])\n\n    const executor = AgentExecutor.fromAgentAndTools({\n        agent: runnableAgent,\n        tools,\n        sessionId: flowObj?.sessionId,\n        chatId: flowObj?.chatId,\n        input: flowObj?.input,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n    })\n\n    return executor\n}"
}

## AnthropicAgent_LlamaIndex_Agents

{
  "className": "AnthropicAgent_LlamaIndex_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Anthropic Agent'\n        this.name = 'anthropicAgentLlamaIndex'\n        this.version = 1.0\n        this.type = 'AnthropicAgent'\n        this.category = 'Agents'\n        this.icon = 'Anthropic.svg'\n        this.description = `Agent that uses Anthropic Claude Function Calling to pick the tools and args to call using LlamaIndex`\n        this.baseClasses = [this.type, ...getBaseClasses(AnthropicAgent)]\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Tools',\n                name: 'tools',\n                type: 'Tool_LlamaIndex',\n                list: true\n            }",
  "if": "if (response.sources.length) {\n            for (const sourceTool of response.sources) {\n                usedTools.push({\n                    tool: sourceTool.tool?.metadata.name ?? '',\n                    toolInput: sourceTool.input,\n                    toolOutput: sourceTool.output as any\n                }",
  "for": "for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                }",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const model = nodeData.inputs?.model as Anthropic\n        const systemMessage = nodeData.inputs?.systemMessage as string\n        const prependMessages = options?.prependMessages\n\n        let tools = nodeData.inputs?.tools\n        tools = flatten(tools)\n\n        const chatHistory = [] as ChatMessage[]\n\n        if (systemMessage) {\n            chatHistory.push({\n                content: systemMessage,\n                role: 'system'\n            })\n        }\n\n        const msgs = (await memory.getChatMessages(this.sessionId, false, prependMessages)) as IMessage[]\n        for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                })\n            } else if (message.type === 'userMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'user'\n                })\n            }\n        }\n\n        const agent = new AnthropicAgent({\n            tools,\n            llm: model,\n            chatHistory: chatHistory,\n            verbose: process.env.DEBUG === 'true' ? true : false\n        })\n\n        let text = ''\n        const usedTools: IUsedTool[] = []\n\n        const response = await agent.chat({ message: input, chatHistory, verbose: process.env.DEBUG === 'true' ? true : false })\n\n        if (response.sources.length) {\n            for (const sourceTool of response.sources) {\n                usedTools.push({\n                    tool: sourceTool.tool?.metadata.name ?? '',\n                    toolInput: sourceTool.input,\n                    toolOutput: sourceTool.output as any\n                })\n            }\n        }\n\n        if (Array.isArray(response.response.message.content) && response.response.message.content.length > 0) {\n            text = (response.response.message.content[0] as MessageContentTextDetail).text\n        } else {\n            text = response.response.message.content as string\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: text,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        return usedTools.length ? { text: text, usedTools } : text\n    }\n}"
}

## OpenAIFunctionAgent_LlamaIndex_Agents

{
  "className": "OpenAIFunctionAgent_LlamaIndex_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'OpenAI Tool Agent'\n        this.name = 'openAIToolAgentLlamaIndex'\n        this.version = 2.0\n        this.type = 'OpenAIToolAgent'\n        this.category = 'Agents'\n        this.icon = 'function.svg'\n        this.description = `Agent that uses OpenAI Function Calling to pick the tools and args to call using LlamaIndex`\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAIAgent)]\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Tools',\n                name: 'tools',\n                type: 'Tool_LlamaIndex',\n                list: true\n            }",
  "if": "if (response.sources.length) {\n                for (const sourceTool of response.sources) {\n                    usedTools.push({\n                        tool: sourceTool.tool?.metadata.name ?? '',\n                        toolInput: sourceTool.input,\n                        toolOutput: sourceTool.output as any\n                    }",
  "for": "for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                }",
  "await": "await (const chunk of stream) {\n                //console.log('chunk', chunk)\n                text += chunk.response.delta\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response.delta)\n                    if (chunk.sources.length) {\n                        for (const sourceTool of chunk.sources) {\n                            usedTools.push({\n                                tool: sourceTool.tool?.metadata.name ?? '',\n                                toolInput: sourceTool.input,\n                                toolOutput: sourceTool.output as any\n                            }",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const model = nodeData.inputs?.model as OpenAI\n        const systemMessage = nodeData.inputs?.systemMessage as string\n        let tools = nodeData.inputs?.tools\n        tools = flatten(tools)\n\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        const chatHistory = [] as ChatMessage[]\n\n        if (systemMessage) {\n            chatHistory.push({\n                content: systemMessage,\n                role: 'system'\n            })\n        }\n\n        const msgs = (await memory.getChatMessages(this.sessionId, false)) as IMessage[]\n        for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                })\n            } else if (message.type === 'userMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'user'\n                })\n            }\n        }\n\n        const agent = new OpenAIAgent({\n            tools,\n            llm: model,\n            chatHistory: chatHistory,\n            verbose: process.env.DEBUG === 'true' ? true : false\n        })\n\n        let text = ''\n        let isStreamingStarted = false\n        const usedTools: IUsedTool[] = []\n\n        if (isStreamingEnabled) {\n            const stream = await agent.chat({\n                message: input,\n                chatHistory,\n                stream: true,\n                verbose: process.env.DEBUG === 'true' ? true : false\n            })\n            for await (const chunk of stream) {\n                //console.log('chunk', chunk)\n                text += chunk.response.delta\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response.delta)\n                    if (chunk.sources.length) {\n                        for (const sourceTool of chunk.sources) {\n                            usedTools.push({\n                                tool: sourceTool.tool?.metadata.name ?? '',\n                                toolInput: sourceTool.input,\n                                toolOutput: sourceTool.output as any\n                            })\n                        }\n                        options.socketIO.to(options.socketIOClientId).emit('usedTools', usedTools)\n                    }\n                }\n\n                options.socketIO.to(options.socketIOClientId).emit('token', chunk.response.delta)\n            }\n        } else {\n            const response = await agent.chat({ message: input, chatHistory, verbose: process.env.DEBUG === 'true' ? true : false })\n            if (response.sources.length) {\n                for (const sourceTool of response.sources) {\n                    usedTools.push({\n                        tool: sourceTool.tool?.metadata.name ?? '',\n                        toolInput: sourceTool.input,\n                        toolOutput: sourceTool.output as any\n                    })\n                }\n            }\n\n            text = response.response.message.content as string\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: text,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        return usedTools.length ? { text: text, usedTools } : text\n    }\n}"
}

## OpenAIAssistant_Agents

{
  "className": "OpenAIAssistant_Agents",
  "loadMethods": {},
  "init": "[Function: init]",
  "clearChatMessages": "[Function: clearChatMessages]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'OpenAI Assistant'\n        this.name = 'openAIAssistant'\n        this.version = 4.0\n        this.type = 'OpenAIAssistant'\n        this.category = 'Agents'\n        this.icon = 'assistant.svg'\n        this.description = `An agent that uses OpenAI Assistant API to pick the tool and args to call`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Select Assistant',\n                name: 'selectedAssistant',\n                type: 'asyncOptions',\n                loadMethod: 'listAssistants'\n            }",
  "if": "if (!response.ok) {\n            throw new Error(`HTTP error! status: ${response.status}",
  "for": "for (let i = 0; i < assistantMessages[0].content.length; i += 1) {\n                if (assistantMessages[0].content[i].type === 'text') {\n                    const content = assistantMessages[0].content[i] as OpenAI.Beta.Threads.Messages.TextContentBlock\n\n                    if (content.text.annotations) {\n                        const message_content = content.text\n                        const annotations = message_content.annotations\n\n                        // Iterate over the annotations\n                        for (let index = 0; index < annotations.length; index++) {\n                            const annotation = annotations[index]\n                            let filePath = ''\n\n                            // Gather citations based on annotation attributes\n                            const file_citation = (annotation as OpenAI.Beta.Threads.Messages.FileCitationAnnotation).file_citation\n\n                            if (file_citation) {\n                                const cited_file = await openai.files.retrieve(file_citation.file_id)\n                                // eslint-disable-next-line no-useless-escape\n                                const fileName = cited_file.filename.split(/[\\/\\\\]/).pop() ?? cited_file.filename\n                                if (!disableFileDownload) {\n                                    filePath = await downloadFile(openAIApiKey, cited_file, fileName, options.chatflowid, options.chatId)\n                                    fileAnnotations.push({\n                                        filePath,\n                                        fileName\n                                    }",
  "catch": "catch (error) {\n        console.error('Error downloading or writing the file:', error)\n        return ''\n    }",
  "await": "await (const event of stream) {\n                                    if (event.event === 'thread.message.delta') {\n                                        const chunk = event.data.delta.content?.[0]\n                                        if (chunk && 'text' in chunk && chunk.text?.value) {\n                                            text += chunk.text.value\n                                            if (!isStreamingStarted) {\n                                                isStreamingStarted = true\n                                                socketIO.to(socketIOClientId).emit('start', chunk.text.value)\n                                            }",
  "while": "while (state === 'requires_action_retry') {\n                if (retries > 0) {\n                    retries -= 1\n                    const newRunThread = await openai.beta.threads.runs.create(threadId, {\n                        assistant_id: retrievedAssistant.id,\n                        tool_choice: toolChoice,\n                        parallel_tool_calls: parallelToolCalls\n                    }",
  "outsideClass_lenticularBracketRegex": "const lenticularBracketRegex = /【[^】]*】/g\nconst imageRegex = /<img[^>]*\\/>/g",
  "outsideClass_appDataSource": "const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n            if (appDataSource === undefined || !appDataSource) {\n                return returnData\n            }\n\n            const assistants = await appDataSource.getRepository(databaseEntities['Assistant']).find()\n\n            for (let i = 0; i < assistants.length; i += 1) {\n                const assistantDetails = JSON.parse(assistants[i].details)\n                const data = {\n                    label: assistantDetails.name,\n                    name: assistants[i].id,\n                    description: assistantDetails.instructions\n                } as INodeOptionsValue\n                returnData.push(data)\n            }\n            return returnData\n        }\n    }\n\n    async init(): Promise<any> {\n        return null\n    }\n\n    async clearChatMessages(nodeData: INodeData, options: ICommonObject, sessionIdObj: { type: string; id: string }): Promise<void> {\n        const selectedAssistantId = nodeData.inputs?.selectedAssistant as string\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n        const assistant = await appDataSource.getRepository(databaseEntities['Assistant']).findOneBy({\n            id: selectedAssistantId\n        })\n\n        if (!assistant) {\n            options.logger.error(`Assistant ${selectedAssistantId} not found`)\n            return\n        }\n\n        if (!sessionIdObj) return\n\n        let sessionId = ''\n        if (sessionIdObj.type === 'chatId') {\n            const chatId = sessionIdObj.id\n            const chatmsg = await appDataSource.getRepository(databaseEntities['ChatMessage']).findOneBy({\n                chatId\n            })\n            if (!chatmsg) {\n                options.logger.error(`Chat Message with Chat Id: ${chatId} not found`)\n                return\n            }\n            sessionId = chatmsg.sessionId\n        } else if (sessionIdObj.type === 'threadId') {\n            sessionId = sessionIdObj.id\n        }\n\n        const credentialData = await getCredentialData(assistant.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n        if (!openAIApiKey) {\n            options.logger.error(`OpenAI ApiKey not found`)\n            return\n        }\n\n        const openai = new OpenAI({ apiKey: openAIApiKey })\n        options.logger.info(`Clearing OpenAI Thread ${sessionId}`)\n        try {\n            if (sessionId && sessionId.startsWith('thread_')) {\n                await openai.beta.threads.del(sessionId)\n                options.logger.info(`Successfully cleared OpenAI Thread ${sessionId}`)\n            } else {\n                options.logger.error(`Error clearing OpenAI Thread ${sessionId}`)\n            }\n        } catch (e) {\n            options.logger.error(`Error clearing OpenAI Thread ${sessionId}`)\n        }\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const selectedAssistantId = nodeData.inputs?.selectedAssistant as string\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const disableFileDownload = nodeData.inputs?.disableFileDownload as boolean\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        const _toolChoice = nodeData.inputs?.toolChoice as string\n        const parallelToolCalls = nodeData.inputs?.parallelToolCalls as boolean\n        const isStreaming = options.socketIO && options.socketIOClientId\n        const socketIO = isStreaming ? options.socketIO : undefined\n        const socketIOClientId = isStreaming ? options.socketIOClientId : ''\n\n        if (moderations && moderations.length > 0) {\n            try {\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(isStreaming, e.message, socketIO, socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        let tools = nodeData.inputs?.tools\n        tools = flatten(tools)\n        const formattedTools = tools?.map((tool: any) => formatToOpenAIAssistantTool(tool)) ?? []\n\n        const usedTools: IUsedTool[] = []\n        const fileAnnotations = []\n\n        const assistant = await appDataSource.getRepository(databaseEntities['Assistant']).findOneBy({\n            id: selectedAssistantId\n        })\n\n        if (!assistant) throw new Error(`Assistant ${selectedAssistantId} not found`)\n\n        const credentialData = await getCredentialData(assistant.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n        if (!openAIApiKey) throw new Error(`OpenAI ApiKey not found`)\n\n        const openai = new OpenAI({ apiKey: openAIApiKey })\n\n        // Start analytics\n        const analyticHandlers = new AnalyticHandler(nodeData, options)\n        await analyticHandlers.init()\n        const parentIds = await analyticHandlers.onChainStart('OpenAIAssistant', input)\n\n        try {\n            const assistantDetails = JSON.parse(assistant.details)\n            const openAIAssistantId = assistantDetails.id\n\n            // Retrieve assistant\n            const retrievedAssistant = await openai.beta.assistants.retrieve(openAIAssistantId)\n\n            if (formattedTools.length) {\n                let filteredTools = []\n                for (const tool of retrievedAssistant.tools) {\n                    if (tool.type === 'code_interpreter' || tool.type === 'file_search') filteredTools.push(tool)\n                }\n                filteredTools = uniqWith([...filteredTools, ...formattedTools], isEqual)\n                // filter out tool with empty function\n                filteredTools = filteredTools.filter((tool) => !(tool.type === 'function' && !(tool as any).function))\n                await openai.beta.assistants.update(openAIAssistantId, { tools: filteredTools })\n            } else {\n                let filteredTools = retrievedAssistant.tools.filter((tool) => tool.type !== 'function')\n                await openai.beta.assistants.update(openAIAssistantId, { tools: filteredTools })\n            }\n\n            const chatmessage = await appDataSource.getRepository(databaseEntities['ChatMessage']).findOneBy({\n                chatId: options.chatId,\n                chatflowid: options.chatflowid\n            })\n\n            let threadId = ''\n            let isNewThread = false\n            if (!chatmessage) {\n                const thread = await openai.beta.threads.create({})\n                threadId = thread.id\n                isNewThread = true\n            } else {\n                const thread = await openai.beta.threads.retrieve(chatmessage.sessionId)\n                threadId = thread.id\n            }\n\n            // List all runs, in case existing thread is still running\n            if (!isNewThread) {\n                const promise = (threadId: string) => {\n                    return new Promise<void>((resolve) => {\n                        const timeout = setInterval(async () => {\n                            const allRuns = await openai.beta.threads.runs.list(threadId)\n                            if (allRuns.data && allRuns.data.length) {\n                                const firstRunId = allRuns.data[0].id\n                                const runStatus = allRuns.data.find((run) => run.id === firstRunId)?.status\n                                if (\n                                    runStatus &&\n                                    (runStatus === 'cancelled' ||\n                                        runStatus === 'completed' ||\n                                        runStatus === 'expired' ||\n                                        runStatus === 'failed' ||\n                                        runStatus === 'requires_action')\n                                ) {\n                                    clearInterval(timeout)\n                                    resolve()\n                                }\n                            } else {\n                                clearInterval(timeout)\n                                resolve()\n                            }\n                        }, 500)\n                    })\n                }\n                await promise(threadId)\n            }\n\n            // Add message to thread\n            await openai.beta.threads.messages.create(threadId, {\n                role: 'user',\n                content: input\n            })\n\n            // Run assistant thread\n            const llmIds = await analyticHandlers.onLLMStart('ChatOpenAI', input, parentIds)\n\n            let text = ''\n            let runThreadId = ''\n            let isStreamingStarted = false\n\n            let toolChoice: any\n            if (_toolChoice) {\n                if (_toolChoice === 'file_search') {\n                    toolChoice = { type: 'file_search' }\n                } else if (_toolChoice === 'code_interpreter') {\n                    toolChoice = { type: 'code_interpreter' }\n                } else if (_toolChoice === 'none' || _toolChoice === 'auto' || _toolChoice === 'required') {\n                    toolChoice = _toolChoice\n                } else {\n                    toolChoice = { type: 'function', function: { name: _toolChoice } }\n                }\n            }\n\n            if (isStreaming) {\n                const streamThread = await openai.beta.threads.runs.create(threadId, {\n                    assistant_id: retrievedAssistant.id,\n                    stream: true,\n                    tool_choice: toolChoice,\n                    parallel_tool_calls: parallelToolCalls\n                })\n\n                for await (const event of streamThread) {\n                    if (event.event === 'thread.run.created') {\n                        runThreadId = event.data.id\n                    }\n\n                    if (event.event === 'thread.message.delta') {\n                        const chunk = event.data.delta.content?.[0]\n\n                        if (chunk && 'text' in chunk) {\n                            if (chunk.text?.annotations?.length) {\n                                const message_content = chunk.text\n                                const annotations = chunk.text?.annotations\n\n                                // Iterate over the annotations\n                                for (let index = 0; index < annotations.length; index++) {\n                                    const annotation = annotations[index]\n                                    let filePath = ''\n\n                                    // Gather citations based on annotation attributes\n                                    const file_citation = (annotation as OpenAI.Beta.Threads.Messages.FileCitationAnnotation).file_citation\n                                    if (file_citation) {\n                                        const cited_file = await openai.files.retrieve(file_citation.file_id)\n                                        // eslint-disable-next-line no-useless-escape\n                                        const fileName = cited_file.filename.split(/[\\/\\\\]/).pop() ?? cited_file.filename\n                                        if (!disableFileDownload) {\n                                            filePath = await downloadFile(\n                                                openAIApiKey,\n                                                cited_file,\n                                                fileName,\n                                                options.chatflowid,\n                                                options.chatId\n                                            )\n                                            fileAnnotations.push({\n                                                filePath,\n                                                fileName\n                                            })\n                                        }\n                                    } else {\n                                        const file_path = (annotation as OpenAI.Beta.Threads.Messages.FilePathAnnotation).file_path\n                                        if (file_path) {\n                                            const cited_file = await openai.files.retrieve(file_path.file_id)\n                                            // eslint-disable-next-line no-useless-escape\n                                            const fileName = cited_file.filename.split(/[\\/\\\\]/).pop() ?? cited_file.filename\n                                            if (!disableFileDownload) {\n                                                filePath = await downloadFile(\n                                                    openAIApiKey,\n                                                    cited_file,\n                                                    fileName,\n                                                    options.chatflowid,\n                                                    options.chatId\n                                                )\n                                                fileAnnotations.push({\n                                                    filePath,\n                                                    fileName\n                                                })\n                                            }\n                                        }\n                                    }\n\n                                    // Replace the text with a footnote\n                                    message_content.value = message_content.value?.replace(\n                                        `${annotation.text}`,\n                                        `${disableFileDownload ? '' : filePath}`\n                                    )\n                                }\n\n                                // Remove lenticular brackets\n                                message_content.value = message_content.value?.replace(lenticularBracketRegex, '')\n\n                                text += message_content.value ?? ''\n\n                                if (message_content.value) {\n                                    if (!isStreamingStarted) {\n                                        isStreamingStarted = true\n                                        socketIO.to(socketIOClientId).emit('start', message_content.value)\n                                    }\n                                    socketIO.to(socketIOClientId).emit('token', message_content.value)\n                                }\n\n                                if (fileAnnotations.length) {\n                                    if (!isStreamingStarted) {\n                                        isStreamingStarted = true\n                                        socketIO.to(socketIOClientId).emit('start', '')\n                                    }\n                                    socketIO.to(socketIOClientId).emit('fileAnnotations', fileAnnotations)\n                                }\n                            } else {\n                                text += chunk.text?.value\n                                if (!isStreamingStarted) {\n                                    isStreamingStarted = true\n                                    socketIO.to(socketIOClientId).emit('start', chunk.text?.value)\n                                }\n\n                                socketIO.to(socketIOClientId).emit('token', chunk.text?.value)\n                            }\n                        }\n\n                        if (chunk && 'image_file' in chunk && chunk.image_file?.file_id) {\n                            const fileId = chunk.image_file.file_id\n                            const fileObj = await openai.files.retrieve(fileId)\n\n                            const buffer = await downloadImg(openai, fileId, `${fileObj.filename}.png`, options.chatflowid, options.chatId)\n                            const base64String = Buffer.from(buffer).toString('base64')\n\n                            // TODO: Use a file path and retrieve image on the fly. Storing as base64 to localStorage and database will easily hit limits\n                            const imgHTML = `<img src=\"data:image/png;base64,${base64String}\" width=\"100%\" height=\"max-content\" alt=\"${fileObj.filename}\" /><br/>`\n                            text += imgHTML\n\n                            if (!isStreamingStarted) {\n                                isStreamingStarted = true\n                                socketIO.to(socketIOClientId).emit('start', imgHTML)\n                            }\n\n                            socketIO.to(socketIOClientId).emit('token', imgHTML)\n                        }\n                    }\n\n                    if (event.event === 'thread.run.requires_action') {\n                        if (event.data.required_action?.submit_tool_outputs.tool_calls) {\n                            const actions: ICommonObject[] = []\n                            event.data.required_action.submit_tool_outputs.tool_calls.forEach((item) => {\n                                const functionCall = item.function\n                                let args = {}\n                                try {\n                                    args = JSON.parse(functionCall.arguments)\n                                } catch (e) {\n                                    console.error('Error parsing arguments, default to empty object')\n                                }\n                                actions.push({\n                                    tool: functionCall.name,\n                                    toolInput: args,\n                                    toolCallId: item.id\n                                })\n                            })\n\n                            const submitToolOutputs = []\n                            for (let i = 0; i < actions.length; i += 1) {\n                                const tool = tools.find((tool: any) => tool.name === actions[i].tool)\n                                if (!tool) continue\n\n                                // Start tool analytics\n                                const toolIds = await analyticHandlers.onToolStart(tool.name, actions[i].toolInput, parentIds)\n\n                                try {\n                                    const toolOutput = await tool.call(actions[i].toolInput, undefined, undefined, {\n                                        sessionId: threadId,\n                                        chatId: options.chatId,\n                                        input\n                                    })\n                                    await analyticHandlers.onToolEnd(toolIds, toolOutput)\n                                    submitToolOutputs.push({\n                                        tool_call_id: actions[i].toolCallId,\n                                        output: toolOutput\n                                    })\n                                    usedTools.push({\n                                        tool: tool.name,\n                                        toolInput: actions[i].toolInput,\n                                        toolOutput\n                                    })\n                                } catch (e) {\n                                    await analyticHandlers.onToolEnd(toolIds, e)\n                                    console.error('Error executing tool', e)\n                                    throw new Error(\n                                        `Error executing tool. Tool: ${tool.name}. Thread ID: ${threadId}. Run ID: ${runThreadId}`\n                                    )\n                                }\n                            }\n\n                            try {\n                                const stream = openai.beta.threads.runs.submitToolOutputsStream(threadId, runThreadId, {\n                                    tool_outputs: submitToolOutputs\n                                })\n\n                                for await (const event of stream) {\n                                    if (event.event === 'thread.message.delta') {\n                                        const chunk = event.data.delta.content?.[0]\n                                        if (chunk && 'text' in chunk && chunk.text?.value) {\n                                            text += chunk.text.value\n                                            if (!isStreamingStarted) {\n                                                isStreamingStarted = true\n                                                socketIO.to(socketIOClientId).emit('start', chunk.text.value)\n                                            }\n\n                                            socketIO.to(socketIOClientId).emit('token', chunk.text.value)\n                                        }\n                                    }\n                                }\n\n                                socketIO.to(socketIOClientId).emit('usedTools', usedTools)\n                            } catch (error) {\n                                console.error('Error submitting tool outputs:', error)\n                                await openai.beta.threads.runs.cancel(threadId, runThreadId)\n\n                                const errMsg = `Error submitting tool outputs. Thread ID: ${threadId}. Run ID: ${runThreadId}`\n\n                                await analyticHandlers.onLLMError(llmIds, errMsg)\n                                await analyticHandlers.onChainError(parentIds, errMsg, true)\n\n                                throw new Error(errMsg)\n                            }\n                        }\n                    }\n                }\n\n                // List messages\n                const messages = await openai.beta.threads.messages.list(threadId)\n                const messageData = messages.data ?? []\n                const assistantMessages = messageData.filter((msg) => msg.role === 'assistant')\n                if (!assistantMessages.length) return ''\n\n                // Remove images from the logging text\n                let llmOutput = text.replace(imageRegex, '')\n                llmOutput = llmOutput.replace('<br/>', '')\n\n                await analyticHandlers.onLLMEnd(llmIds, llmOutput)\n                await analyticHandlers.onChainEnd(parentIds, messageData, true)\n\n                return {\n                    text,\n                    usedTools,\n                    fileAnnotations,\n                    assistant: { assistantId: openAIAssistantId, threadId, runId: runThreadId, messages: messageData }\n                }\n            }\n\n            const promise = (threadId: string, runId: string) => {\n                return new Promise((resolve, reject) => {\n                    const timeout = setInterval(async () => {\n                        const run = await openai.beta.threads.runs.retrieve(threadId, runId)\n                        const state = run.status\n                        if (state === 'completed') {\n                            clearInterval(timeout)\n                            resolve(state)\n                        } else if (state === 'requires_action') {\n                            if (run.required_action?.submit_tool_outputs.tool_calls) {\n                                clearInterval(timeout)\n                                const actions: ICommonObject[] = []\n                                run.required_action.submit_tool_outputs.tool_calls.forEach((item) => {\n                                    const functionCall = item.function\n                                    let args = {}\n                                    try {\n                                        args = JSON.parse(functionCall.arguments)\n                                    } catch (e) {\n                                        console.error('Error parsing arguments, default to empty object')\n                                    }\n                                    actions.push({\n                                        tool: functionCall.name,\n                                        toolInput: args,\n                                        toolCallId: item.id\n                                    })\n                                })\n\n                                const submitToolOutputs = []\n                                for (let i = 0; i < actions.length; i += 1) {\n                                    const tool = tools.find((tool: any) => tool.name === actions[i].tool)\n                                    if (!tool) continue\n\n                                    // Start tool analytics\n                                    const toolIds = await analyticHandlers.onToolStart(tool.name, actions[i].toolInput, parentIds)\n                                    if (socketIO && socketIOClientId) socketIO.to(socketIOClientId).emit('tool', tool.name)\n\n                                    try {\n                                        const toolOutput = await tool.call(actions[i].toolInput, undefined, undefined, {\n                                            sessionId: threadId,\n                                            chatId: options.chatId,\n                                            input\n                                        })\n                                        await analyticHandlers.onToolEnd(toolIds, toolOutput)\n                                        submitToolOutputs.push({\n                                            tool_call_id: actions[i].toolCallId,\n                                            output: toolOutput\n                                        })\n                                        usedTools.push({\n                                            tool: tool.name,\n                                            toolInput: actions[i].toolInput,\n                                            toolOutput\n                                        })\n                                    } catch (e) {\n                                        await analyticHandlers.onToolEnd(toolIds, e)\n                                        console.error('Error executing tool', e)\n                                        clearInterval(timeout)\n                                        reject(\n                                            new Error(\n                                                `Error processing thread: ${state}, Thread ID: ${threadId}, Run ID: ${runId}, Tool: ${tool.name}`\n                                            )\n                                        )\n                                        break\n                                    }\n                                }\n\n                                const newRun = await openai.beta.threads.runs.retrieve(threadId, runId)\n                                const newStatus = newRun?.status\n\n                                try {\n                                    if (submitToolOutputs.length && newStatus === 'requires_action') {\n                                        await openai.beta.threads.runs.submitToolOutputs(threadId, runId, {\n                                            tool_outputs: submitToolOutputs\n                                        })\n                                        resolve(state)\n                                    } else {\n                                        await openai.beta.threads.runs.cancel(threadId, runId)\n                                        resolve('requires_action_retry')\n                                    }\n                                } catch (e) {\n                                    clearInterval(timeout)\n                                    reject(new Error(`Error submitting tool outputs: ${state}, Thread ID: ${threadId}, Run ID: ${runId}`))\n                                }\n                            }\n                        } else if (state === 'cancelled' || state === 'expired' || state === 'failed') {\n                            clearInterval(timeout)\n                            reject(\n                                new Error(`Error processing thread: ${state}, Thread ID: ${threadId}, Run ID: ${runId}, Status: ${state}`)\n                            )\n                        }\n                    }, 500)\n                })\n            }\n\n            // Polling run status\n            const runThread = await openai.beta.threads.runs.create(threadId, {\n                assistant_id: retrievedAssistant.id,\n                tool_choice: toolChoice,\n                parallel_tool_calls: parallelToolCalls\n            })\n            runThreadId = runThread.id\n            let state = await promise(threadId, runThread.id)\n            while (state === 'requires_action') {\n                state = await promise(threadId, runThread.id)\n            }\n\n            let retries = 3\n            while (state === 'requires_action_retry') {\n                if (retries > 0) {\n                    retries -= 1\n                    const newRunThread = await openai.beta.threads.runs.create(threadId, {\n                        assistant_id: retrievedAssistant.id,\n                        tool_choice: toolChoice,\n                        parallel_tool_calls: parallelToolCalls\n                    })\n                    runThreadId = newRunThread.id\n                    state = await promise(threadId, newRunThread.id)\n                } else {\n                    const errMsg = `Error processing thread: ${state}, Thread ID: ${threadId}`\n                    await analyticHandlers.onChainError(parentIds, errMsg)\n                    throw new Error(errMsg)\n                }\n            }\n\n            // List messages\n            const messages = await openai.beta.threads.messages.list(threadId)\n            const messageData = messages.data ?? []\n            const assistantMessages = messageData.filter((msg) => msg.role === 'assistant')\n            if (!assistantMessages.length) return ''\n\n            let returnVal = ''\n            for (let i = 0; i < assistantMessages[0].content.length; i += 1) {\n                if (assistantMessages[0].content[i].type === 'text') {\n                    const content = assistantMessages[0].content[i] as OpenAI.Beta.Threads.Messages.TextContentBlock\n\n                    if (content.text.annotations) {\n                        const message_content = content.text\n                        const annotations = message_content.annotations\n\n                        // Iterate over the annotations\n                        for (let index = 0; index < annotations.length; index++) {\n                            const annotation = annotations[index]\n                            let filePath = ''\n\n                            // Gather citations based on annotation attributes\n                            const file_citation = (annotation as OpenAI.Beta.Threads.Messages.FileCitationAnnotation).file_citation\n\n                            if (file_citation) {\n                                const cited_file = await openai.files.retrieve(file_citation.file_id)\n                                // eslint-disable-next-line no-useless-escape\n                                const fileName = cited_file.filename.split(/[\\/\\\\]/).pop() ?? cited_file.filename\n                                if (!disableFileDownload) {\n                                    filePath = await downloadFile(openAIApiKey, cited_file, fileName, options.chatflowid, options.chatId)\n                                    fileAnnotations.push({\n                                        filePath,\n                                        fileName\n                                    })\n                                }\n                            } else {\n                                const file_path = (annotation as OpenAI.Beta.Threads.Messages.FilePathAnnotation).file_path\n                                if (file_path) {\n                                    const cited_file = await openai.files.retrieve(file_path.file_id)\n                                    // eslint-disable-next-line no-useless-escape\n                                    const fileName = cited_file.filename.split(/[\\/\\\\]/).pop() ?? cited_file.filename\n                                    if (!disableFileDownload) {\n                                        filePath = await downloadFile(\n                                            openAIApiKey,\n                                            cited_file,\n                                            fileName,\n                                            options.chatflowid,\n                                            options.chatId\n                                        )\n                                        fileAnnotations.push({\n                                            filePath,\n                                            fileName\n                                        })\n                                    }\n                                }\n                            }\n\n                            // Replace the text with a footnote\n                            message_content.value = message_content.value.replace(\n                                `${annotation.text}`,\n                                `${disableFileDownload ? '' : filePath}`\n                            )\n                        }\n\n                        returnVal += message_content.value\n                    } else {\n                        returnVal += content.text.value\n                    }\n\n                    returnVal = returnVal.replace(lenticularBracketRegex, '')\n                } else {\n                    const content = assistantMessages[0].content[i] as OpenAI.Beta.Threads.Messages.ImageFileContentBlock\n                    const fileId = content.image_file.file_id\n                    const fileObj = await openai.files.retrieve(fileId)\n\n                    const buffer = await downloadImg(openai, fileId, `${fileObj.filename}.png`, options.chatflowid, options.chatId)\n                    const base64String = Buffer.from(buffer).toString('base64')\n\n                    // TODO: Use a file path and retrieve image on the fly. Storing as base64 to localStorage and database will easily hit limits\n                    const imgHTML = `<img src=\"data:image/png;base64,${base64String}\" width=\"100%\" height=\"max-content\" alt=\"${fileObj.filename}\" /><br/>`\n                    returnVal += imgHTML\n                }\n            }\n\n            let llmOutput = returnVal.replace(imageRegex, '')\n            llmOutput = llmOutput.replace('<br/>', '')\n\n            await analyticHandlers.onLLMEnd(llmIds, llmOutput)\n            await analyticHandlers.onChainEnd(parentIds, messageData, true)\n\n            return {\n                text: returnVal,\n                usedTools,\n                fileAnnotations,\n                assistant: { assistantId: openAIAssistantId, threadId, runId: runThreadId, messages: messageData }\n            }\n        } catch (error) {\n            await analyticHandlers.onChainError(parentIds, error, true)\n            throw new Error(error)\n        }\n    }\n}\n\nconst downloadImg = async (openai: OpenAI, fileId: string, fileName: string, ...paths: string[]) => {\n    const response = await openai.files.content(fileId)\n\n    // Extract the binary data from the Response object\n    const image_data = await response.arrayBuffer()\n\n    // Convert the binary data to a Buffer\n    const image_data_buffer = Buffer.from(image_data)\n    const mime = 'image/png'\n\n    await addSingleFileToStorage(mime, image_data_buffer, fileName, ...paths)\n\n    return image_data_buffer\n}\n\nconst downloadFile = async (openAIApiKey: string, fileObj: any, fileName: string, ...paths: string[]) => {\n    try {\n        const response = await fetch(`https://api.openai.com/v1/files/${fileObj.id}/content`, {\n            method: 'GET',\n            headers: { Accept: '*/*', Authorization: `Bearer ${openAIApiKey}` }\n        })\n\n        if (!response.ok) {\n            throw new Error(`HTTP error! status: ${response.status}`)\n        }\n\n        // Extract the binary data from the Response object\n        const data = await response.arrayBuffer()\n\n        // Convert the binary data to a Buffer\n        const data_buffer = Buffer.from(data)\n        const mime = 'application/octet-stream'\n\n        return await addSingleFileToStorage(mime, data_buffer, fileName, ...paths)\n    } catch (error) {\n        console.error('Error downloading or writing the file:', error)\n        return ''\n    }\n}\n\nconst formatToOpenAIAssistantTool = (tool: any): OpenAI.Beta.FunctionTool => {\n    return {\n        type: 'function',\n        function: {\n            name: tool.name,\n            description: tool.description,\n            parameters: zodToJsonSchema(tool.schema)\n        }\n    }\n}"
}

## ReActAgentChat_Agents

{
  "className": "ReActAgentChat_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'ReAct Agent for Chat Models'\n        this.name = 'reactAgentChat'\n        this.version = 4.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'agent.svg'\n        this.description = 'Agent that uses the ReAct logic to decide what action to take, optimized to be used with Chat Models'\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Allowed Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (messageContent?.length) {\n                // Change model to vision supported\n                visionChatModel.setVisionModel()\n                const oldTemplate = prompt.template as string\n\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: oldTemplate\n                    }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const maxIterations = nodeData.inputs?.maxIterations as string\n        const model = nodeData.inputs?.model as BaseChatModel\n        let tools = nodeData.inputs?.tools as Tool[]\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        const prependMessages = options?.prependMessages\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the ReAct Agent for Chat Models\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        tools = flatten(tools)\n\n        const prompt = await pull<PromptTemplate>('hwchase17/react-chat')\n        let chatPromptTemplate = undefined\n\n        if (llmSupportsVision(model)) {\n            const visionChatModel = model as IVisionChatModal\n            const messageContent = await addImagesToMessages(nodeData, options, model.multiModalOption)\n\n            if (messageContent?.length) {\n                // Change model to vision supported\n                visionChatModel.setVisionModel()\n                const oldTemplate = prompt.template as string\n\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: oldTemplate\n                    }\n                ])\n                msg.inputVariables = prompt.inputVariables\n                chatPromptTemplate = ChatPromptTemplate.fromMessages([msg])\n            } else {\n                // revert to previous values if image upload is empty\n                visionChatModel.revertToOriginalModel()\n            }\n        }\n\n        const agent = await createReactAgent({\n            llm: model,\n            tools,\n            prompt: chatPromptTemplate ?? prompt\n        })\n\n        const executor = new AgentExecutor({\n            agent,\n            tools,\n            verbose: process.env.DEBUG === 'true',\n            maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n        })\n\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        const chatHistory = ((await memory.getChatMessages(this.sessionId, false, prependMessages)) as IMessage[]) ?? []\n        const chatHistoryString = chatHistory.map((hist) => hist.message).join('\\\\n')\n\n        const result = await executor.invoke({ input, chat_history: chatHistoryString }, { callbacks })\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: result?.output,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        return result?.output\n    }\n}"
}

## ReActAgentLLM_Agents

{
  "className": "ReActAgentLLM_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'ReAct Agent for LLMs'\n        this.name = 'reactAgentLLM'\n        this.version = 2.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'agent.svg'\n        this.description = 'Agent that uses the ReAct logic to decide what action to take, optimized to be used with LLMs'\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Allowed Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the ReAct Agent for LLMs\n                input = await checkInputs(moderations, input)\n            }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const maxIterations = nodeData.inputs?.maxIterations as string\n        let tools = nodeData.inputs?.tools as Tool[]\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the ReAct Agent for LLMs\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        tools = flatten(tools)\n\n        const prompt = await pull<PromptTemplate>('hwchase17/react')\n\n        const agent = await createReactAgent({\n            llm: model,\n            tools,\n            prompt\n        })\n\n        const executor = new AgentExecutor({\n            agent,\n            tools,\n            verbose: process.env.DEBUG === 'true' ? true : false,\n            maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n        })\n\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        const result = await executor.invoke({ input }, { callbacks })\n\n        return result?.output\n    }\n}"
}

## ToolAgent_Agents

{
  "className": "ToolAgent_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Tool Agent'\n        this.name = 'toolAgent'\n        this.version = 2.0\n        this.type = 'AgentExecutor'\n        this.category = 'Agents'\n        this.icon = 'toolAgent.png'\n        this.description = `Agent that uses Function Calling to pick the tools and args to call`\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (model.bindTools === undefined) {\n        throw new Error(`This agent requires that the \"bindTools()\" method be implemented on the input model.`)\n    }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                if (isStreamable)\n                    streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        const isStreamable = options.socketIO && options.socketIOClientId\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the OpenAI Function Agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                if (isStreamable)\n                    streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const executor = await prepareAgent(nodeData, options, { sessionId: this.sessionId, chatId: options.chatId, input })\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        let res: ChainValues = {}\n        let sourceDocuments: ICommonObject[] = []\n        let usedTools: IUsedTool[] = []\n\n        if (isStreamable) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, handler, ...callbacks] })\n            if (res.sourceDocuments) {\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', flatten(res.sourceDocuments))\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                options.socketIO.to(options.socketIOClientId).emit('usedTools', res.usedTools)\n                usedTools = res.usedTools\n            }\n            // If the tool is set to returnDirect, stream the output to the client\n            if (res.usedTools && res.usedTools.length) {\n                let inputTools = nodeData.inputs?.tools\n                inputTools = flatten(inputTools)\n                for (const tool of res.usedTools) {\n                    const inputTool = inputTools.find((inputTool: Tool) => inputTool.name === tool.tool)\n                    if (inputTool && inputTool.returnDirect) {\n                        options.socketIO.to(options.socketIOClientId).emit('token', tool.toolOutput)\n                    }\n                }\n            }\n        } else {\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, ...callbacks] })\n            if (res.sourceDocuments) {\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                usedTools = res.usedTools\n            }\n        }\n\n        let output = res?.output\n        if (Array.isArray(output)) {\n            output = output[0]?.text || ''\n        } else if (typeof output === 'object') {\n            output = output?.text || ''\n        }\n\n        // Claude 3 Opus tends to spit out <thinking>..</thinking> as well, discard that in final output\n        const regexPattern: RegExp = /<thinking>[\\s\\S]*?<\\/thinking>/\n        const matches: RegExpMatchArray | null = output.match(regexPattern)\n        if (matches) {\n            for (const match of matches) {\n                output = output.replace(match, '')\n            }\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: output,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        let finalRes = output\n\n        if (sourceDocuments.length || usedTools.length) {\n            const finalRes: ICommonObject = { text: output }\n            if (sourceDocuments.length) {\n                finalRes.sourceDocuments = flatten(sourceDocuments)\n            }\n            if (usedTools.length) {\n                finalRes.usedTools = usedTools\n            }\n            return finalRes\n        }\n\n        return finalRes\n    }\n}\n\nconst prepareAgent = async (\n    nodeData: INodeData,\n    options: ICommonObject,\n    flowObj: { sessionId?: string; chatId?: string; input?: string }\n) => {\n    const model = nodeData.inputs?.model as BaseChatModel\n    const maxIterations = nodeData.inputs?.maxIterations as string\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const systemMessage = nodeData.inputs?.systemMessage as string\n    let tools = nodeData.inputs?.tools\n    tools = flatten(tools)\n    const memoryKey = memory.memoryKey ? memory.memoryKey : 'chat_history'\n    const inputKey = memory.inputKey ? memory.inputKey : 'input'\n    const prependMessages = options?.prependMessages\n\n    let prompt = ChatPromptTemplate.fromMessages([\n        ['system', systemMessage],\n        new MessagesPlaceholder(memoryKey),\n        ['human', `{${inputKey}}`],\n        new MessagesPlaceholder('agent_scratchpad')\n    ])\n\n    let promptVariables = {}\n    const chatPromptTemplate = nodeData.inputs?.chatPromptTemplate as ChatPromptTemplate\n    if (chatPromptTemplate && chatPromptTemplate.promptMessages.length) {\n        const humanPrompt = chatPromptTemplate.promptMessages[chatPromptTemplate.promptMessages.length - 1]\n        const messages = [\n            ...chatPromptTemplate.promptMessages.slice(0, -1),\n            new MessagesPlaceholder(memoryKey),\n            humanPrompt,\n            new MessagesPlaceholder('agent_scratchpad')\n        ]\n        prompt = ChatPromptTemplate.fromMessages(messages)\n        if ((chatPromptTemplate as any).promptValues) {\n            const promptValuesRaw = (chatPromptTemplate as any).promptValues\n            const promptValues = handleEscapeCharacters(promptValuesRaw, true)\n            for (const val in promptValues) {\n                promptVariables = {\n                    ...promptVariables,\n                    [val]: () => {\n                        return promptValues[val]\n                    }\n                }\n            }\n        }\n    }\n\n    if (llmSupportsVision(model)) {\n        const visionChatModel = model as IVisionChatModal\n        const messageContent = await addImagesToMessages(nodeData, options, model.multiModalOption)\n\n        if (messageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            // Pop the `agent_scratchpad` MessagePlaceHolder\n            let messagePlaceholder = prompt.promptMessages.pop() as MessagesPlaceholder\n            if (prompt.promptMessages.at(-1) instanceof HumanMessagePromptTemplate) {\n                const lastMessage = prompt.promptMessages.pop() as HumanMessagePromptTemplate\n                const template = (lastMessage.prompt as PromptTemplate).template as string\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: template\n                    }\n                ])\n                msg.inputVariables = lastMessage.inputVariables\n                prompt.promptMessages.push(msg)\n            }\n\n            // Add the `agent_scratchpad` MessagePlaceHolder back\n            prompt.promptMessages.push(messagePlaceholder)\n        } else {\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    if (model.bindTools === undefined) {\n        throw new Error(`This agent requires that the \"bindTools()\" method be implemented on the input model.`)\n    }\n\n    const modelWithTools = model.bindTools(tools)\n\n    const runnableAgent = RunnableSequence.from([\n        {\n            [inputKey]: (i: { input: string; steps: ToolsAgentStep[] }) => i.input,\n            agent_scratchpad: (i: { input: string; steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(i.steps),\n            [memoryKey]: async (_: { input: string; steps: ToolsAgentStep[] }) => {\n                const messages = (await memory.getChatMessages(flowObj?.sessionId, true, prependMessages)) as BaseMessage[]\n                return messages ?? []\n            },\n            ...promptVariables\n        },\n        prompt,\n        modelWithTools,\n        new ToolCallingAgentOutputParser()\n    ])\n\n    const executor = AgentExecutor.fromAgentAndTools({\n        agent: runnableAgent,\n        tools,\n        sessionId: flowObj?.sessionId,\n        chatId: flowObj?.chatId,\n        input: flowObj?.input,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n    })\n\n    return executor\n}"
}

## XMLAgent_Agents

{
  "className": "XMLAgent_Agents",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'XML Agent'\n        this.name = 'xmlAgent'\n        this.version = 2.0\n        this.type = 'XMLAgent'\n        this.category = 'Agents'\n        this.icon = 'xmlagent.svg'\n        this.description = `Agent that is designed for LLMs that are good for reasoning/writing XML (e.g: Anthropic Claude)`\n        this.baseClasses = [this.type, ...getBaseClasses(AgentExecutor)]\n        this.inputs = [\n            {\n                label: 'Tools',\n                name: 'tools',\n                type: 'Tool',\n                list: true\n            }",
  "if": "if (message.type === 'userMessage') {\n            chatHistoryMsgTxt += `\\\\nHuman:${message.message}",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "for": "for (const message of messages) {\n        if (message.type === 'apiMessage') {\n            chatHistoryMsgTxt += `\\\\nAI:${message.message}",
  "outsideClass_defaultSystemMessage": "const defaultSystemMessage = `You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}`",
  "outsideClass_memory": "const memory = nodeData.inputs?.memory as FlowiseMemory\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the OpenAI Function Agent\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const executor = await prepareAgent(nodeData, options, { sessionId: this.sessionId, chatId: options.chatId, input })\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        let res: ChainValues = {}\n        let sourceDocuments: ICommonObject[] = []\n        let usedTools: IUsedTool[] = []\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, handler, ...callbacks] })\n            if (res.sourceDocuments) {\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', flatten(res.sourceDocuments))\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                options.socketIO.to(options.socketIOClientId).emit('usedTools', res.usedTools)\n                usedTools = res.usedTools\n            }\n            // If the tool is set to returnDirect, stream the output to the client\n            if (res.usedTools && res.usedTools.length) {\n                let inputTools = nodeData.inputs?.tools\n                inputTools = flatten(inputTools)\n                for (const tool of res.usedTools) {\n                    const inputTool = inputTools.find((inputTool: Tool) => inputTool.name === tool.tool)\n                    if (inputTool && inputTool.returnDirect) {\n                        options.socketIO.to(options.socketIOClientId).emit('token', tool.toolOutput)\n                    }\n                }\n            }\n        } else {\n            res = await executor.invoke({ input }, { callbacks: [loggerHandler, ...callbacks] })\n            if (res.sourceDocuments) {\n                sourceDocuments = res.sourceDocuments\n            }\n            if (res.usedTools) {\n                usedTools = res.usedTools\n            }\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: res?.output,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        let finalRes = res?.output\n\n        if (sourceDocuments.length || usedTools.length) {\n            finalRes = { text: res?.output }\n            if (sourceDocuments.length) {\n                finalRes.sourceDocuments = flatten(sourceDocuments)\n            }\n            if (usedTools.length) {\n                finalRes.usedTools = usedTools\n            }\n            return finalRes\n        }\n\n        return finalRes\n    }\n}\n\nconst prepareAgent = async (\n    nodeData: INodeData,\n    options: ICommonObject,\n    flowObj: { sessionId?: string; chatId?: string; input?: string }\n) => {\n    const model = nodeData.inputs?.model as BaseChatModel\n    const maxIterations = nodeData.inputs?.maxIterations as string\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const systemMessage = nodeData.inputs?.systemMessage as string\n    let tools = nodeData.inputs?.tools\n    tools = flatten(tools)\n    const inputKey = memory.inputKey ? memory.inputKey : 'input'\n    const memoryKey = memory.memoryKey ? memory.memoryKey : 'chat_history'\n    const prependMessages = options?.prependMessages\n\n    let promptMessage = systemMessage ? systemMessage : defaultSystemMessage\n    if (memory.memoryKey) promptMessage = promptMessage.replaceAll('{chat_history}', `{${memory.memoryKey}}`)\n    if (memory.inputKey) promptMessage = promptMessage.replaceAll('{input}', `{${memory.inputKey}}`)\n\n    const prompt = ChatPromptTemplate.fromMessages([\n        HumanMessagePromptTemplate.fromTemplate(promptMessage),\n        new MessagesPlaceholder('agent_scratchpad')\n    ])\n\n    const missingVariables = ['tools', 'agent_scratchpad'].filter((v) => !prompt.inputVariables.includes(v))\n\n    if (missingVariables.length > 0) {\n        throw new Error(`Provided prompt is missing required input variables: ${JSON.stringify(missingVariables)}`)\n    }\n\n    const llmWithStop = model.bind({ stop: ['</tool_input>', '</final_answer>'] })\n\n    const messages = (await memory.getChatMessages(flowObj.sessionId, false, prependMessages)) as IMessage[]\n    let chatHistoryMsgTxt = ''\n    for (const message of messages) {\n        if (message.type === 'apiMessage') {\n            chatHistoryMsgTxt += `\\\\nAI:${message.message}`\n        } else if (message.type === 'userMessage') {\n            chatHistoryMsgTxt += `\\\\nHuman:${message.message}`\n        }\n    }\n\n    const runnableAgent = RunnableSequence.from([\n        {\n            [inputKey]: (i: { input: string; tools: Tool[]; steps: AgentStep[] }) => i.input,\n            agent_scratchpad: (i: { input: string; tools: Tool[]; steps: AgentStep[] }) => formatLogToMessage(i.steps),\n            tools: (_: { input: string; tools: Tool[]; steps: AgentStep[] }) =>\n                tools.map((tool: Tool) => `${tool.name}: ${tool.description}`),\n            [memoryKey]: (_: { input: string; tools: Tool[]; steps: AgentStep[] }) => chatHistoryMsgTxt\n        },\n        prompt,\n        llmWithStop,\n        new XMLAgentOutputParser()\n    ])\n\n    const executor = AgentExecutor.fromAgentAndTools({\n        agent: runnableAgent,\n        tools,\n        sessionId: flowObj?.sessionId,\n        chatId: flowObj?.chatId,\n        input: flowObj?.input,\n        isXML: true,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n    })\n\n    return executor\n}"
}

## LangFuse_Analytic

{
  "className": "LangFuse_Analytic",
  "constructor": "constructor() {\n        this.label = 'LangFuse'\n        this.name = 'langFuse'\n        this.version = 1.0\n        this.type = 'LangFuse'\n        this.icon = 'Langfuse.svg'\n        this.category = 'Analytic'\n        this.baseClasses = [this.type]\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['langfuseApi']\n        }"
}

## LangSmith_Analytic

{
  "className": "LangSmith_Analytic",
  "constructor": "constructor() {\n        this.label = 'LangSmith'\n        this.name = 'langSmith'\n        this.version = 1.0\n        this.type = 'LangSmith'\n        this.icon = 'langchain.png'\n        this.category = 'Analytic'\n        this.baseClasses = [this.type]\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['langsmithApi']\n        }"
}

## LangWatch_Analytic

{
  "className": "LangWatch_Analytic",
  "constructor": "constructor() {\n        this.label = 'LangWatch'\n        this.name = 'LangWatch'\n        this.version = 1.0\n        this.type = 'LangWatch'\n        this.icon = 'LangWatch.svg'\n        this.category = 'Analytic'\n        this.baseClasses = [this.type]\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['langwatchApi']\n        }"
}

## Lunary_Analytic

{
  "className": "Lunary_Analytic",
  "constructor": "constructor() {\n        this.label = 'Lunary'\n        this.name = 'lunary'\n        this.version = 1.0\n        this.type = 'Lunary'\n        this.icon = 'Lunary.svg'\n        this.category = 'Analytic'\n        this.baseClasses = [this.type]\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['lunaryApi']\n        }"
}

## InMemoryCache

{
  "className": "InMemoryCache",
  "init": "[Function: init]",
  "constructor": "constructor(map: Map<string, any>) {\n        super()\n        this.cache = map\n    }",
  "outsideClass_memoryMap": "const memoryMap = options.cachePool.getLLMCache(options.chatflowid) ?? new Map()\n        const inMemCache = new InMemoryCacheExtended(memoryMap)\n\n        inMemCache.lookup = async (prompt: string, llmKey: string): Promise<any | null> => {\n            const memory = options.cachePool.getLLMCache(options.chatflowid) ?? inMemCache.cache\n            return Promise.resolve(memory.get(getCacheKey(prompt, llmKey)) ?? null)\n        }\n\n        inMemCache.update = async (prompt: string, llmKey: string, value: any): Promise<void> => {\n            inMemCache.cache.set(getCacheKey(prompt, llmKey), value)\n            options.cachePool.addLLMCache(options.chatflowid, inMemCache.cache)\n        }\n        return inMemCache\n    }\n}\n\nconst getCacheKey = (...strings: string[]): string => hash(strings.join('_'))"
}

## InMemoryEmbeddingCache

{
  "className": "InMemoryEmbeddingCache",
  "init": "[Function: init]",
  "constructor": "constructor(map: Record<string, T>) {\n        super()\n        this.store = map\n    }",
  "for": "for (const key of keys) {\n            if (prefix === undefined || key.startsWith(prefix)) {\n                yield key\n            }",
  "mget": "mget(keys: string[]) {\n        return keys.map((key) => this.store[key])\n    }",
  "outsideClass_namespace": "const namespace = nodeData.inputs?.namespace as string\n        const underlyingEmbeddings = nodeData.inputs?.embeddings as Embeddings\n        const memoryMap = options.cachePool.getEmbeddingCache(options.chatflowid) ?? {}\n        const inMemCache = new InMemoryEmbeddingCacheExtended(memoryMap)\n\n        inMemCache.mget = async (keys: string[]) => {\n            const memory = options.cachePool.getEmbeddingCache(options.chatflowid) ?? inMemCache.store\n            return keys.map((key) => memory[key])\n        }\n\n        inMemCache.mset = async (keyValuePairs: [string, any][]): Promise<void> => {\n            for (const [key, value] of keyValuePairs) {\n                inMemCache.store[key] = value\n            }\n            options.cachePool.addEmbeddingCache(options.chatflowid, inMemCache.store)\n        }\n\n        inMemCache.mdelete = async (keys: string[]): Promise<void> => {\n            for (const key of keys) {\n                delete inMemCache.store[key]\n            }\n            options.cachePool.addEmbeddingCache(options.chatflowid, inMemCache.store)\n        }\n\n        return CacheBackedEmbeddings.fromBytesStore(underlyingEmbeddings, inMemCache, {\n            namespace: namespace\n        })\n    }\n}",
  "outsideClass_keys": "const keys = Object.keys(this.store)\n        for (const key of keys) {\n            if (prefix === undefined || key.startsWith(prefix)) {\n                yield key\n            }\n        }\n    }\n}"
}

## MomentoCache

{
  "className": "MomentoCache",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Momento Cache'\n        this.name = 'momentoCache'\n        this.version = 1.0\n        this.type = 'MomentoCache'\n        this.description = 'Cache LLM response using Momento, a distributed, serverless cache'\n        this.icon = 'Momento.svg'\n        this.category = 'Cache'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainMomentoCache)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: true,\n            credentialNames: ['momentoCacheApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('momentoApiKey', credentialData, nodeData)\n        const cacheName = getCredentialParam('momentoCache', credentialData, nodeData)\n\n        // See https://github.com/momentohq/client-sdk-javascript for connection options\n        const client = new CacheClient({\n            configuration: Configurations.Laptop.v1(),\n            credentialProvider: CredentialProvider.fromString({\n                apiKey: apiKey\n            }),\n            defaultTtlSeconds: 60 * 60 * 24\n        })\n\n        let momentoCache = await LangchainMomentoCache.fromProps({\n            client,\n            cacheName: cacheName\n        })\n        return momentoCache\n    }\n}"
}

## RedisCache

{
  "className": "RedisCache",
  "init": "[Function: init]",
  "if": "if (storedGeneration.message !== undefined) {\n        return {\n            text: storedGeneration.text,\n            message: mapStoredMessageToChatMessage(storedGeneration.message)\n        }",
  "constructor": "constructor() {\n        this.label = 'Redis Cache'\n        this.name = 'redisCache'\n        this.version = 1.0\n        this.type = 'RedisCache'\n        this.description = 'Cache LLM response in Redis, useful for sharing cache across multiple processes or servers'\n        this.icon = 'redis.svg'\n        this.category = 'Cache'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainRedisCache)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: true,\n            credentialNames: ['redisCacheApi', 'redisCacheUrlApi']\n        }",
  "while": "while (value) {\n                const storedGeneration = JSON.parse(value)\n                generations.push(deserializeStoredGeneration(storedGeneration))\n                idx += 1\n                key = getCacheKey(prompt, llmKey, String(idx))\n                value = await client.get(key)\n            }",
  "for": "for (let i = 0; i < value.length; i += 1) {\n                const key = getCacheKey(prompt, llmKey, String(i))\n                if (ttl) {\n                    await client.set(key, JSON.stringify(serializeGeneration(value[i])), 'PX', parseInt(ttl, 10))\n                }",
  "outsideClass_getRedisClientbyOption": "const getRedisClientbyOption = (option: RedisOptions) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    } else if (redisClientSingleton && !isEqual(option, redisClientOption)) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}\n\nconst getRedisClientbyUrl = (url: string) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    } else if (redisClientSingleton && url !== redisClientUrl) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}",
  "outsideClass_ttl": "const ttl = nodeData.inputs?.ttl as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const redisUrl = getCredentialParam('redisUrl', credentialData, nodeData)\n\n        let client: Redis\n        if (!redisUrl || redisUrl === '') {\n            const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n            const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n            const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n            const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n            const sslEnabled = getCredentialParam('redisCacheSslEnabled', credentialData, nodeData)\n\n            const tlsOptions = sslEnabled === true ? { tls: { rejectUnauthorized: false } } : {}\n\n            client = getRedisClientbyOption({\n                port: portStr ? parseInt(portStr) : 6379,\n                host,\n                username,\n                password,\n                ...tlsOptions\n            })\n        } else {\n            client = getRedisClientbyUrl(redisUrl)\n        }\n\n        const redisClient = new LangchainRedisCache(client)\n\n        redisClient.lookup = async (prompt: string, llmKey: string) => {\n            let idx = 0\n            let key = getCacheKey(prompt, llmKey, String(idx))\n            let value = await client.get(key)\n            const generations: Generation[] = []\n\n            while (value) {\n                const storedGeneration = JSON.parse(value)\n                generations.push(deserializeStoredGeneration(storedGeneration))\n                idx += 1\n                key = getCacheKey(prompt, llmKey, String(idx))\n                value = await client.get(key)\n            }\n\n            return generations.length > 0 ? generations : null\n        }\n\n        redisClient.update = async (prompt: string, llmKey: string, value: Generation[]) => {\n            for (let i = 0; i < value.length; i += 1) {\n                const key = getCacheKey(prompt, llmKey, String(i))\n                if (ttl) {\n                    await client.set(key, JSON.stringify(serializeGeneration(value[i])), 'PX', parseInt(ttl, 10))\n                } else {\n                    await client.set(key, JSON.stringify(serializeGeneration(value[i])))\n                }\n            }\n        }\n\n        return redisClient\n    }\n}\n\nconst getCacheKey = (...strings: string[]): string => hash(strings.join('_'))\nconst deserializeStoredGeneration = (storedGeneration: StoredGeneration) => {\n    if (storedGeneration.message !== undefined) {\n        return {\n            text: storedGeneration.text,\n            message: mapStoredMessageToChatMessage(storedGeneration.message)\n        }\n    } else {\n        return { text: storedGeneration.text }\n    }\n}\nconst serializeGeneration = (generation: Generation) => {\n    const serializedValue: StoredGeneration = {\n        text: generation.text\n    }\n    if ((generation as ChatGeneration).message !== undefined) {\n        serializedValue.message = (generation as ChatGeneration).message.toDict()\n    }\n    return serializedValue\n}"
}

## RedisEmbeddingsCache

{
  "className": "RedisEmbeddingsCache",
  "init": "[Function: init]",
  "if": "if (!redisUrl || redisUrl === '') {\n            const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n            const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n            const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n            const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n            const sslEnabled = getCredentialParam('redisCacheSslEnabled', credentialData, nodeData)\n\n            const tlsOptions = sslEnabled === true ? { tls: { rejectUnauthorized: false }",
  "constructor": "constructor() {\n        this.label = 'Redis Embeddings Cache'\n        this.name = 'redisEmbeddingsCache'\n        this.version = 1.0\n        this.type = 'RedisEmbeddingsCache'\n        this.description = 'Cache generated Embeddings in Redis to avoid needing to recompute them.'\n        this.icon = 'redis.svg'\n        this.category = 'Cache'\n        this.baseClasses = [this.type, ...getBaseClasses(CacheBackedEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: true,\n            credentialNames: ['redisCacheApi', 'redisCacheUrlApi']\n        }",
  "outsideClass_getRedisClientbyOption": "const getRedisClientbyOption = (option: RedisOptions) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    } else if (redisClientSingleton && !isEqual(option, redisClientOption)) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}\n\nconst getRedisClientbyUrl = (url: string) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    } else if (redisClientSingleton && url !== redisClientUrl) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}",
  "outsideClass_namespace": "const namespace = nodeData.inputs?.namespace as string\n        const underlyingEmbeddings = nodeData.inputs?.embeddings as Embeddings\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const redisUrl = getCredentialParam('redisUrl', credentialData, nodeData)\n\n        let client: Redis\n        if (!redisUrl || redisUrl === '') {\n            const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n            const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n            const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n            const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n            const sslEnabled = getCredentialParam('redisCacheSslEnabled', credentialData, nodeData)\n\n            const tlsOptions = sslEnabled === true ? { tls: { rejectUnauthorized: false } } : {}\n\n            client = getRedisClientbyOption({\n                port: portStr ? parseInt(portStr) : 6379,\n                host,\n                username,\n                password,\n                ...tlsOptions\n            })\n        } else {\n            client = getRedisClientbyUrl(redisUrl)\n        }\n\n        ttl ??= '3600'\n        let ttlNumber = parseInt(ttl, 10)\n        const redisStore = new RedisByteStore({\n            client: client,\n            ttl: ttlNumber\n        })\n\n        return CacheBackedEmbeddings.fromBytesStore(underlyingEmbeddings, redisStore, {\n            namespace: namespace\n        })\n    }\n}"
}

## UpstashRedisCache

{
  "className": "UpstashRedisCache",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Upstash Redis Cache'\n        this.name = 'upstashRedisCache'\n        this.version = 1.0\n        this.type = 'UpstashRedisCache'\n        this.description = 'Cache LLM response in Upstash Redis, serverless data for Redis and Kafka'\n        this.icon = 'Upstash.svg'\n        this.category = 'Cache'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainUpstashRedisCache)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: true,\n            credentialNames: ['upstashRedisApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const upstashConnectionUrl = getCredentialParam('upstashConnectionUrl', credentialData, nodeData)\n        const upstashToken = getCredentialParam('upstashConnectionToken', credentialData, nodeData)\n\n        const cache = new LangchainUpstashRedisCache({\n            config: {\n                url: upstashConnectionUrl,\n                token: upstashToken\n            }\n        })\n        return cache\n    }\n}"
}

## GETApiChain_Chains

{
  "className": "GETApiChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'GET API Chain'\n        this.name = 'getApiChain'\n        this.version = 1.0\n        this.type = 'GETApiChain'\n        this.icon = 'get.svg'\n        this.category = 'Chains'\n        this.description = 'Chain to run queries against GET API'\n        this.baseClasses = [this.type, ...getBaseClasses(APIChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        }",
  "outsideClass_API_URL_RAW_PROMPT_TEMPLATE": "const API_URL_RAW_PROMPT_TEMPLATE = `You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate the full API url to call for answering the user question.\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\nAPI url:`\n\nexport const API_RESPONSE_RAW_PROMPT_TEMPLATE =\n    'Given this {api_response} response for {api_url}. use the given response to answer this {question}'",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const apiDocs = nodeData.inputs?.apiDocs as string\n        const headers = nodeData.inputs?.headers as string\n        const urlPrompt = nodeData.inputs?.urlPrompt as string\n        const ansPrompt = nodeData.inputs?.ansPrompt as string\n\n        const chain = await getAPIChain(apiDocs, model, headers, urlPrompt, ansPrompt)\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string> {\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const apiDocs = nodeData.inputs?.apiDocs as string\n        const headers = nodeData.inputs?.headers as string\n        const urlPrompt = nodeData.inputs?.urlPrompt as string\n        const ansPrompt = nodeData.inputs?.ansPrompt as string\n\n        const chain = await getAPIChain(apiDocs, model, headers, urlPrompt, ansPrompt)\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        } else {\n            const res = await chain.run(input, [loggerHandler, ...callbacks])\n            return res\n        }\n    }\n}\n\nconst getAPIChain = async (documents: string, llm: BaseLanguageModel, headers: string, urlPrompt: string, ansPrompt: string) => {\n    const apiUrlPrompt = new PromptTemplate({\n        inputVariables: ['api_docs', 'question'],\n        template: urlPrompt ? urlPrompt : API_URL_RAW_PROMPT_TEMPLATE\n    })\n\n    const apiResponsePrompt = new PromptTemplate({\n        inputVariables: ['api_docs', 'question', 'api_url', 'api_response'],\n        template: ansPrompt ? ansPrompt : API_RESPONSE_RAW_PROMPT_TEMPLATE\n    })\n\n    const chain = APIChain.fromLLMAndAPIDocs(llm, documents, {\n        apiUrlPrompt,\n        apiResponsePrompt,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        headers: typeof headers === 'object' ? headers : headers ? JSON.parse(headers) : {}\n    })\n    return chain\n}"
}

## OpenApiChain_Chains

{
  "className": "OpenApiChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'OpenAPI Chain'\n        this.name = 'openApiChain'\n        this.version = 2.0\n        this.type = 'OpenAPIChain'\n        this.icon = 'openapi.svg'\n        this.category = 'Chains'\n        this.description = 'Chain that automatically select and call APIs based only on an OpenAPI spec'\n        this.baseClasses = [this.type, ...getBaseClasses(APIChain)]\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel'\n            }",
  "if": "if (yamlLink) {\n        yamlString = yamlLink\n    }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_chain": "const chain = await initChain(nodeData, options)\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the OpenAPI chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        } else {\n            const res = await chain.run(input, [loggerHandler, ...callbacks])\n            return res\n        }\n    }\n}\n\nconst initChain = async (nodeData: INodeData, options: ICommonObject) => {\n    const model = nodeData.inputs?.model as BaseChatModel\n    const headers = nodeData.inputs?.headers as string\n    const yamlLink = nodeData.inputs?.yamlLink as string\n    const yamlFileBase64 = nodeData.inputs?.yamlFile as string\n\n    let yamlString = ''\n\n    if (yamlLink) {\n        yamlString = yamlLink\n    } else {\n        if (yamlFileBase64.startsWith('FILE-STORAGE::')) {\n            const file = yamlFileBase64.replace('FILE-STORAGE::', '')\n            const chatflowid = options.chatflowid\n            const fileData = await getFileFromStorage(file, chatflowid)\n            yamlString = fileData.toString()\n        } else {\n            const splitDataURI = yamlFileBase64.split(',')\n            splitDataURI.pop()\n            const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n            yamlString = bf.toString('utf-8')\n        }\n    }\n\n    return await createOpenAPIChain(yamlString, {\n        llm: model,\n        headers: typeof headers === 'object' ? headers : headers ? JSON.parse(headers) : {},\n        verbose: process.env.DEBUG === 'true' ? true : false\n    })\n}"
}

## POSTApiChain_Chains

{
  "className": "POSTApiChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'POST API Chain'\n        this.name = 'postApiChain'\n        this.version = 1.0\n        this.type = 'POSTApiChain'\n        this.icon = 'post.svg'\n        this.category = 'Chains'\n        this.description = 'Chain to run queries against POST API'\n        this.baseClasses = [this.type, ...getBaseClasses(APIChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const apiDocs = nodeData.inputs?.apiDocs as string\n        const headers = nodeData.inputs?.headers as string\n        const urlPrompt = nodeData.inputs?.urlPrompt as string\n        const ansPrompt = nodeData.inputs?.ansPrompt as string\n\n        const chain = await getAPIChain(apiDocs, model, headers, urlPrompt, ansPrompt)\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string> {\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const apiDocs = nodeData.inputs?.apiDocs as string\n        const headers = nodeData.inputs?.headers as string\n        const urlPrompt = nodeData.inputs?.urlPrompt as string\n        const ansPrompt = nodeData.inputs?.ansPrompt as string\n\n        const chain = await getAPIChain(apiDocs, model, headers, urlPrompt, ansPrompt)\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        } else {\n            const res = await chain.run(input, [loggerHandler, ...callbacks])\n            return res\n        }\n    }\n}\n\nconst getAPIChain = async (documents: string, llm: BaseLanguageModel, headers: string, urlPrompt: string, ansPrompt: string) => {\n    const apiUrlPrompt = new PromptTemplate({\n        inputVariables: ['api_docs', 'question'],\n        template: urlPrompt ? urlPrompt : API_URL_RAW_PROMPT_TEMPLATE\n    })\n\n    const apiResponsePrompt = new PromptTemplate({\n        inputVariables: ['api_docs', 'question', 'api_url_body', 'api_response'],\n        template: ansPrompt ? ansPrompt : API_RESPONSE_RAW_PROMPT_TEMPLATE\n    })\n\n    const chain = APIChain.fromLLMAndAPIDocs(llm, documents, {\n        apiUrlPrompt,\n        apiResponsePrompt,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        headers: typeof headers === 'object' ? headers : headers ? JSON.parse(headers) : {}\n    })\n    return chain\n}"
}

## ConversationChain_Chains

{
  "className": "ConversationChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Conversation Chain'\n        this.name = 'conversationChain'\n        this.version = 3.0\n        this.type = 'ConversationChain'\n        this.icon = 'conv.svg'\n        this.category = 'Chains'\n        this.description = 'Chat models specific conversational chain with memory'\n        this.baseClasses = [this.type, ...getBaseClasses(ConversationChain)]\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel'\n            }",
  "if": "if (promptValuesRaw) {\n        const promptValues = handleEscapeCharacters(promptValuesRaw, true)\n        for (const val in promptValues) {\n            promptVariables = {\n                ...promptVariables,\n                [val]: () => {\n                    return promptValues[val]\n                }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_inputKey": "const inputKey = 'input'",
  "outsideClass_chain": "const chain = prepareChain(nodeData, options, this.sessionId)\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const memory = nodeData.inputs?.memory\n\n        const chain = await prepareChain(nodeData, options, this.sessionId)\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the LLM chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const additionalCallback = await additionalCallbacks(nodeData, options)\n\n        let res = ''\n        let callbacks = [loggerHandler, ...additionalCallback]\n\n        if (process.env.DEBUG === 'true') {\n            callbacks.push(new LCConsoleCallbackHandler())\n        }\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            callbacks.push(handler)\n            res = await chain.invoke({ input }, { callbacks })\n        } else {\n            res = await chain.invoke({ input }, { callbacks })\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: res,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        return res\n    }\n}\n\nconst prepareChatPrompt = (nodeData: INodeData, humanImageMessages: MessageContentImageUrl[]) => {\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const prompt = nodeData.inputs?.systemMessagePrompt as string\n    const chatPromptTemplate = nodeData.inputs?.chatPromptTemplate as ChatPromptTemplate\n    let model = nodeData.inputs?.model as BaseChatModel\n\n    if (chatPromptTemplate && chatPromptTemplate.promptMessages.length) {\n        const sysPrompt = chatPromptTemplate.promptMessages[0]\n        const humanPrompt = chatPromptTemplate.promptMessages[chatPromptTemplate.promptMessages.length - 1]\n        const messages = [sysPrompt, new MessagesPlaceholder(memory.memoryKey ?? 'chat_history'), humanPrompt]\n\n        // OpenAI works better when separate images into standalone human messages\n        if (model instanceof ChatOpenAI && humanImageMessages.length) {\n            messages.push(new HumanMessage({ content: [...humanImageMessages] }))\n        } else if (humanImageMessages.length) {\n            const lastMessage = messages.pop() as HumanMessagePromptTemplate\n            const template = (lastMessage.prompt as PromptTemplate).template as string\n            const msg = HumanMessagePromptTemplate.fromTemplate([\n                ...humanImageMessages,\n                {\n                    text: template\n                }\n            ])\n            msg.inputVariables = lastMessage.inputVariables\n            messages.push(msg)\n        }\n\n        const chatPrompt = ChatPromptTemplate.fromMessages(messages)\n        if ((chatPromptTemplate as any).promptValues) {\n            // @ts-ignore\n            chatPrompt.promptValues = (chatPromptTemplate as any).promptValues\n        }\n\n        return chatPrompt\n    }\n\n    const messages: BaseMessagePromptTemplateLike[] = [\n        SystemMessagePromptTemplate.fromTemplate(prompt ? prompt : systemMessage),\n        new MessagesPlaceholder(memory.memoryKey ?? 'chat_history'),\n        HumanMessagePromptTemplate.fromTemplate(`{${inputKey}}`)\n    ]\n\n    // OpenAI works better when separate images into standalone human messages\n    if (model instanceof ChatOpenAI && humanImageMessages.length) {\n        messages.push(new HumanMessage({ content: [...humanImageMessages] }))\n    } else if (humanImageMessages.length) {\n        messages.pop()\n        messages.push(HumanMessagePromptTemplate.fromTemplate([`{${inputKey}}`, ...humanImageMessages]))\n    }\n\n    const chatPrompt = ChatPromptTemplate.fromMessages(messages)\n\n    return chatPrompt\n}\n\nconst prepareChain = async (nodeData: INodeData, options: ICommonObject, sessionId?: string) => {\n    let model = nodeData.inputs?.model as BaseChatModel\n    const memory = nodeData.inputs?.memory as FlowiseMemory\n    const memoryKey = memory.memoryKey ?? 'chat_history'\n    const prependMessages = options?.prependMessages\n\n    let messageContent: MessageContentImageUrl[] = []\n    if (llmSupportsVision(model)) {\n        messageContent = await addImagesToMessages(nodeData, options, model.multiModalOption)\n        const visionChatModel = model as IVisionChatModal\n        if (messageContent?.length) {\n            visionChatModel.setVisionModel()\n        } else {\n            // revert to previous values if image upload is empty\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    const chatPrompt = prepareChatPrompt(nodeData, messageContent)\n    let promptVariables = {}\n    const promptValuesRaw = (chatPrompt as any).promptValues\n    if (promptValuesRaw) {\n        const promptValues = handleEscapeCharacters(promptValuesRaw, true)\n        for (const val in promptValues) {\n            promptVariables = {\n                ...promptVariables,\n                [val]: () => {\n                    return promptValues[val]\n                }\n            }\n        }\n    }\n\n    const conversationChain = RunnableSequence.from([\n        {\n            [inputKey]: (input: { input: string }) => input.input,\n            [memoryKey]: async () => {\n                const history = await memory.getChatMessages(sessionId, true, prependMessages)\n                return history\n            },\n            ...promptVariables\n        },\n        prepareChatPrompt(nodeData, messageContent),\n        model,\n        new StringOutputParser()\n    ])\n\n    return conversationChain\n}"
}

## ConversationalRetrievalQAChain_Chains

{
  "className": "ConversationalRetrievalQAChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.appDataSource = fields.appDataSource\n        this.databaseEntities = fields.databaseEntities\n        this.chatflowid = fields.chatflowid\n    }",
  "if": "if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "await": "await (const chunk of stream) {\n            streamedResponse = applyPatch(streamedResponse, chunk.ops).newDocument\n\n            if (streamedResponse.final_output) {\n                text = streamedResponse.final_output?.output\n                if (isStreamingEnabled) options.socketIO.to(options.socketIOClientId).emit('end')\n                if (Array.isArray(streamedResponse?.logs?.[sourceRunnableName]?.final_output?.output)) {\n                    sourceDocuments = streamedResponse?.logs?.[sourceRunnableName]?.final_output?.output\n                    if (isStreamingEnabled && returnSourceDocuments)\n                        options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n                }",
  "for": "for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            }",
  "outsideClass_sourceRunnableName": "const sourceRunnableName = 'FindDocs'",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as BaseRetriever\n        const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const rephrasePrompt = nodeData.inputs?.rephrasePrompt as string\n        const responsePrompt = nodeData.inputs?.responsePrompt as string\n\n        let customResponsePrompt = responsePrompt\n        // If the deprecated systemMessagePrompt is still exists\n        if (systemMessagePrompt) {\n            customResponsePrompt = `${systemMessagePrompt}\\n${QA_TEMPLATE}`\n        }\n\n        const answerChain = createChain(model, vectorStoreRetriever, rephrasePrompt, customResponsePrompt)\n        return answerChain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | ICommonObject> {\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const externalMemory = nodeData.inputs?.memory\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as BaseRetriever\n        const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const rephrasePrompt = nodeData.inputs?.rephrasePrompt as string\n        const responsePrompt = nodeData.inputs?.responsePrompt as string\n        const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n        const prependMessages = options?.prependMessages\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n\n        let customResponsePrompt = responsePrompt\n        // If the deprecated systemMessagePrompt is still exists\n        if (systemMessagePrompt) {\n            customResponsePrompt = `${systemMessagePrompt}\\n${QA_TEMPLATE}`\n        }\n\n        let memory: FlowiseMemory | undefined = externalMemory\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (!memory) {\n            memory = new BufferMemory({\n                returnMessages: true,\n                memoryKey: 'chat_history',\n                appDataSource,\n                databaseEntities,\n                chatflowid\n            })\n        }\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Conversational Retrieval QA Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const answerChain = createChain(model, vectorStoreRetriever, rephrasePrompt, customResponsePrompt)\n\n        const history = ((await memory.getChatMessages(this.sessionId, false, prependMessages)) as IMessage[]) ?? []\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const additionalCallback = await additionalCallbacks(nodeData, options)\n\n        let callbacks = [loggerHandler, ...additionalCallback]\n\n        if (process.env.DEBUG === 'true') {\n            callbacks.push(new LCConsoleCallbackHandler())\n        }\n\n        const stream = answerChain.streamLog(\n            { question: input, chat_history: history },\n            { callbacks },\n            {\n                includeNames: [sourceRunnableName]\n            }\n        )\n\n        let streamedResponse: Record<string, any> = {}\n        let sourceDocuments: ICommonObject[] = []\n        let text = ''\n        let isStreamingStarted = false\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        for await (const chunk of stream) {\n            streamedResponse = applyPatch(streamedResponse, chunk.ops).newDocument\n\n            if (streamedResponse.final_output) {\n                text = streamedResponse.final_output?.output\n                if (isStreamingEnabled) options.socketIO.to(options.socketIOClientId).emit('end')\n                if (Array.isArray(streamedResponse?.logs?.[sourceRunnableName]?.final_output?.output)) {\n                    sourceDocuments = streamedResponse?.logs?.[sourceRunnableName]?.final_output?.output\n                    if (isStreamingEnabled && returnSourceDocuments)\n                        options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n                }\n            }\n\n            if (\n                Array.isArray(streamedResponse?.streamed_output) &&\n                streamedResponse?.streamed_output.length &&\n                !streamedResponse.final_output\n            ) {\n                const token = streamedResponse.streamed_output[streamedResponse.streamed_output.length - 1]\n\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    if (isStreamingEnabled) options.socketIO.to(options.socketIOClientId).emit('start', token)\n                }\n                if (isStreamingEnabled) options.socketIO.to(options.socketIOClientId).emit('token', token)\n            }\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: text,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        if (returnSourceDocuments) return { text, sourceDocuments }\n        else return { text }\n    }\n}\n\nconst createRetrieverChain = (llm: BaseLanguageModel, retriever: Runnable, rephrasePrompt: string) => {\n    // Small speed/accuracy optimization: no need to rephrase the first question\n    // since there shouldn't be any meta-references to prior chat history\n    const CONDENSE_QUESTION_PROMPT = PromptTemplate.fromTemplate(rephrasePrompt)\n    const condenseQuestionChain = RunnableSequence.from([CONDENSE_QUESTION_PROMPT, llm, new StringOutputParser()]).withConfig({\n        runName: 'CondenseQuestion'\n    })\n\n    const hasHistoryCheckFn = RunnableLambda.from((input: RetrievalChainInput) => input.chat_history.length > 0).withConfig({\n        runName: 'HasChatHistoryCheck'\n    })\n\n    const conversationChain = condenseQuestionChain.pipe(retriever).withConfig({\n        runName: 'RetrievalChainWithHistory'\n    })\n\n    const basicRetrievalChain = RunnableLambda.from((input: RetrievalChainInput) => input.question)\n        .withConfig({\n            runName: 'Itemgetter:question'\n        })\n        .pipe(retriever)\n        .withConfig({ runName: 'RetrievalChainWithNoHistory' })\n\n    return RunnableBranch.from([[hasHistoryCheckFn, conversationChain], basicRetrievalChain]).withConfig({ runName: sourceRunnableName })\n}\n\nconst formatDocs = (docs: Document[]) => {\n    return docs.map((doc, i) => `<doc id='${i}'>${doc.pageContent}</doc>`).join('\\n')\n}\n\nconst formatChatHistoryAsString = (history: BaseMessage[]) => {\n    return history.map((message) => `${message._getType()}: ${message.content}`).join('\\n')\n}\n\nconst serializeHistory = (input: any) => {\n    const chatHistory: IMessage[] = input.chat_history || []\n    const convertedChatHistory = []\n    for (const message of chatHistory) {\n        if (message.type === 'userMessage') {\n            convertedChatHistory.push(new HumanMessage({ content: message.message }))\n        }\n        if (message.type === 'apiMessage') {\n            convertedChatHistory.push(new AIMessage({ content: message.message }))\n        }\n    }\n    return convertedChatHistory\n}\n\nconst createChain = (\n    llm: BaseLanguageModel,\n    retriever: Runnable,\n    rephrasePrompt = REPHRASE_TEMPLATE,\n    responsePrompt = RESPONSE_TEMPLATE\n) => {\n    const retrieverChain = createRetrieverChain(llm, retriever, rephrasePrompt)\n\n    const context = RunnableMap.from({\n        context: RunnableSequence.from([\n            ({ question, chat_history }) => ({\n                question,\n                chat_history: formatChatHistoryAsString(chat_history)\n            }),\n            retrieverChain,\n            RunnableLambda.from(formatDocs).withConfig({\n                runName: 'FormatDocumentChunks'\n            })\n        ]),\n        question: RunnableLambda.from((input: RetrievalChainInput) => input.question).withConfig({\n            runName: 'Itemgetter:question'\n        }),\n        chat_history: RunnableLambda.from((input: RetrievalChainInput) => input.chat_history).withConfig({\n            runName: 'Itemgetter:chat_history'\n        })\n    }).withConfig({ tags: ['RetrieveDocs'] })\n\n    const prompt = ChatPromptTemplate.fromMessages([\n        ['system', responsePrompt],\n        new MessagesPlaceholder('chat_history'),\n        ['human', `{question}`]\n    ])\n\n    const responseSynthesizerChain = RunnableSequence.from([prompt, llm, new StringOutputParser()]).withConfig({\n        tags: ['GenerateResponse']\n    })\n\n    const conversationalQAChain = RunnableSequence.from([\n        {\n            question: RunnableLambda.from((input: RetrievalChainInput) => input.question).withConfig({\n                runName: 'Itemgetter:question'\n            }),\n            chat_history: RunnableLambda.from(serializeHistory).withConfig({\n                runName: 'SerializeHistory'\n            })\n        },\n        context,\n        responseSynthesizerChain\n    ])\n\n    return conversationalQAChain\n}\n\ninterface BufferMemoryExtendedInput {\n    appDataSource: DataSource\n    databaseEntities: IDatabaseEntity\n    chatflowid: string\n}",
  "outsideClass_chatMessage": "const chatMessage = await this.appDataSource.getRepository(this.databaseEntities['ChatMessage']).find({\n            where: {\n                sessionId: overrideSessionId,\n                chatflowid: this.chatflowid\n            },\n            order: {\n                createdDate: 'ASC'\n            }\n        })\n\n        if (prependMessages?.length) {\n            chatMessage.unshift(...prependMessages)\n        }\n\n        if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }\n\n        let returnIMessages: IMessage[] = []\n        for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            })\n        }\n        return returnIMessages\n    }\n\n    async addChatMessages(): Promise<void> {\n        // adding chat messages is done on server level\n        return\n    }\n\n    async clearChatMessages(): Promise<void> {\n        // clearing chat messages is done on server level\n        return\n    }\n}"
}

## LLMChain_Chains

{
  "className": "LLMChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'LLM Chain'\n        this.name = 'llmChain'\n        this.version = 3.0\n        this.type = 'LLMChain'\n        this.icon = 'LLM_Chain.svg'\n        this.category = 'Chains'\n        this.description = 'Chain to run queries against LLMs'\n        this.baseClasses = [this.type, ...getBaseClasses(LLMChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (isStreaming) {\n            const handler = new CustomChainHandler(socketIO, socketIOClientId)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return formatResponse(res)\n        }",
  "catch": "catch (e) {\n            await new Promise((resolve) => setTimeout(resolve, 500))\n            streamResponse(isStreaming, e.message, socketIO, socketIOClientId)\n            return formatResponse(e.message)\n        }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const prompt = nodeData.inputs?.prompt\n        const output = nodeData.outputs?.output as string\n        let promptValues: ICommonObject | undefined = nodeData.inputs?.prompt.promptValues as ICommonObject\n        const llmOutputParser = nodeData.inputs?.outputParser as BaseOutputParser\n        this.outputParser = llmOutputParser\n        if (llmOutputParser) {\n            let autoFix = (llmOutputParser as any).autoFix\n            if (autoFix === true) {\n                this.outputParser = OutputFixingParser.fromLLM(model, llmOutputParser)\n            }\n        }\n        if (output === this.name) {\n            const chain = new LLMChain({\n                llm: model,\n                outputParser: this.outputParser as BaseLLMOutputParser<string | object>,\n                prompt,\n                verbose: process.env.DEBUG === 'true'\n            })\n            return chain\n        } else if (output === 'outputPrediction') {\n            const chain = new LLMChain({\n                llm: model,\n                outputParser: this.outputParser as BaseLLMOutputParser<string | object>,\n                prompt,\n                verbose: process.env.DEBUG === 'true'\n            })\n            const inputVariables = chain.prompt.inputVariables as string[] // [\"product\"]\n            promptValues = injectOutputParser(this.outputParser, chain, promptValues)\n            // Disable streaming because its not final chain\n            const disableStreaming = true\n            const res = await runPrediction(inputVariables, chain, input, promptValues, options, nodeData, disableStreaming)\n            // eslint-disable-next-line no-console\n            console.log('\\x1b[92m\\x1b[1m\\n*****OUTPUT PREDICTION*****\\n\\x1b[0m\\x1b[0m')\n            // eslint-disable-next-line no-console\n            console.log(res)\n\n            let finalRes = res\n            if (this.outputParser && typeof res === 'object' && Object.prototype.hasOwnProperty.call(res, 'json')) {\n                finalRes = (res as ICommonObject).json\n            }\n\n            /**\n             * Apply string transformation to convert special chars:\n             * FROM: hello i am ben\\n\\n\\thow are you?\n             * TO: hello i am benFLOWISE_NEWLINEFLOWISE_NEWLINEFLOWISE_TABhow are you?\n             */\n            return handleEscapeCharacters(finalRes, false)\n        }\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const inputVariables = nodeData.instance.prompt.inputVariables as string[] // [\"product\"]\n        const chain = nodeData.instance as LLMChain\n        let promptValues: ICommonObject | undefined = nodeData.inputs?.prompt.promptValues as ICommonObject\n        const outputParser = nodeData.inputs?.outputParser as BaseOutputParser\n        if (!this.outputParser && outputParser) {\n            this.outputParser = outputParser\n        }\n        promptValues = injectOutputParser(this.outputParser, chain, promptValues)\n        const res = await runPrediction(inputVariables, chain, input, promptValues, options, nodeData)\n        // eslint-disable-next-line no-console\n        console.log('\\x1b[93m\\x1b[1m\\n*****FINAL RESULT*****\\n\\x1b[0m\\x1b[0m')\n        // eslint-disable-next-line no-console\n        console.log(res)\n        return res\n    }\n}\n\nconst runPrediction = async (\n    inputVariables: string[],\n    chain: LLMChain<string | object | BaseLanguageModel<any, BaseLanguageModelCallOptions>>,\n    input: string,\n    promptValuesRaw: ICommonObject | undefined,\n    options: ICommonObject,\n    nodeData: INodeData,\n    disableStreaming?: boolean\n) => {\n    const loggerHandler = new ConsoleCallbackHandler(options.logger)\n    const callbacks = await additionalCallbacks(nodeData, options)\n\n    const isStreaming = !disableStreaming && options.socketIO && options.socketIOClientId\n    const socketIO = isStreaming ? options.socketIO : undefined\n    const socketIOClientId = isStreaming ? options.socketIOClientId : ''\n    const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n    if (moderations && moderations.length > 0) {\n        try {\n            // Use the output of the moderation chain as input for the LLM chain\n            input = await checkInputs(moderations, input)\n        } catch (e) {\n            await new Promise((resolve) => setTimeout(resolve, 500))\n            streamResponse(isStreaming, e.message, socketIO, socketIOClientId)\n            return formatResponse(e.message)\n        }\n    }\n\n    /**\n     * Apply string transformation to reverse converted special chars:\n     * FROM: { \"value\": \"hello i am benFLOWISE_NEWLINEFLOWISE_NEWLINEFLOWISE_TABhow are you?\" }\n     * TO: { \"value\": \"hello i am ben\\n\\n\\thow are you?\" }\n     */\n    const promptValues = handleEscapeCharacters(promptValuesRaw, true)\n\n    if (llmSupportsVision(chain.llm)) {\n        const visionChatModel = chain.llm as IVisionChatModal\n        const messageContent = await addImagesToMessages(nodeData, options, visionChatModel.multiModalOption)\n        if (messageContent?.length) {\n            // Change model to gpt-4-vision && max token to higher when using gpt-4-vision\n            visionChatModel.setVisionModel()\n            // Add image to the message\n            if (chain.prompt instanceof PromptTemplate) {\n                const existingPromptTemplate = chain.prompt.template as string\n                const msg = HumanMessagePromptTemplate.fromTemplate([\n                    ...messageContent,\n                    {\n                        text: existingPromptTemplate\n                    }\n                ])\n                msg.inputVariables = chain.prompt.inputVariables\n                chain.prompt = ChatPromptTemplate.fromMessages([msg])\n            } else if (chain.prompt instanceof ChatPromptTemplate) {\n                if (chain.prompt.promptMessages.at(-1) instanceof HumanMessagePromptTemplate) {\n                    const lastMessage = chain.prompt.promptMessages.pop() as HumanMessagePromptTemplate\n                    const template = (lastMessage.prompt as PromptTemplate).template as string\n                    const msg = HumanMessagePromptTemplate.fromTemplate([\n                        ...messageContent,\n                        {\n                            text: template\n                        }\n                    ])\n                    msg.inputVariables = lastMessage.inputVariables\n                    chain.prompt.promptMessages.push(msg)\n                } else {\n                    chain.prompt.promptMessages.push(new HumanMessage({ content: messageContent }))\n                }\n            } else if (chain.prompt instanceof FewShotPromptTemplate) {\n                let existingFewShotPromptTemplate = chain.prompt.examplePrompt.template as string\n                let newFewShotPromptTemplate = ChatPromptTemplate.fromMessages([\n                    HumanMessagePromptTemplate.fromTemplate(existingFewShotPromptTemplate)\n                ])\n                newFewShotPromptTemplate.promptMessages.push(new HumanMessage({ content: messageContent }))\n                // @ts-ignore\n                chain.prompt.examplePrompt = newFewShotPromptTemplate\n            }\n        } else {\n            // revert to previous values if image upload is empty\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    if (promptValues && inputVariables.length > 0) {\n        let seen: string[] = []\n\n        for (const variable of inputVariables) {\n            seen.push(variable)\n            if (promptValues[variable]) {\n                seen.pop()\n            }\n        }\n\n        if (seen.length === 0) {\n            // All inputVariables have fixed values specified\n            const options = { ...promptValues }\n            if (isStreaming) {\n                const handler = new CustomChainHandler(socketIO, socketIOClientId)\n                const res = await chain.call(options, [loggerHandler, handler, ...callbacks])\n                return formatResponse(res?.text)\n            } else {\n                const res = await chain.call(options, [loggerHandler, ...callbacks])\n                return formatResponse(res?.text)\n            }\n        } else if (seen.length === 1) {\n            // If one inputVariable is not specify, use input (user's question) as value\n            const lastValue = seen.pop()\n            if (!lastValue) throw new Error('Please provide Prompt Values')\n            const options = {\n                ...promptValues,\n                [lastValue]: input\n            }\n            if (isStreaming) {\n                const handler = new CustomChainHandler(socketIO, socketIOClientId)\n                const res = await chain.call(options, [loggerHandler, handler, ...callbacks])\n                return formatResponse(res?.text)\n            } else {\n                const res = await chain.call(options, [loggerHandler, ...callbacks])\n                return formatResponse(res?.text)\n            }\n        } else {\n            throw new Error(`Please provide Prompt Values for: ${seen.join(', ')}`)\n        }\n    } else {\n        if (isStreaming) {\n            const handler = new CustomChainHandler(socketIO, socketIOClientId)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return formatResponse(res)\n        } else {\n            const res = await chain.run(input, [loggerHandler, ...callbacks])\n            return formatResponse(res)\n        }\n    }\n}"
}

## MultiPromptChain_Chains

{
  "className": "MultiPromptChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'Multi Prompt Chain'\n        this.name = 'multiPromptChain'\n        this.version = 2.0\n        this.type = 'MultiPromptChain'\n        this.icon = 'prompt.svg'\n        this.category = 'Chains'\n        this.description = 'Chain automatically picks an appropriate prompt from multiple prompt templates'\n        this.baseClasses = [this.type, ...getBaseClasses(MultiPromptChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "for": "for (const prompt of promptRetriever) {\n            promptNames.push(prompt.name)\n            promptDescriptions.push(prompt.description)\n            promptTemplates.push(prompt.systemMessage)\n        }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const promptRetriever = nodeData.inputs?.promptRetriever as PromptRetriever[]\n        const promptNames = []\n        const promptDescriptions = []\n        const promptTemplates = []\n\n        for (const prompt of promptRetriever) {\n            promptNames.push(prompt.name)\n            promptDescriptions.push(prompt.description)\n            promptTemplates.push(prompt.systemMessage)\n        }\n\n        const chain = MultiPromptChain.fromLLMAndPrompts(model, {\n            promptNames,\n            promptDescriptions,\n            promptTemplates,\n            llmChainOpts: { verbose: process.env.DEBUG === 'true' ? true : false }\n        })\n\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const chain = nodeData.instance as MultiPromptChain\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Multi Prompt Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const obj = { input }\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        } else {\n            const res = await chain.call(obj, [loggerHandler, ...callbacks])\n            return res?.text\n        }\n    }\n}"
}

## MultiRetrievalQAChain_Chains

{
  "className": "MultiRetrievalQAChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'Multi Retrieval QA Chain'\n        this.name = 'multiRetrievalQAChain'\n        this.version = 2.0\n        this.type = 'MultiRetrievalQAChain'\n        this.icon = 'qa.svg'\n        this.category = 'Chains'\n        this.description = 'QA Chain that automatically picks an appropriate vector store from multiple retrievers'\n        this.baseClasses = [this.type, ...getBaseClasses(MultiRetrievalQAChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "for": "for (const vs of vectorStoreRetriever) {\n            retrieverNames.push(vs.name)\n            retrieverDescriptions.push(vs.description)\n            retrievers.push(vs.vectorStore.asRetriever((vs.vectorStore as any).k ?? 4))\n        }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2, returnSourceDocuments)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            if (res.text && res.sourceDocuments) return res\n            return res?.text\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as VectorStoreRetriever[]\n        const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n\n        const retrieverNames = []\n        const retrieverDescriptions = []\n        const retrievers = []\n\n        for (const vs of vectorStoreRetriever) {\n            retrieverNames.push(vs.name)\n            retrieverDescriptions.push(vs.description)\n            retrievers.push(vs.vectorStore.asRetriever((vs.vectorStore as any).k ?? 4))\n        }\n\n        const chain = MultiRetrievalQAChain.fromLLMAndRetrievers(model, {\n            retrieverNames,\n            retrieverDescriptions,\n            retrievers,\n            retrievalQAChainOpts: { verbose: process.env.DEBUG === 'true' ? true : false, returnSourceDocuments }\n        })\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | ICommonObject> {\n        const chain = nodeData.instance as MultiRetrievalQAChain\n        const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Multi Retrieval QA Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const obj = { input }\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2, returnSourceDocuments)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            if (res.text && res.sourceDocuments) return res\n            return res?.text\n        } else {\n            const res = await chain.call(obj, [loggerHandler, ...callbacks])\n            if (res.text && res.sourceDocuments) return res\n            return res?.text\n        }\n    }\n}"
}

## RetrievalQAChain_Chains

{
  "className": "RetrievalQAChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'Retrieval QA Chain'\n        this.name = 'retrievalQAChain'\n        this.version = 2.0\n        this.type = 'RetrievalQAChain'\n        this.icon = 'qa.svg'\n        this.category = 'Chains'\n        this.description = 'QA chain to answer a question based on the retrieved documents'\n        this.baseClasses = [this.type, ...getBaseClasses(RetrievalQAChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as BaseRetriever\n\n        const chain = RetrievalQAChain.fromLLM(model, vectorStoreRetriever, { verbose: process.env.DEBUG === 'true' ? true : false })\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const chain = nodeData.instance as RetrievalQAChain\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Retrieval QA Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const obj = {\n            query: input\n        }\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        } else {\n            const res = await chain.call(obj, [loggerHandler, ...callbacks])\n            return res?.text\n        }\n    }\n}"
}

## SqlDatabaseChain_Chains

{
  "className": "SqlDatabaseChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'Sql Database Chain'\n        this.name = 'sqlDatabaseChain'\n        this.version = 5.0\n        this.type = 'SqlDatabaseChain'\n        this.icon = 'sqlchain.svg'\n        this.category = 'Chains'\n        this.description = 'Answer questions over a SQL database'\n        this.baseClasses = [this.type, ...getBaseClasses(SqlDatabaseChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (customPrompt) {\n        const options: PromptTemplateInput = {\n            template: customPrompt,\n            inputVariables: getInputVariables(customPrompt)\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_databaseType": "const databaseType = nodeData.inputs?.database as DatabaseType\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const url = nodeData.inputs?.url as string\n        const includesTables = nodeData.inputs?.includesTables\n        const splittedIncludesTables = includesTables == '' ? undefined : includesTables?.split(',')\n        const ignoreTables = nodeData.inputs?.ignoreTables\n        const splittedIgnoreTables = ignoreTables == '' ? undefined : ignoreTables?.split(',')\n        const sampleRowsInTableInfo = nodeData.inputs?.sampleRowsInTableInfo as number\n        const topK = nodeData.inputs?.topK as number\n        const customPrompt = nodeData.inputs?.customPrompt as string\n\n        const chain = await getSQLDBChain(\n            databaseType,\n            url,\n            model,\n            splittedIncludesTables,\n            splittedIgnoreTables,\n            sampleRowsInTableInfo,\n            topK,\n            customPrompt\n        )\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const databaseType = nodeData.inputs?.database as DatabaseType\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const url = nodeData.inputs?.url as string\n        const includesTables = nodeData.inputs?.includesTables\n        const splittedIncludesTables = includesTables == '' ? undefined : includesTables?.split(',')\n        const ignoreTables = nodeData.inputs?.ignoreTables\n        const splittedIgnoreTables = ignoreTables == '' ? undefined : ignoreTables?.split(',')\n        const sampleRowsInTableInfo = nodeData.inputs?.sampleRowsInTableInfo as number\n        const topK = nodeData.inputs?.topK as number\n        const customPrompt = nodeData.inputs?.customPrompt as string\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Sql Database Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const chain = await getSQLDBChain(\n            databaseType,\n            url,\n            model,\n            splittedIncludesTables,\n            splittedIgnoreTables,\n            sampleRowsInTableInfo,\n            topK,\n            customPrompt\n        )\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId, 2)\n            const res = await chain.run(input, [loggerHandler, handler, ...callbacks])\n            return res\n        } else {\n            const res = await chain.run(input, [loggerHandler, ...callbacks])\n            return res\n        }\n    }\n}\n\nconst getSQLDBChain = async (\n    databaseType: DatabaseType,\n    url: string,\n    llm: BaseLanguageModel,\n    includesTables?: string[],\n    ignoreTables?: string[],\n    sampleRowsInTableInfo?: number,\n    topK?: number,\n    customPrompt?: string\n) => {\n    const datasource = new DataSource(\n        databaseType === 'sqlite'\n            ? {\n                  type: databaseType,\n                  database: url\n              }\n            : ({\n                  type: databaseType,\n                  url: url\n              } as DataSourceOptions)\n    )\n\n    const db = await SqlDatabase.fromDataSourceParams({\n        appDataSource: datasource,\n        includesTables: includesTables,\n        ignoreTables: ignoreTables,\n        sampleRowsInTableInfo: sampleRowsInTableInfo\n    })\n\n    const obj: SqlDatabaseChainInput = {\n        llm,\n        database: db,\n        verbose: process.env.DEBUG === 'true' ? true : false,\n        topK: topK\n    }\n\n    if (customPrompt) {\n        const options: PromptTemplateInput = {\n            template: customPrompt,\n            inputVariables: getInputVariables(customPrompt)\n        }\n        obj.prompt = new PromptTemplate(options)\n    }\n\n    const chain = new SqlDatabaseChain(obj)\n    return chain\n}"
}

## VectaraChain_Chains

{
  "className": "VectaraChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "for": "for (let i = 0; i < responses.length; i += 1) {\n                const responseMetadata = responses[i].metadata\n                const documentMetadata = documents[responses[i].documentIndex].metadata\n                const combinedMetadata: Record<string, unknown> = {}",
  "constructor": "constructor() {\n        this.label = 'Vectara QA Chain'\n        this.name = 'vectaraQAChain'\n        this.version = 2.0\n        this.type = 'VectaraQAChain'\n        this.icon = 'vectara.png'\n        this.category = 'Chains'\n        this.description = 'QA chain for Vectara'\n        this.baseClasses = [this.type, ...getBaseClasses(VectorDBQAChain)]\n        this.inputs = [\n            {\n                label: 'Vectara Store',\n                name: 'vectaraStore',\n                type: 'VectorStore'\n            }",
  "if": "if (\n                summaryStatus.length > 0 &&\n                summaryStatus[0].code === 'NOT_FOUND' &&\n                summaryStatus[0].statusDetail === 'Failed to retrieve summarizer.'\n            ) {\n                throw new Error(`BAD REQUEST: summarizer ${summarizerPromptName}",
  "catch": "catch (error) {\n            throw new Error(error)\n        }",
  "outsideClass_reorderCitations": "const reorderCitations = (unorderedSummary: string) => {\n    const allCitations = unorderedSummary.match(/\\[\\d+\\]/g) || []\n\n    const uniqueCitations = [...new Set(allCitations)]\n    const citationToReplacement: { [key: string]: string } = {}\n    uniqueCitations.forEach((citation, index) => {\n        citationToReplacement[citation] = `[${index + 1}]`\n    })\n\n    return unorderedSummary.replace(/\\[\\d+\\]/g, (match) => citationToReplacement[match])\n}\nconst applyCitationOrder = (searchResults: any[], unorderedSummary: string) => {\n    const orderedSearchResults: any[] = []\n    const allCitations = unorderedSummary.match(/\\[\\d+\\]/g) || []\n\n    const addedIndices = new Set<number>()\n    for (let i = 0; i < allCitations.length; i++) {\n        const citation = allCitations[i]\n        const index = Number(citation.slice(1, citation.length - 1)) - 1\n\n        if (addedIndices.has(index)) continue\n        orderedSearchResults.push(searchResults[index])\n        addedIndices.add(index)\n    }\n\n    return orderedSearchResults\n}",
  "outsideClass_vectorStore": "const vectorStore = nodeData.inputs?.vectaraStore as VectaraStore\n        const responseLang = (nodeData.inputs?.responseLang as string) ?? 'eng'\n        const summarizerPromptName = nodeData.inputs?.summarizerPromptName as string\n        const maxSummarizedResultsStr = nodeData.inputs?.maxSummarizedResults as string\n        const maxSummarizedResults = maxSummarizedResultsStr ? parseInt(maxSummarizedResultsStr, 10) : 7\n\n        const topK = (vectorStore as any)?.k ?? 10\n\n        const headers = await vectorStore.getJsonHeader()\n        const vectaraFilter = (vectorStore as any).vectaraFilter ?? {}\n        const corpusId: number[] = (vectorStore as any).corpusId ?? []\n        const customerId = (vectorStore as any).customerId ?? ''\n\n        const corpusKeys = corpusId.map((corpusId) => ({\n            customerId,\n            corpusId,\n            metadataFilter: vectaraFilter?.filter ?? '',\n            lexicalInterpolationConfig: { lambda: vectaraFilter?.lambda ?? 0.025 }\n        }))\n\n        // Vectara reranker ID for MMR (https://docs.vectara.com/docs/api-reference/search-apis/reranking#maximal-marginal-relevance-mmr-reranker)\n        const mmrRerankerId = 272725718\n        const mmrEnabled = vectaraFilter?.mmrConfig?.enabled\n\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the Vectara chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n\n        const data = {\n            query: [\n                {\n                    query: input,\n                    start: 0,\n                    numResults: mmrEnabled ? vectaraFilter?.mmrTopK : topK,\n                    corpusKey: corpusKeys,\n                    contextConfig: {\n                        sentencesAfter: vectaraFilter?.contextConfig?.sentencesAfter ?? 2,\n                        sentencesBefore: vectaraFilter?.contextConfig?.sentencesBefore ?? 2\n                    },\n                    ...(mmrEnabled\n                        ? {\n                              rerankingConfig: {\n                                  rerankerId: mmrRerankerId,\n                                  mmrConfig: {\n                                      diversityBias: vectaraFilter?.mmrConfig.diversityBias\n                                  }\n                              }\n                          }\n                        : {}),\n                    summary: [\n                        {\n                            summarizerPromptName,\n                            responseLang,\n                            maxSummarizedResults\n                        }\n                    ]\n                }\n            ]\n        }\n\n        try {\n            const response = await fetch(`https://api.vectara.io/v1/query`, {\n                method: 'POST',\n                headers: headers?.headers,\n                body: JSON.stringify(data)\n            })\n\n            if (response.status !== 200) {\n                throw new Error(`Vectara API returned status code ${response.status}`)\n            }\n\n            const result = await response.json()\n            const responses = result.responseSet[0].response\n            const documents = result.responseSet[0].document\n            let rawSummarizedText = ''\n\n            // remove responses that are not in the topK (in case of MMR)\n            // Note that this does not really matter functionally due to the reorder citations, but it is more efficient\n            const maxResponses = mmrEnabled ? Math.min(responses.length, topK) : responses.length\n            if (responses.length > maxResponses) {\n                responses.splice(0, maxResponses)\n            }\n\n            // Add metadata to each text response given its corresponding document metadata\n            for (let i = 0; i < responses.length; i += 1) {\n                const responseMetadata = responses[i].metadata\n                const documentMetadata = documents[responses[i].documentIndex].metadata\n                const combinedMetadata: Record<string, unknown> = {}\n\n                responseMetadata.forEach((item: { name: string; value: unknown }) => {\n                    combinedMetadata[item.name] = item.value\n                })\n\n                documentMetadata.forEach((item: { name: string; value: unknown }) => {\n                    combinedMetadata[item.name] = item.value\n                })\n\n                responses[i].metadata = combinedMetadata\n            }\n\n            // Create the summarization response\n            const summaryStatus = result.responseSet[0].summary[0].status\n            if (summaryStatus.length > 0 && summaryStatus[0].code === 'BAD_REQUEST') {\n                throw new Error(\n                    `BAD REQUEST: Too much text for the summarizer to summarize. Please try reducing the number of search results to summarize, or the context of each result by adjusting the 'summary_num_sentences', and 'summary_num_results' parameters respectively.`\n                )\n            }\n            if (\n                summaryStatus.length > 0 &&\n                summaryStatus[0].code === 'NOT_FOUND' &&\n                summaryStatus[0].statusDetail === 'Failed to retrieve summarizer.'\n            ) {\n                throw new Error(`BAD REQUEST: summarizer ${summarizerPromptName} is invalid for this account.`)\n            }\n\n            // Reorder citations in summary and create the list of returned source documents\n            rawSummarizedText = result.responseSet[0].summary[0]?.text\n            let summarizedText = reorderCitations(rawSummarizedText)\n            let summaryResponses = applyCitationOrder(responses, rawSummarizedText)\n\n            const sourceDocuments: Document[] = summaryResponses.map(\n                (response: { text: string; metadata: Record<string, unknown>; score: number }) =>\n                    new Document({\n                        pageContent: response.text,\n                        metadata: response.metadata\n                    })\n            )\n\n            return { text: summarizedText, sourceDocuments: sourceDocuments }\n        } catch (error) {\n            throw new Error(error)\n        }\n    }\n}"
}

## VectorDBQAChain_Chains

{
  "className": "VectorDBQAChain_Chains",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor() {\n        this.label = 'VectorDB QA Chain'\n        this.name = 'vectorDBQAChain'\n        this.version = 2.0\n        this.type = 'VectorDBQAChain'\n        this.icon = 'vectordb.svg'\n        this.category = 'Chains'\n        this.description = 'QA chain for vector databases'\n        this.baseClasses = [this.type, ...getBaseClasses(VectorDBQAChain)]\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        }",
  "catch": "catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n\n        const chain = VectorDBQAChain.fromLLM(model, vectorStore, {\n            k: (vectorStore as any)?.k ?? 4,\n            verbose: process.env.DEBUG === 'true' ? true : false\n        })\n        return chain\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string | object> {\n        const chain = nodeData.instance as VectorDBQAChain\n        const moderations = nodeData.inputs?.inputModeration as Moderation[]\n\n        if (moderations && moderations.length > 0) {\n            try {\n                // Use the output of the moderation chain as input for the VectorDB QA Chain\n                input = await checkInputs(moderations, input)\n            } catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, 500))\n                //streamResponse(options.socketIO && options.socketIOClientId, e.message, options.socketIO, options.socketIOClientId)\n                return formatResponse(e.message)\n            }\n        }\n        const obj = {\n            query: input\n        }\n\n        const loggerHandler = new ConsoleCallbackHandler(options.logger)\n        const callbacks = await additionalCallbacks(nodeData, options)\n\n        if (options.socketIO && options.socketIOClientId) {\n            const handler = new CustomChainHandler(options.socketIO, options.socketIOClientId)\n            const res = await chain.call(obj, [loggerHandler, handler, ...callbacks])\n            return res?.text\n        } else {\n            const res = await chain.call(obj, [loggerHandler, ...callbacks])\n            return res?.text\n        }\n    }\n}"
}

## AWSChatBedrock_ChatModels

{
  "className": "AWSChatBedrock_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'AWS ChatBedrock'\n        this.name = 'awsChatBedrock'\n        this.version = 5.0\n        this.type = 'AWSChatBedrock'\n        this.icon = 'aws.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around AWS Bedrock large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(BedrockChat)]\n        this.credential = {\n            label: 'AWS Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['awsApi'],\n            optional: true\n        }",
  "outsideClass_iRegion": "const iRegion = nodeData.inputs?.region as string\n        const iModel = nodeData.inputs?.model as string\n        const customModel = nodeData.inputs?.customModel as string\n        const iTemperature = nodeData.inputs?.temperature as string\n        const iMax_tokens_to_sample = nodeData.inputs?.max_tokens_to_sample as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const obj: BedrockChatFields = {\n            region: iRegion,\n            model: customModel ? customModel : iModel,\n            maxTokens: parseInt(iMax_tokens_to_sample, 10),\n            temperature: parseFloat(iTemperature),\n            streaming: streaming ?? true\n        }\n\n        /**\n         * Long-term credentials specified in LLM configuration are optional.\n         * Bedrock's credential provider falls back to the AWS SDK to fetch\n         * credentials from the running environment.\n         * When specified, we override the default provider with configured values.\n         * @see https://github.com/aws/aws-sdk-js-v3/blob/main/packages/credential-provider-node/README.md\n         */\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        if (credentialData && Object.keys(credentialData).length !== 0) {\n            const credentialApiKey = getCredentialParam('awsKey', credentialData, nodeData)\n            const credentialApiSecret = getCredentialParam('awsSecret', credentialData, nodeData)\n            const credentialApiSession = getCredentialParam('awsSession', credentialData, nodeData)\n\n            obj.credentials = {\n                accessKeyId: credentialApiKey,\n                secretAccessKey: credentialApiSecret,\n                sessionToken: credentialApiSession\n            }\n        }\n        if (cache) obj.cache = cache\n\n        const allowImageUploads = nodeData.inputs?.allowImageUploads as boolean\n\n        const multiModalOption: IMultiModalOption = {\n            image: {\n                allowImageUploads: allowImageUploads ?? false\n            }\n        }\n\n        const amazonBedrock = new BedrockChat(nodeData.id, obj)\n        if (obj.model?.includes('anthropic.claude-3')) amazonBedrock.setMultiModalOption(multiModalOption)\n        return amazonBedrock\n    }\n}"
}

## AzureChatOpenAI_ChatModels

{
  "className": "AzureChatOpenAI_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Azure ChatOpenAI'\n        this.name = 'azureChatOpenAI'\n        this.version = 5.0\n        this.type = 'AzureChatOpenAI'\n        this.icon = 'Azure.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Azure OpenAI large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainChatOpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['azureOpenAIApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const presencePenalty = nodeData.inputs?.presencePenalty as string\n        const timeout = nodeData.inputs?.timeout as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const cache = nodeData.inputs?.cache as BaseCache\n        const topP = nodeData.inputs?.topP as string\n        const basePath = nodeData.inputs?.basepath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const azureOpenAIApiKey = getCredentialParam('azureOpenAIApiKey', credentialData, nodeData)\n        const azureOpenAIApiInstanceName = getCredentialParam('azureOpenAIApiInstanceName', credentialData, nodeData)\n        const azureOpenAIApiDeploymentName = getCredentialParam('azureOpenAIApiDeploymentName', credentialData, nodeData)\n        const azureOpenAIApiVersion = getCredentialParam('azureOpenAIApiVersion', credentialData, nodeData)\n\n        const allowImageUploads = nodeData.inputs?.allowImageUploads as boolean\n        const imageResolution = nodeData.inputs?.imageResolution as string\n\n        const obj: Partial<AzureOpenAIInput> & BaseLLMParams & Partial<OpenAIChatInput> = {\n            temperature: parseFloat(temperature),\n            modelName,\n            azureOpenAIApiKey,\n            azureOpenAIApiInstanceName,\n            azureOpenAIApiDeploymentName,\n            azureOpenAIApiVersion,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (presencePenalty) obj.presencePenalty = parseFloat(presencePenalty)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (cache) obj.cache = cache\n        if (topP) obj.topP = parseFloat(topP)\n        if (basePath) obj.azureOpenAIBasePath = basePath\n\n        const multiModalOption: IMultiModalOption = {\n            image: {\n                allowImageUploads: allowImageUploads ?? false,\n                imageResolution\n            }\n        }\n\n        const model = new ChatOpenAI(nodeData.id, obj)\n        model.setMultiModalOption(multiModalOption)\n        return model\n    }\n}"
}

## AzureChatOpenAI_LlamaIndex_ChatModels

{
  "className": "AzureChatOpenAI_LlamaIndex_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'AzureChatOpenAI'\n        this.name = 'azureChatOpenAI_LlamaIndex'\n        this.version = 2.0\n        this.type = 'AzureChatOpenAI'\n        this.icon = 'Azure.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Azure OpenAI Chat LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(OpenAI)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['azureOpenAIApi']\n        }",
  "outsideClass_ALL_AZURE_OPENAI_CHAT_MODELS": "const ALL_AZURE_OPENAI_CHAT_MODELS = {\n    'gpt-35-turbo': { contextWindow: 4096, openAIModel: 'gpt-3.5-turbo' },\n    'gpt-35-turbo-16k': {\n        contextWindow: 16384,\n        openAIModel: 'gpt-3.5-turbo-16k'\n    },\n    'gpt-4': { contextWindow: 8192, openAIModel: 'gpt-4' },\n    'gpt-4-32k': { contextWindow: 32768, openAIModel: 'gpt-4-32k' },\n    'gpt-4-turbo': {\n        contextWindow: 128000,\n        openAIModel: 'gpt-4-turbo'\n    },\n    'gpt-4-vision-preview': {\n        contextWindow: 128000,\n        openAIModel: 'gpt-4-vision-preview'\n    },\n    'gpt-4-1106-preview': {\n        contextWindow: 128000,\n        openAIModel: 'gpt-4-1106-preview'\n    }\n}",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as keyof typeof ALL_AZURE_OPENAI_CHAT_MODELS\n        const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const timeout = nodeData.inputs?.timeout as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const azureOpenAIApiKey = getCredentialParam('azureOpenAIApiKey', credentialData, nodeData)\n        const azureOpenAIApiInstanceName = getCredentialParam('azureOpenAIApiInstanceName', credentialData, nodeData)\n        const azureOpenAIApiDeploymentName = getCredentialParam('azureOpenAIApiDeploymentName', credentialData, nodeData)\n        const azureOpenAIApiVersion = getCredentialParam('azureOpenAIApiVersion', credentialData, nodeData)\n\n        const obj: Partial<OpenAI> & { azure?: AzureOpenAIConfig } = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            azure: {\n                apiKey: azureOpenAIApiKey,\n                endpoint: `https://${azureOpenAIApiInstanceName}.openai.azure.com`,\n                apiVersion: azureOpenAIApiVersion,\n                deploymentName: azureOpenAIApiDeploymentName\n            }\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n\n        const model = new OpenAI(obj)\n        return model\n    }\n}"
}

## ChatAnthropic_ChatModels

{
  "className": "ChatAnthropic_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatAnthropic'\n        this.name = 'chatAnthropic'\n        this.version = 6.0\n        this.type = 'ChatAnthropic'\n        this.icon = 'Anthropic.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around ChatAnthropic large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainChatAnthropic)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['anthropicApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokensToSample as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const anthropicApiKey = getCredentialParam('anthropicApiKey', credentialData, nodeData)\n\n        const allowImageUploads = nodeData.inputs?.allowImageUploads as boolean\n\n        const obj: Partial<AnthropicInput> & BaseLLMParams & { anthropicApiKey?: string } = {\n            temperature: parseFloat(temperature),\n            modelName,\n            anthropicApiKey,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (cache) obj.cache = cache\n\n        const multiModalOption: IMultiModalOption = {\n            image: {\n                allowImageUploads: allowImageUploads ?? false\n            }\n        }\n\n        const model = new ChatAnthropic(nodeData.id, obj)\n        model.setMultiModalOption(multiModalOption)\n        return model\n    }\n}"
}

## ChatAnthropic_LlamaIndex_ChatModels

{
  "className": "ChatAnthropic_LlamaIndex_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatAnthropic'\n        this.name = 'chatAnthropic_LlamaIndex'\n        this.version = 3.0\n        this.type = 'ChatAnthropic'\n        this.icon = 'Anthropic.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around ChatAnthropic LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(Anthropic)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['anthropicApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as 'claude-3-opus' | 'claude-3-sonnet' | 'claude-2.1' | 'claude-instant-1.2'\n        const maxTokensToSample = nodeData.inputs?.maxTokensToSample as string\n        const topP = nodeData.inputs?.topP as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const anthropicApiKey = getCredentialParam('anthropicApiKey', credentialData, nodeData)\n\n        const obj: Partial<Anthropic> = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            apiKey: anthropicApiKey\n        }\n\n        if (maxTokensToSample) obj.maxTokens = parseInt(maxTokensToSample, 10)\n        if (topP) obj.topP = parseFloat(topP)\n\n        const model = new Anthropic(obj)\n        return model\n    }\n}"
}

## ChatBaiduWenxin_ChatModels

{
  "className": "ChatBaiduWenxin_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatBaiduWenxin'\n        this.name = 'chatBaiduWenxin'\n        this.version = 1.0\n        this.type = 'ChatBaiduWenxin'\n        this.icon = 'baiduwenxin.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around BaiduWenxin Chat Endpoints'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatBaiduWenxin)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['baiduApi']\n        }",
  "outsideClass_cache": "const cache = nodeData.inputs?.cache as BaseCache\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const baiduApiKey = getCredentialParam('baiduApiKey', credentialData, nodeData)\n        const baiduSecretKey = getCredentialParam('baiduSecretKey', credentialData, nodeData)\n\n        const obj: Partial<ChatBaiduWenxin> = {\n            streaming: true,\n            baiduApiKey,\n            baiduSecretKey,\n            modelName,\n            temperature: temperature ? parseFloat(temperature) : undefined\n        }\n        if (cache) obj.cache = cache\n\n        const model = new ChatBaiduWenxin(obj)\n        return model\n    }\n}"
}

## ChatCohere_ChatModels

{
  "className": "ChatCohere_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatCohere'\n        this.name = 'chatCohere'\n        this.version = 1.0\n        this.type = 'ChatCohere'\n        this.icon = 'Cohere.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Cohere Chat Endpoints'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatCohere)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['cohereApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const temperature = nodeData.inputs?.temperature as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const cohereApiKey = getCredentialParam('cohereApiKey', credentialData, nodeData)\n\n        const obj: ChatCohereInput = {\n            model: modelName,\n            apiKey: cohereApiKey,\n            temperature: temperature ? parseFloat(temperature) : undefined,\n            streaming: streaming ?? true\n        }\n        if (cache) obj.cache = cache\n\n        const model = new ChatCohere(obj)\n        return model\n    }\n}"
}

## ChatFireworks_ChatModels

{
  "className": "ChatFireworks_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatFireworks'\n        this.name = 'chatFireworks'\n        this.version = 1.0\n        this.type = 'ChatFireworks'\n        this.icon = 'Fireworks.png'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Fireworks Chat Endpoints'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatFireworks)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['fireworksApi']\n        }",
  "outsideClass_cache": "const cache = nodeData.inputs?.cache as BaseCache\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const fireworksApiKey = getCredentialParam('fireworksApiKey', credentialData, nodeData)\n\n        const obj: Partial<ChatFireworks> = {\n            fireworksApiKey,\n            model: modelName,\n            modelName,\n            temperature: temperature ? parseFloat(temperature) : undefined,\n            streaming: streaming ?? true\n        }\n        if (cache) obj.cache = cache\n\n        const model = new ChatFireworks(obj)\n        return model\n    }\n}"
}

## GoogleGenerativeAI_ChatModels

{
  "className": "GoogleGenerativeAI_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatGoogleGenerativeAI'\n        this.name = 'chatGoogleGenerativeAI'\n        this.version = 2.1\n        this.type = 'ChatGoogleGenerativeAI'\n        this.icon = 'GoogleGemini.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Google Gemini large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatGoogleGenerativeAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleGenerativeAI'],\n            optional: false,\n            description: 'Google Generative AI credential.'\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('googleGenerativeAPIKey', credentialData, nodeData)\n\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const customModelName = nodeData.inputs?.customModelName as string\n        const maxOutputTokens = nodeData.inputs?.maxOutputTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const harmCategory = nodeData.inputs?.harmCategory as string\n        const harmBlockThreshold = nodeData.inputs?.harmBlockThreshold as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const allowImageUploads = nodeData.inputs?.allowImageUploads as boolean\n\n        const obj: Partial<GoogleGenerativeAIChatInput> = {\n            apiKey: apiKey,\n            modelName: customModelName || modelName,\n            streaming: streaming ?? true\n        }\n\n        if (maxOutputTokens) obj.maxOutputTokens = parseInt(maxOutputTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (cache) obj.cache = cache\n        if (temperature) obj.temperature = parseFloat(temperature)\n\n        // Safety Settings\n        let harmCategories: string[] = convertMultiOptionsToStringArray(harmCategory)\n        let harmBlockThresholds: string[] = convertMultiOptionsToStringArray(harmBlockThreshold)\n        if (harmCategories.length != harmBlockThresholds.length)\n            throw new Error(`Harm Category & Harm Block Threshold are not the same length`)\n        const safetySettings: SafetySetting[] = harmCategories.map((harmCategory, index) => {\n            return {\n                category: harmCategory as HarmCategory,\n                threshold: harmBlockThresholds[index] as HarmBlockThreshold\n            }\n        })\n        if (safetySettings.length > 0) obj.safetySettings = safetySettings\n\n        const multiModalOption: IMultiModalOption = {\n            image: {\n                allowImageUploads: allowImageUploads ?? false\n            }\n        }\n\n        const model = new ChatGoogleGenerativeAI(nodeData.id, obj)\n        model.setMultiModalOption(multiModalOption)\n\n        return model\n    }\n}"
}

## ChatGooglePaLM_ChatModels

{
  "className": "ChatGooglePaLM_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatGooglePaLM'\n        this.name = 'chatGooglePaLM'\n        this.version = 3.0\n        this.type = 'ChatGooglePaLM'\n        this.icon = 'GooglePaLM.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Google MakerSuite PaLM large language models using the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatGooglePaLM)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleMakerSuite']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const temperature = nodeData.inputs?.temperature as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleMakerSuiteKey = getCredentialParam('googleMakerSuiteKey', credentialData, nodeData)\n\n        const obj: Partial<GooglePaLMChatInput> = {\n            modelName: modelName,\n            temperature: parseFloat(temperature),\n            apiKey: googleMakerSuiteKey\n        }\n\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (cache) obj.cache = cache\n\n        const model = new ChatGooglePaLM(obj)\n        return model\n    }\n}"
}

## GoogleVertexAI_ChatModels

{
  "className": "GoogleVertexAI_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatGoogleVertexAI'\n        this.name = 'chatGoogleVertexAI'\n        this.version = 4.0\n        this.type = 'ChatGoogleVertexAI'\n        this.icon = 'GoogleVertex.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around VertexAI large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatVertexAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleVertexAuth'],\n            optional: true,\n            description:\n                'Google Vertex AI credential. If you are using a GCP service like Cloud Run, or if you have installed default credentials on your local machine, you do not need to set this credential.'\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleApplicationCredentialFilePath = getCredentialParam('googleApplicationCredentialFilePath', credentialData, nodeData)\n        const googleApplicationCredential = getCredentialParam('googleApplicationCredential', credentialData, nodeData)\n        const projectID = getCredentialParam('projectID', credentialData, nodeData)\n\n        const authOptions: ICommonObject = {}\n        if (Object.keys(credentialData).length !== 0) {\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error('Please specify your Google Application Credential')\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error(\n                    'Error: More than one component has been inputted. Please use only one of the following: Google Application Credential File Path or Google Credential JSON Object'\n                )\n\n            if (googleApplicationCredentialFilePath && !googleApplicationCredential)\n                authOptions.keyFile = googleApplicationCredentialFilePath\n            else if (!googleApplicationCredentialFilePath && googleApplicationCredential)\n                authOptions.credentials = JSON.parse(googleApplicationCredential)\n\n            if (projectID) authOptions.projectId = projectID\n        }\n\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxOutputTokens = nodeData.inputs?.maxOutputTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const topK = nodeData.inputs?.topK as string\n\n        const obj: ChatVertexAIInput = {\n            temperature: parseFloat(temperature),\n            model: modelName\n        }\n        if (Object.keys(authOptions).length !== 0) obj.authOptions = authOptions\n\n        if (maxOutputTokens) obj.maxOutputTokens = parseInt(maxOutputTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (cache) obj.cache = cache\n        if (topK) obj.topK = parseFloat(topK)\n\n        const model = new ChatVertexAI(obj)\n        return model\n    }\n}"
}

## ChatHuggingFace_ChatModels

{
  "className": "ChatHuggingFace_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatHuggingFace'\n        this.name = 'chatHuggingFace'\n        this.version = 3.0\n        this.type = 'ChatHuggingFace'\n        this.icon = 'HuggingFace.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around HuggingFace large language models'\n        this.baseClasses = [this.type, 'BaseChatModel', ...getBaseClasses(HuggingFaceInference)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['huggingFaceApi']\n        }",
  "if": "if (stop) {\n            const stopSequences = stop.split(',')\n            obj.stopSequences = stopSequences\n        }",
  "outsideClass_model": "const model = nodeData.inputs?.model as string\n        const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const hfTopK = nodeData.inputs?.hfTopK as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const endpoint = nodeData.inputs?.endpoint as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const stop = nodeData.inputs?.stop as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const huggingFaceApiKey = getCredentialParam('huggingFaceApiKey', credentialData, nodeData)\n\n        const obj: Partial<HFInput> = {\n            model,\n            apiKey: huggingFaceApiKey\n        }\n\n        if (temperature) obj.temperature = parseFloat(temperature)\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (hfTopK) obj.topK = parseFloat(hfTopK)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (endpoint) obj.endpointUrl = endpoint\n        if (stop) {\n            const stopSequences = stop.split(',')\n            obj.stopSequences = stopSequences\n        }\n\n        const huggingFace = new HuggingFaceInference(obj)\n        if (cache) huggingFace.cache = cache\n        return huggingFace\n    }\n}"
}

## ChatLocalAI_ChatModels

{
  "className": "ChatLocalAI_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatLocalAI'\n        this.name = 'chatLocalAI'\n        this.version = 2.0\n        this.type = 'ChatLocalAI'\n        this.icon = 'localai.png'\n        this.category = 'Chat Models'\n        this.description = 'Use local LLMs like llama.cpp, gpt4all using LocalAI'\n        this.baseClasses = [this.type, 'BaseChatModel', ...getBaseClasses(ChatOpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['localAIApi'],\n            optional: true\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const timeout = nodeData.inputs?.timeout as string\n        const basePath = nodeData.inputs?.basePath as string\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const localAIApiKey = getCredentialParam('localAIApiKey', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<OpenAIChatInput> & BaseLLMParams & { openAIApiKey?: string } = {\n            temperature: parseFloat(temperature),\n            modelName,\n            openAIApiKey: 'sk-'\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (cache) obj.cache = cache\n        if (localAIApiKey) obj.openAIApiKey = localAIApiKey\n\n        const model = new ChatOpenAI(obj, { basePath })\n\n        return model\n    }\n}"
}

## ChatMistral_ChatModels

{
  "className": "ChatMistral_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatMistralAI'\n        this.name = 'chatMistralAI'\n        this.version = 3.0\n        this.type = 'ChatMistralAI'\n        this.icon = 'MistralAI.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Mistral large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatMistralAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['mistralAIApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('mistralAIAPIKey', credentialData, nodeData)\n\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxOutputTokens = nodeData.inputs?.maxOutputTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const safeMode = nodeData.inputs?.safeMode as boolean\n        const randomSeed = nodeData.inputs?.safeMode as string\n        const overrideEndpoint = nodeData.inputs?.overrideEndpoint as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: ChatMistralAIInput = {\n            apiKey: apiKey,\n            modelName: modelName,\n            streaming: streaming ?? true\n        }\n\n        if (maxOutputTokens) obj.maxTokens = parseInt(maxOutputTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (cache) obj.cache = cache\n        if (temperature) obj.temperature = parseFloat(temperature)\n        if (randomSeed) obj.randomSeed = parseFloat(randomSeed)\n        if (safeMode) obj.safeMode = safeMode\n        if (overrideEndpoint) obj.endpoint = overrideEndpoint\n\n        const model = new ChatMistralAI(obj)\n\n        return model\n    }\n}"
}

## ChatMistral_LlamaIndex_ChatModels

{
  "className": "ChatMistral_LlamaIndex_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatMistral'\n        this.name = 'chatMistral_LlamaIndex'\n        this.version = 1.0\n        this.type = 'ChatMistral'\n        this.icon = 'MistralAI.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around ChatMistral LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(MistralAI)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['mistralAIApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as keyof typeof ALL_AVAILABLE_MISTRAL_MODELS\n        const maxTokensToSample = nodeData.inputs?.maxTokensToSample as string\n        const topP = nodeData.inputs?.topP as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('mistralAIAPIKey', credentialData, nodeData)\n\n        const obj: Partial<MistralAI> = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            apiKey: apiKey\n        }\n\n        if (maxTokensToSample) obj.maxTokens = parseInt(maxTokensToSample, 10)\n        if (topP) obj.topP = parseFloat(topP)\n\n        const model = new MistralAI(obj)\n        return model\n    }\n}"
}

## ChatOllama_ChatModels

{
  "className": "ChatOllama_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatOllama'\n        this.name = 'chatOllama'\n        this.version = 3.0\n        this.type = 'ChatOllama'\n        this.icon = 'Ollama.svg'\n        this.category = 'Chat Models'\n        this.description = 'Chat completion using open-source LLM on Ollama'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatOllama)]\n        this.inputs = [\n            {\n                label: 'Cache',\n                name: 'cache',\n                type: 'BaseCache',\n                optional: true\n            }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const modelName = nodeData.inputs?.modelName as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const mirostat = nodeData.inputs?.mirostat as string\n        const mirostatEta = nodeData.inputs?.mirostatEta as string\n        const mirostatTau = nodeData.inputs?.mirostatTau as string\n        const numCtx = nodeData.inputs?.numCtx as string\n        const keepAlive = nodeData.inputs?.keepAlive as string\n        const numGpu = nodeData.inputs?.numGpu as string\n        const numThread = nodeData.inputs?.numThread as string\n        const repeatLastN = nodeData.inputs?.repeatLastN as string\n        const repeatPenalty = nodeData.inputs?.repeatPenalty as string\n        const tfsZ = nodeData.inputs?.tfsZ as string\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: ChatOllamaInput & BaseChatModelParams = {\n            baseUrl,\n            temperature: parseFloat(temperature),\n            model: modelName\n        }\n\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (mirostat) obj.mirostat = parseFloat(mirostat)\n        if (mirostatEta) obj.mirostatEta = parseFloat(mirostatEta)\n        if (mirostatTau) obj.mirostatTau = parseFloat(mirostatTau)\n        if (numCtx) obj.numCtx = parseFloat(numCtx)\n        if (numGpu) obj.numGpu = parseFloat(numGpu)\n        if (numThread) obj.numThread = parseFloat(numThread)\n        if (repeatLastN) obj.repeatLastN = parseFloat(repeatLastN)\n        if (repeatPenalty) obj.repeatPenalty = parseFloat(repeatPenalty)\n        if (tfsZ) obj.tfsZ = parseFloat(tfsZ)\n        if (keepAlive) obj.keepAlive = keepAlive\n        if (cache) obj.cache = cache\n\n        const model = new ChatOllama(obj)\n        return model\n    }\n}"
}

## ChatOllama_LlamaIndex_ChatModels

{
  "className": "ChatOllama_LlamaIndex_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatOllama'\n        this.name = 'chatOllama_LlamaIndex'\n        this.version = 1.0\n        this.type = 'ChatOllama'\n        this.icon = 'Ollama.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around ChatOllama LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(Ollama)]\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Base URL',\n                name: 'baseUrl',\n                type: 'string',\n                default: 'http://localhost:11434'\n            }",
  "if": "if (stop) {\n            const stopSequences = stop.split(',')\n            obj.options.stop = stopSequences\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const modelName = nodeData.inputs?.modelName as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const mirostat = nodeData.inputs?.mirostat as string\n        const mirostatEta = nodeData.inputs?.mirostatEta as string\n        const mirostatTau = nodeData.inputs?.mirostatTau as string\n        const numCtx = nodeData.inputs?.numCtx as string\n        const numGpu = nodeData.inputs?.numGpu as string\n        const numThread = nodeData.inputs?.numThread as string\n        const repeatLastN = nodeData.inputs?.repeatLastN as string\n        const repeatPenalty = nodeData.inputs?.repeatPenalty as string\n        const stop = nodeData.inputs?.stop as string\n        const tfsZ = nodeData.inputs?.tfsZ as string\n\n        const obj: OllamaParams = {\n            model: modelName,\n            options: {},\n            config: {\n                host: baseUrl\n            }\n        }\n\n        if (temperature) obj.options.temperature = parseFloat(temperature)\n        if (topP) obj.options.top_p = parseFloat(topP)\n        if (topK) obj.options.top_k = parseFloat(topK)\n        if (mirostat) obj.options.mirostat = parseFloat(mirostat)\n        if (mirostatEta) obj.options.mirostat_eta = parseFloat(mirostatEta)\n        if (mirostatTau) obj.options.mirostat_tau = parseFloat(mirostatTau)\n        if (numCtx) obj.options.num_ctx = parseFloat(numCtx)\n        if (numGpu) obj.options.main_gpu = parseFloat(numGpu)\n        if (numThread) obj.options.num_thread = parseFloat(numThread)\n        if (repeatLastN) obj.options.repeat_last_n = parseFloat(repeatLastN)\n        if (repeatPenalty) obj.options.repeat_penalty = parseFloat(repeatPenalty)\n        if (tfsZ) obj.options.tfs_z = parseFloat(tfsZ)\n        if (stop) {\n            const stopSequences = stop.split(',')\n            obj.options.stop = stopSequences\n        }\n\n        const model = new Ollama(obj)\n        return model\n    }\n}"
}

## ChatOllamaFunction_ChatModels

{
  "className": "ChatOllamaFunction_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor(fields: OllamaInput & BaseChatModelParams) {\n        super(fields)\n        this.model = fields.model ?? this.model\n        this.baseUrl = fields.baseUrl?.endsWith('/') ? fields.baseUrl.slice(0, -1) : fields.baseUrl ?? this.baseUrl\n        this.keepAlive = fields.keepAlive ?? this.keepAlive\n        this.embeddingOnly = fields.embeddingOnly\n        this.f16KV = fields.f16KV\n        this.frequencyPenalty = fields.frequencyPenalty\n        this.headers = fields.headers\n        this.logitsAll = fields.logitsAll\n        this.lowVram = fields.lowVram\n        this.mainGpu = fields.mainGpu\n        this.mirostat = fields.mirostat\n        this.mirostatEta = fields.mirostatEta\n        this.mirostatTau = fields.mirostatTau\n        this.numBatch = fields.numBatch\n        this.numCtx = fields.numCtx\n        this.numGpu = fields.numGpu\n        this.numGqa = fields.numGqa\n        this.numKeep = fields.numKeep\n        this.numPredict = fields.numPredict\n        this.numThread = fields.numThread\n        this.penalizeNewline = fields.penalizeNewline\n        this.presencePenalty = fields.presencePenalty\n        this.repeatLastN = fields.repeatLastN\n        this.repeatPenalty = fields.repeatPenalty\n        this.ropeFrequencyBase = fields.ropeFrequencyBase\n        this.ropeFrequencyScale = fields.ropeFrequencyScale\n        this.temperature = fields.temperature\n        this.stop = fields.stop\n        this.tfsZ = fields.tfsZ\n        this.topK = fields.topK\n        this.topP = fields.topP\n        this.typicalP = fields.typicalP\n        this.useMLock = fields.useMLock\n        this.useMMap = fields.useMMap\n        this.vocabOnly = fields.vocabOnly\n        this.format = fields.format\n    }",
  "if": "if (contentPart.type === 'image_url' && typeof contentPart.image_url === 'string') {\n                        const imageUrlComponents = contentPart.image_url.split(',')\n                        // Support both data:image/jpeg;base64,<image> format as well\n                        images.push(imageUrlComponents[1] ?? imageUrlComponents[0])\n                    }",
  "invocationParams": "invocationParams(options?: this['ParsedCallOptions']) {\n        return {\n            model: this.model,\n            format: this.format,\n            keep_alive: this.keepAlive,\n            options: {\n                embedding_only: this.embeddingOnly,\n                f16_kv: this.f16KV,\n                frequency_penalty: this.frequencyPenalty,\n                logits_all: this.logitsAll,\n                low_vram: this.lowVram,\n                main_gpu: this.mainGpu,\n                mirostat: this.mirostat,\n                mirostat_eta: this.mirostatEta,\n                mirostat_tau: this.mirostatTau,\n                num_batch: this.numBatch,\n                num_ctx: this.numCtx,\n                num_gpu: this.numGpu,\n                num_gqa: this.numGqa,\n                num_keep: this.numKeep,\n                num_predict: this.numPredict,\n                num_thread: this.numThread,\n                penalize_newline: this.penalizeNewline,\n                presence_penalty: this.presencePenalty,\n                repeat_last_n: this.repeatLastN,\n                repeat_penalty: this.repeatPenalty,\n                rope_frequency_base: this.ropeFrequencyBase,\n                rope_frequency_scale: this.ropeFrequencyScale,\n                temperature: this.temperature,\n                stop: options?.stop ?? this.stop,\n                tfs_z: this.tfsZ,\n                top_k: this.topK,\n                top_p: this.topP,\n                typical_p: this.typicalP,\n                use_mlock: this.useMLock,\n                use_mmap: this.useMMap,\n                vocab_only: this.vocabOnly\n            }",
  "_identifyingParams": "_identifyingParams() {\n        return this.llm._identifyingParams()\n    }",
  "catch": "catch (e: any) {\n            if (e.response?.status === 404) {\n                console.warn(\n                    '[WARNING]: It seems you are using a legacy version of Ollama. Please upgrade to a newer version for better chat support.'\n                )\n                yield* this._streamResponseChunksLegacy(input, options, runManager)\n            }",
  "_combineLLMOutput": "_combineLLMOutput() {\n        return {}",
  "lc_name": "lc_name() {\n        return 'ChatOllama'\n    }",
  "_llmType": "_llmType() {\n        return 'ollama'\n    }",
  "await": "await (const chunk of stream) {\n                if (!chunk.done) {\n                    yield new ChatGenerationChunk({\n                        text: chunk.message.content,\n                        message: new AIMessageChunk({ content: chunk.message.content }",
  "for": "for (const contentPart of message.content) {\n                    if (contentPart.type === 'text') {\n                        content = `${content}",
  "outsideClass_DEFAULT_TOOL_SYSTEM_TEMPLATE": "const DEFAULT_TOOL_SYSTEM_TEMPLATE = `You have access to the following tools:\n{tools}\nYou must always select one of the above tools and respond with only a JSON object matching the following schema:\n{{\n  \"tool\": <name of the selected tool>,\n  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n}}`",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const modelName = nodeData.inputs?.modelName as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const mirostat = nodeData.inputs?.mirostat as string\n        const mirostatEta = nodeData.inputs?.mirostatEta as string\n        const mirostatTau = nodeData.inputs?.mirostatTau as string\n        const numCtx = nodeData.inputs?.numCtx as string\n        const numGqa = nodeData.inputs?.numGqa as string\n        const numGpu = nodeData.inputs?.numGpu as string\n        const numThread = nodeData.inputs?.numThread as string\n        const repeatLastN = nodeData.inputs?.repeatLastN as string\n        const repeatPenalty = nodeData.inputs?.repeatPenalty as string\n        const stop = nodeData.inputs?.stop as string\n        const tfsZ = nodeData.inputs?.tfsZ as string\n        const toolSystemPromptTemplate = nodeData.inputs?.toolSystemPromptTemplate as string\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: OllamaFunctionsInput = {\n            baseUrl,\n            temperature: parseFloat(temperature),\n            model: modelName,\n            toolSystemPromptTemplate: toolSystemPromptTemplate ? toolSystemPromptTemplate : DEFAULT_TOOL_SYSTEM_TEMPLATE\n        }\n\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (mirostat) obj.mirostat = parseFloat(mirostat)\n        if (mirostatEta) obj.mirostatEta = parseFloat(mirostatEta)\n        if (mirostatTau) obj.mirostatTau = parseFloat(mirostatTau)\n        if (numCtx) obj.numCtx = parseFloat(numCtx)\n        if (numGqa) obj.numGqa = parseFloat(numGqa)\n        if (numGpu) obj.numGpu = parseFloat(numGpu)\n        if (numThread) obj.numThread = parseFloat(numThread)\n        if (repeatLastN) obj.repeatLastN = parseFloat(repeatLastN)\n        if (repeatPenalty) obj.repeatPenalty = parseFloat(repeatPenalty)\n        if (tfsZ) obj.tfsZ = parseFloat(tfsZ)\n        if (stop) {\n            const stopSequences = stop.split(',')\n            obj.stop = stopSequences\n        }\n        if (cache) obj.cache = cache\n\n        const model = new OllamaFunctions(obj)\n        return model\n    }\n}\n\ninterface ChatOllamaFunctionsCallOptions extends BaseFunctionCallOptions {}\n\ntype OllamaFunctionsInput = Partial<ChatOllamaInput> &\n    BaseChatModelParams & {\n        llm?: OllamaChat\n        toolSystemPromptTemplate?: string\n    }",
  "outsideClass_systemPromptTemplate": "const systemPromptTemplate = SystemMessagePromptTemplate.fromTemplate(this.toolSystemPromptTemplate)\n        const systemMessage = await systemPromptTemplate.format({\n            tools: JSON.stringify(functions, null, 2)\n        })\n\n        let generatedMessages = [systemMessage, ...messages]\n        let isToolResponse = false\n        if (\n            messages.length > 3 &&\n            messages[messages.length - 1]._getType() === 'tool' &&\n            functions.length &&\n            messages[messages.length - 1].additional_kwargs?.name === functions[0].name\n        ) {\n            const lastToolQuestion = messages[messages.length - 3].content\n            const lastToolResp = messages.pop()?.content\n            // Pop the message again to get rid of tool call message\n            messages.pop()?.content\n            const humanMessage = new HumanMessage({\n                content: `Given user question: ${lastToolQuestion} and answer: ${lastToolResp}\\n\\nWrite a natural language response`\n            })\n            generatedMessages = [...messages, humanMessage]\n            isToolResponse = true\n            this.llm = new OllamaChat({ ...this.fields })\n        }\n        const chatResult = await this.llm._generate(generatedMessages, options, runManager)\n        const chatGenerationContent = chatResult.generations[0].message.content\n\n        if (typeof chatGenerationContent !== 'string') {\n            throw new Error('OllamaFunctions does not support non-string output.')\n        }\n\n        if (isToolResponse) {\n            return {\n                generations: [\n                    {\n                        message: new AIMessage({\n                            content: chatGenerationContent\n                        }),\n                        text: chatGenerationContent\n                    }\n                ]\n            }\n        }\n\n        let parsedChatResult\n        try {\n            parsedChatResult = JSON.parse(chatGenerationContent)\n        } catch (e) {\n            throw new Error(`\"${this.llm.model}\" did not respond with valid JSON. Please try again.`)\n        }\n\n        const calledToolName = parsedChatResult.tool\n        const calledToolArguments = parsedChatResult.tool_input\n        const calledTool = functions.find((fn) => fn.name === calledToolName)\n        if (calledTool === undefined) {\n            throw new Error(`Failed to parse a function call from ${this.llm.model} output: ${chatGenerationContent}`)\n        }\n\n        if (calledTool.name === this.defaultResponseFunction.name) {\n            return {\n                generations: [\n                    {\n                        message: new AIMessage({\n                            content: calledToolArguments.response\n                        }),\n                        text: calledToolArguments.response\n                    }\n                ]\n            }\n        }\n\n        const responseMessageWithFunctions = new AIMessage({\n            content: '',\n            tool_calls: [\n                {\n                    name: calledToolName,\n                    args: calledToolArguments || {}\n                }\n            ],\n            invalid_tool_calls: [],\n            additional_kwargs: {\n                function_call: {\n                    name: calledToolName,\n                    arguments: calledToolArguments ? JSON.stringify(calledToolArguments) : ''\n                },\n                tool_calls: [\n                    {\n                        id: Date.now().toString(),\n                        type: 'function',\n                        function: {\n                            name: calledToolName,\n                            arguments: calledToolArguments ? JSON.stringify(calledToolArguments) : ''\n                        }\n                    }\n                ]\n            }\n        })\n\n        return {\n            generations: [{ message: responseMessageWithFunctions, text: '' }]\n        }\n    }\n\n    //@ts-ignore\n    override bindTools(\n        tools: StructuredToolInterface[],\n        kwargs?: Partial<ICommonObject>\n    ): RunnableInterface<BaseLanguageModelInput, AIMessageChunk, ICommonObject> {\n        return this.bind({\n            functions: tools.map((tool) => convertToOpenAIFunction(tool)),\n            ...kwargs\n        } as Partial<ICommonObject>)\n    }\n\n    _llmType(): string {\n        return 'ollama_functions'\n    }\n\n    /** @ignore */\n    _combineLLMOutput() {\n        return []\n    }\n}\n\nexport interface ChatOllamaInput extends OllamaInput {}\n\ninterface ChatOllamaCallOptions extends BaseLanguageModelCallOptions {}",
  "outsideClass_stream": "const stream = createOllamaGenerateStream(\n            this.baseUrl,\n            {\n                ...this.invocationParams(options),\n                prompt: this._formatMessagesAsPrompt(input)\n            },\n            {\n                ...options,\n                headers: this.headers\n            }\n        )\n        for await (const chunk of stream) {\n            if (!chunk.done) {\n                yield new ChatGenerationChunk({\n                    text: chunk.response,\n                    message: new AIMessageChunk({ content: chunk.response })\n                })\n                await runManager?.handleLLMNewToken(chunk.response ?? '')\n            } else {\n                yield new ChatGenerationChunk({\n                    text: '',\n                    message: new AIMessageChunk({ content: '' }),\n                    generationInfo: {\n                        model: chunk.model,\n                        total_duration: chunk.total_duration,\n                        load_duration: chunk.load_duration,\n                        prompt_eval_count: chunk.prompt_eval_count,\n                        prompt_eval_duration: chunk.prompt_eval_duration,\n                        eval_count: chunk.eval_count,\n                        eval_duration: chunk.eval_duration\n                    }\n                })\n            }\n        }\n    }\n\n    async *_streamResponseChunks(\n        input: BaseMessage[],\n        options: this['ParsedCallOptions'],\n        runManager?: CallbackManagerForLLMRun\n    ): AsyncGenerator<ChatGenerationChunk> {\n        try {\n            const stream = await this.caller.call(async () =>\n                createOllamaChatStream(\n                    this.baseUrl,\n                    {\n                        ...this.invocationParams(options),\n                        messages: this._convertMessagesToOllamaMessages(input)\n                    },\n                    {\n                        ...options,\n                        headers: this.headers\n                    }\n                )\n            )\n            for await (const chunk of stream) {\n                if (!chunk.done) {\n                    yield new ChatGenerationChunk({\n                        text: chunk.message.content,\n                        message: new AIMessageChunk({ content: chunk.message.content })\n                    })\n                    await runManager?.handleLLMNewToken(chunk.message.content ?? '')\n                } else {\n                    yield new ChatGenerationChunk({\n                        text: '',\n                        message: new AIMessageChunk({ content: '' }),\n                        generationInfo: {\n                            model: chunk.model,\n                            total_duration: chunk.total_duration,\n                            load_duration: chunk.load_duration,\n                            prompt_eval_count: chunk.prompt_eval_count,\n                            prompt_eval_duration: chunk.prompt_eval_duration,\n                            eval_count: chunk.eval_count,\n                            eval_duration: chunk.eval_duration\n                        }\n                    })\n                }\n            }\n        } catch (e: any) {\n            if (e.response?.status === 404) {\n                console.warn(\n                    '[WARNING]: It seems you are using a legacy version of Ollama. Please upgrade to a newer version for better chat support.'\n                )\n                yield* this._streamResponseChunksLegacy(input, options, runManager)\n            } else {\n                throw e\n            }\n        }\n    }\n\n    protected _convertMessagesToOllamaMessages(messages: BaseMessage[]): OllamaMessage[] {\n        return messages.map((message) => {\n            let role\n            if (message._getType() === 'human') {\n                role = 'user'\n            } else if (message._getType() === 'ai' || message._getType() === 'tool') {\n                role = 'assistant'\n            } else if (message._getType() === 'system') {\n                role = 'system'\n            } else {\n                throw new Error(`Unsupported message type for Ollama: ${message._getType()}`)\n            }\n            let content = ''\n            const images = []\n            if (typeof message.content === 'string') {\n                content = message.content\n            } else {\n                for (const contentPart of message.content) {\n                    if (contentPart.type === 'text') {\n                        content = `${content}\\n${contentPart.text}`\n                    } else if (contentPart.type === 'image_url' && typeof contentPart.image_url === 'string') {\n                        const imageUrlComponents = contentPart.image_url.split(',')\n                        // Support both data:image/jpeg;base64,<image> format as well\n                        images.push(imageUrlComponents[1] ?? imageUrlComponents[0])\n                    } else {\n                        throw new Error(\n                            `Unsupported message content type. Must either have type \"text\" or type \"image_url\" with a string \"image_url\" field.`\n                        )\n                    }\n                }\n            }\n            return {\n                role,\n                content,\n                images\n            }\n        })\n    }\n\n    /** @deprecated */\n    protected _formatMessagesAsPrompt(messages: BaseMessage[]): string {\n        const formattedMessages = messages\n            .map((message) => {\n                let messageText\n                if (message._getType() === 'human') {\n                    messageText = `[INST] ${message.content} [/INST]`\n                } else if (message._getType() === 'ai') {\n                    messageText = message.content\n                } else if (message._getType() === 'system') {\n                    messageText = `<<SYS>> ${message.content} <</SYS>>`\n                } else if (ChatMessage.isInstance(message)) {\n                    messageText = `\\n\\n${message.role[0].toUpperCase()}${message.role.slice(1)}: ${message.content}`\n                } else {\n                    console.warn(`Unsupported message type passed to Ollama: \"${message._getType()}\"`)\n                    messageText = ''\n                }\n                return messageText\n            })\n            .join('\\n')\n        return formattedMessages\n    }\n\n    /** @ignore */\n    async _call(messages: BaseMessage[], options: this['ParsedCallOptions'], runManager?: CallbackManagerForLLMRun): Promise<string> {\n        const chunks = []\n        for await (const chunk of this._streamResponseChunks(messages, options, runManager)) {\n            chunks.push(chunk.message.content)\n        }\n        return chunks.join('')\n    }\n}"
}

## ChatOpenAI_ChatModels

{
  "className": "ChatOpenAI_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatOpenAI'\n        this.name = 'chatOpenAI'\n        this.version = 6.0\n        this.type = 'ChatOpenAI'\n        this.icon = 'openai.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around OpenAI large language models that use the Chat endpoint'\n        this.baseClasses = [this.type, ...getBaseClasses(LangchainChatOpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "if": "if (basePath || parsedBaseOptions) {\n            obj.configuration = {\n                baseURL: basePath,\n                baseOptions: parsedBaseOptions\n            }",
  "catch": "catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatOpenAI's BaseOptions: \" + exception)\n            }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const presencePenalty = nodeData.inputs?.presencePenalty as string\n        const timeout = nodeData.inputs?.timeout as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const basePath = nodeData.inputs?.basepath as string\n        const baseOptions = nodeData.inputs?.baseOptions\n\n        const allowImageUploads = nodeData.inputs?.allowImageUploads as boolean\n        const imageResolution = nodeData.inputs?.imageResolution as string\n\n        if (nodeData.inputs?.credentialId) {\n            nodeData.credential = nodeData.inputs?.credentialId\n        }\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<OpenAIChatInput> &\n            Partial<AzureOpenAIInput> &\n            BaseChatModelParams & { configuration?: ClientOptions & LegacyOpenAIInput } = {\n            temperature: parseFloat(temperature),\n            modelName,\n            openAIApiKey,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (presencePenalty) obj.presencePenalty = parseFloat(presencePenalty)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (cache) obj.cache = cache\n\n        let parsedBaseOptions: any | undefined = undefined\n\n        if (baseOptions) {\n            try {\n                parsedBaseOptions = typeof baseOptions === 'object' ? baseOptions : JSON.parse(baseOptions)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatOpenAI's BaseOptions: \" + exception)\n            }\n        }\n\n        if (basePath || parsedBaseOptions) {\n            obj.configuration = {\n                baseURL: basePath,\n                baseOptions: parsedBaseOptions\n            }\n        }\n\n        const multiModalOption: IMultiModalOption = {\n            image: {\n                allowImageUploads: allowImageUploads ?? false,\n                imageResolution\n            }\n        }\n\n        const model = new ChatOpenAI(nodeData.id, obj)\n        model.setMultiModalOption(multiModalOption)\n        return model\n    }\n}"
}

## ChatOpenAI_LlamaIndex_LLMs

{
  "className": "ChatOpenAI_LlamaIndex_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatOpenAI'\n        this.name = 'chatOpenAI_LlamaIndex'\n        this.version = 2.0\n        this.type = 'ChatOpenAI'\n        this.icon = 'openai.svg'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around OpenAI Chat LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(OpenAI)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "if": "if (basePath) {\n            obj.additionalSessionOptions = {\n                baseURL: basePath\n            }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as keyof typeof ALL_AVAILABLE_OPENAI_MODELS\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const timeout = nodeData.inputs?.timeout as string\n        const basePath = nodeData.inputs?.basepath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAI> = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            apiKey: openAIApiKey\n        }\n\n        if (basePath) {\n            obj.additionalSessionOptions = {\n                baseURL: basePath\n            }\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        const openai = new OpenAISession(obj)\n\n        const model = new OpenAI({ ...obj, session: openai })\n        return model\n    }\n}"
}

## ChatOpenAICustom_ChatModels

{
  "className": "ChatOpenAICustom_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatOpenAI Custom'\n        this.name = 'chatOpenAICustom'\n        this.version = 3.0\n        this.type = 'ChatOpenAI-Custom'\n        this.icon = 'openai.svg'\n        this.category = 'Chat Models'\n        this.description = 'Custom/FineTuned model using OpenAI Chat compatible API'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatOpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi'],\n            optional: true\n        }",
  "if": "if (baseOptions) {\n            try {\n                parsedBaseOptions = typeof baseOptions === 'object' ? baseOptions : JSON.parse(baseOptions)\n            }",
  "catch": "catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatOpenAI's BaseOptions: \" + exception)\n            }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const presencePenalty = nodeData.inputs?.presencePenalty as string\n        const timeout = nodeData.inputs?.timeout as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const basePath = nodeData.inputs?.basepath as string\n        const baseOptions = nodeData.inputs?.baseOptions\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAIChatInput> & BaseLLMParams & { openAIApiKey?: string } = {\n            temperature: parseFloat(temperature),\n            modelName,\n            openAIApiKey,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (presencePenalty) obj.presencePenalty = parseFloat(presencePenalty)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (cache) obj.cache = cache\n\n        let parsedBaseOptions: any | undefined = undefined\n\n        if (baseOptions) {\n            try {\n                parsedBaseOptions = typeof baseOptions === 'object' ? baseOptions : JSON.parse(baseOptions)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatOpenAI's BaseOptions: \" + exception)\n            }\n        }\n        const model = new ChatOpenAI(obj, {\n            basePath,\n            baseOptions: parsedBaseOptions\n        })\n        return model\n    }\n}"
}

## ChatTogetherAI_ChatModels

{
  "className": "ChatTogetherAI_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatTogetherAI'\n        this.name = 'chatTogetherAI'\n        this.version = 1.0\n        this.type = 'ChatTogetherAI'\n        this.icon = 'togetherai.png'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around TogetherAI large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatTogetherAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['togetherAIApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const temperature = nodeData.inputs?.temperature as string\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const togetherAIApiKey = getCredentialParam('togetherAIApiKey', credentialData, nodeData)\n\n        const obj: any = {\n            model: modelName,\n            temperature: parseFloat(temperature),\n            togetherAIApiKey: togetherAIApiKey,\n            streaming: streaming ?? true\n        }\n        if (cache) obj.cache = cache\n\n        const model = new ChatTogetherAI(obj)\n        return model\n    }\n}"
}

## ChatTogetherAI_LlamaIndex_ChatModels

{
  "className": "ChatTogetherAI_LlamaIndex_ChatModels",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatTogetherAI'\n        this.name = 'chatTogetherAI_LlamaIndex'\n        this.version = 1.0\n        this.type = 'ChatTogetherAI'\n        this.icon = 'togetherai.png'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around ChatTogetherAI LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(TogetherLLM)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['togetherAIApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const togetherAIApiKey = getCredentialParam('togetherAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAI> = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            apiKey: togetherAIApiKey\n        }\n\n        const model = new TogetherLLM(obj)\n        return model\n    }\n}"
}

## ChatGroq_LlamaIndex_ChatModels

{
  "className": "ChatGroq_LlamaIndex_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'ChatGroq'\n        this.name = 'chatGroq_LlamaIndex'\n        this.version = 1.0\n        this.type = 'ChatGroq'\n        this.icon = 'groq.png'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Groq LLM specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseChatModel_LlamaIndex', ...getBaseClasses(Groq)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['groqApi'],\n            optional: true\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const groqApiKey = getCredentialParam('groqApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAI> = {\n            temperature: parseFloat(temperature),\n            model: modelName,\n            apiKey: groqApiKey\n        }\n\n        const model = new Groq(obj)\n        return model\n    }\n}"
}

## Groq_ChatModels

{
  "className": "Groq_ChatModels",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GroqChat'\n        this.name = 'groqChat'\n        this.version = 3.0\n        this.type = 'GroqChat'\n        this.icon = 'groq.png'\n        this.category = 'Chat Models'\n        this.description = 'Wrapper around Groq API with LPU Inference Engine'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatGroq)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['groqApi'],\n            optional: true\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const temperature = nodeData.inputs?.temperature as string\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const groqApiKey = getCredentialParam('groqApiKey', credentialData, nodeData)\n\n        const obj: ChatGroqInput = {\n            modelName,\n            temperature: parseFloat(temperature),\n            apiKey: groqApiKey,\n            streaming: streaming ?? true\n        }\n        if (cache) obj.cache = cache\n\n        const model = new ChatGroq(obj)\n        return model\n    }\n}"
}

## API_DocumentLoaders

{
  "className": "API_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor({ url, headers, body, method }: ApiLoaderParams) {\n        super()\n        this.url = url\n        this.headers = headers\n        this.body = body\n        this.method = method\n    }",
  "if": "if (headers) {\n                config.headers = headers\n            }",
  "catch": "catch (error) {\n            throw new Error(`Failed to post ${url}",
  "outsideClass_headers": "const headers = nodeData.inputs?.headers as string\n        const url = nodeData.inputs?.url as string\n        const body = nodeData.inputs?.body as string\n        const method = nodeData.inputs?.method as string\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const options: ApiLoaderParams = {\n            url,\n            method\n        }\n\n        if (headers) {\n            const parsedHeaders = typeof headers === 'object' ? headers : JSON.parse(headers)\n            options.headers = parsedHeaders\n        }\n\n        if (body) {\n            const parsedBody = typeof body === 'object' ? body : JSON.parse(body)\n            options.body = parsedBody\n        }\n\n        const loader = new ApiLoader(options)\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}\n\ninterface ApiLoaderParams {\n    url: string\n    method: string\n    headers?: ICommonObject\n    body?: ICommonObject\n}",
  "outsideClass_response": "const response = await axios.get(url, config)\n            const responseJsonString = JSON.stringify(response.data, null, 2)\n            const doc = new Document({\n                pageContent: responseJsonString,\n                metadata: {\n                    url\n                }\n            })\n            return [doc]\n        } catch (error) {\n            throw new Error(`Failed to fetch ${url}: ${error}`)\n        }\n    }\n\n    protected async executePostRequest(url: string, headers?: ICommonObject, body?: ICommonObject): Promise<IDocument[]> {\n        try {\n            const config: AxiosRequestConfig = {}\n            if (headers) {\n                config.headers = headers\n            }\n            const response = await axios.post(url, body ?? {}, config)\n            const responseJsonString = JSON.stringify(response.data, null, 2)\n            const doc = new Document({\n                pageContent: responseJsonString,\n                metadata: {\n                    url\n                }\n            })\n            return [doc]\n        } catch (error) {\n            throw new Error(`Failed to post ${url}: ${error}`)\n        }\n    }\n}"
}

## Airtable_DocumentLoaders

{
  "className": "Airtable_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor({\n        baseId,\n        tableId,\n        viewId,\n        fields = [],\n        accessToken,\n        limit = 100,\n        returnAll = false,\n        filterByFormula\n    }: AirtableLoaderParams) {\n        super()\n        this.baseId = baseId\n        this.tableId = tableId\n        this.viewId = viewId\n        this.fields = fields\n        this.accessToken = accessToken\n        this.limit = limit\n        this.returnAll = returnAll\n        this.filterByFormula = filterByFormula\n    }",
  "if": "if (this.filterByFormula) {\n            data.filterByFormula = this.filterByFormula\n        }",
  "catch": "catch (error) {\n            if (axios.isAxiosError(error)) {\n                throw new Error(`Failed to fetch ${url}",
  "outsideClass_baseId": "const baseId = nodeData.inputs?.baseId as string\n        const tableId = nodeData.inputs?.tableId as string\n        const viewId = nodeData.inputs?.viewId as string\n        const fieldsInput = nodeData.inputs?.fields as string\n        const fields = fieldsInput ? fieldsInput.split(',').map((field) => field.trim()) : []\n        const returnAll = nodeData.inputs?.returnAll as boolean\n        const limit = nodeData.inputs?.limit as string\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n        const filterByFormula = nodeData.inputs?.filterByFormula as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const accessToken = getCredentialParam('accessToken', credentialData, nodeData)\n\n        const airtableOptions: AirtableLoaderParams = {\n            baseId,\n            tableId,\n            viewId,\n            fields,\n            returnAll,\n            accessToken,\n            limit: limit ? parseInt(limit, 10) : 100,\n            filterByFormula\n        }\n\n        const loader = new AirtableLoader(airtableOptions)\n\n        if (!baseId || !tableId) {\n            throw new Error('Base ID and Table ID must be provided.')\n        }\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        const output = nodeData.outputs?.output as string\n\n        if (output === 'text') {\n            let finalText = ''\n            for (const doc of docs) {\n                finalText += `${doc.pageContent}\\n`\n            }\n            return handleEscapeCharacters(finalText, false)\n        }\n\n        return docs\n    }\n}\n\ninterface AirtableLoaderParams {\n    baseId: string\n    tableId: string\n    accessToken: string\n    viewId?: string\n    fields?: string[]\n    limit?: number\n    returnAll?: boolean\n    filterByFormula?: string\n}\n\ninterface AirtableLoaderRequest {\n    maxRecords?: number\n    view: string | undefined\n    fields?: string[]\n    offset?: string\n    filterByFormula?: string\n}\n\ninterface AirtableLoaderResponse {\n    records: AirtableLoaderPage[]\n    offset?: string\n}\n\ninterface AirtableLoaderPage {\n    id: string\n    createdTime: string\n    fields: ICommonObject\n}",
  "outsideClass_headers": "const headers = {\n                Authorization: `Bearer ${this.accessToken}`,\n                'Content-Type': 'application/json',\n                Accept: 'application/json'\n            }\n            const response = await axios.post(url, data, { headers })\n            return response.data\n        } catch (error) {\n            if (axios.isAxiosError(error)) {\n                throw new Error(`Failed to fetch ${url} from Airtable: ${error.message}, status: ${error.response?.status}`)\n            } else {\n                throw new Error(`Failed to fetch ${url} from Airtable: ${error}`)\n            }\n        }\n    }\n\n    private createDocumentFromPage(page: AirtableLoaderPage): IDocument {\n        // Generate the URL\n        const pageUrl = `https://api.airtable.com/v0/${this.baseId}/${this.tableId}/${page.id}`\n\n        // Return a langchain document\n        return new Document({\n            pageContent: JSON.stringify(page.fields, null, 2),\n            metadata: {\n                url: pageUrl\n            }\n        })\n    }\n\n    private async loadLimit(): Promise<IDocument[]> {\n        let data: AirtableLoaderRequest = {\n            maxRecords: this.limit,\n            view: this.viewId\n        }\n\n        if (this.fields.length > 0) {\n            data.fields = this.fields\n        }\n\n        if (this.filterByFormula) {\n            data.filterByFormula = this.filterByFormula\n        }\n\n        let response: AirtableLoaderResponse\n        let returnPages: AirtableLoaderPage[] = []\n\n        // Paginate if the user specifies a limit > 100 (like 200) but not return all.\n        do {\n            response = await this.fetchAirtableData(`https://api.airtable.com/v0/${this.baseId}/${this.tableId}/listRecords`, data)\n            returnPages.push(...response.records)\n            data.offset = response.offset\n\n            // Stop if we have fetched enough records\n            if (returnPages.length >= this.limit) break\n        } while (response.offset !== undefined)\n\n        // Truncate array to the limit if necessary\n        if (returnPages.length > this.limit) {\n            returnPages.length = this.limit\n        }\n\n        return returnPages.map((page) => this.createDocumentFromPage(page))\n    }\n\n    private async loadAll(): Promise<IDocument[]> {\n        let data: AirtableLoaderRequest = {\n            view: this.viewId\n        }\n\n        if (this.fields.length > 0) {\n            data.fields = this.fields\n        }\n\n        if (this.filterByFormula) {\n            data.filterByFormula = this.filterByFormula\n        }\n\n        let response: AirtableLoaderResponse\n        let returnPages: AirtableLoaderPage[] = []\n\n        do {\n            response = await this.fetchAirtableData(`https://api.airtable.com/v0/${this.baseId}/${this.tableId}/listRecords`, data)\n            returnPages.push(...response.records)\n            data.offset = response.offset\n        } while (response.offset !== undefined)\n        return returnPages.map((page) => this.createDocumentFromPage(page))\n    }\n}"
}

## ApifyWebsiteContentCrawler_DocumentLoaders

{
  "className": "ApifyWebsiteContentCrawler_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Apify Website Content Crawler'\n        this.name = 'apifyWebsiteContentCrawler'\n        this.type = 'Document'\n        this.icon = 'apify-symbol-transparent.svg'\n        this.version = 2.0\n        this.category = 'Document Loaders'\n        this.description = 'Load data from Apify Website Content Crawler'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Text Splitter',\n                name: 'textSplitter',\n                type: 'TextSplitter',\n                optional: true\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        // Get input options and merge with additional input\n        const urls = nodeData.inputs?.urls as string\n        const crawlerType = nodeData.inputs?.crawlerType as string\n        const maxCrawlDepth = nodeData.inputs?.maxCrawlDepth as string\n        const maxCrawlPages = nodeData.inputs?.maxCrawlPages as string\n        const additionalInput =\n            typeof nodeData.inputs?.additionalInput === 'object'\n                ? nodeData.inputs?.additionalInput\n                : JSON.parse(nodeData.inputs?.additionalInput as string)\n        const input = {\n            startUrls: urls.split(',').map((url) => ({ url: url.trim() })),\n            crawlerType,\n            maxCrawlDepth: parseInt(maxCrawlDepth, 10),\n            maxCrawlPages: parseInt(maxCrawlPages, 10),\n            ...additionalInput\n        }\n\n        // Get Apify API token from credential data\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apifyApiToken = getCredentialParam('apifyApiToken', credentialData, nodeData)\n\n        const loader = await ApifyDatasetLoader.fromActorCall('apify/website-content-crawler', input, {\n            datasetMappingFunction: (item) =>\n                new Document({\n                    pageContent: (item.text || '') as string,\n                    metadata: { source: item.url }\n                }),\n            clientOptions: {\n                token: apifyApiToken\n            }\n        })\n\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Cheerio_DocumentLoaders

{
  "className": "Cheerio_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Cheerio Web Scraper'\n        this.name = 'cheerioWebScraper'\n        this.version = 1.1\n        this.type = 'Document'\n        this.icon = 'cheerio.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from webpages`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'URL',\n                name: 'url',\n                type: 'string'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "catch": "catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in CheerioWebBaseLoader: ${err.message}",
  "for": "for (const page of pages) {\n                docs.push(...(await cheerioLoader(page)))\n            }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const relativeLinksMethod = nodeData.inputs?.relativeLinksMethod as string\n        const selectedLinks = nodeData.inputs?.selectedLinks as string[]\n        let limit = parseInt(nodeData.inputs?.limit as string)\n\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let url = nodeData.inputs?.url as string\n        url = url.trim()\n        if (!test(url)) {\n            throw new Error('Invalid URL')\n        }\n\n        const selector: SelectorType = nodeData.inputs?.selector as SelectorType\n\n        let params: WebBaseLoaderParams = {}\n        if (selector) {\n            parse(selector) // comes with cheerio - will throw error if invalid\n            params['selector'] = selector\n        }\n\n        async function cheerioLoader(url: string): Promise<any> {\n            try {\n                let docs: IDocument[] = []\n                if (url.endsWith('.pdf')) {\n                    if (process.env.DEBUG === 'true') options.logger.info(`CheerioWebBaseLoader does not support PDF files: ${url}`)\n                    return docs\n                }\n                const loader = new CheerioWebBaseLoader(url, params)\n                if (textSplitter) {\n                    docs = await loader.load()\n                    docs = await textSplitter.splitDocuments(docs)\n                } else {\n                    docs = await loader.load()\n                }\n                return docs\n            } catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in CheerioWebBaseLoader: ${err.message}, on page: ${url}`)\n                return []\n            }\n        }\n\n        let docs: IDocument[] = []\n\n        if (relativeLinksMethod) {\n            if (process.env.DEBUG === 'true') options.logger.info(`Start ${relativeLinksMethod}`)\n            // if limit is 0 we don't want it to default to 10 so we check explicitly for null or undefined\n            // so when limit is 0 we can fetch all the links\n            if (limit === null || limit === undefined) limit = 10\n            else if (limit < 0) throw new Error('Limit cannot be less than 0')\n            const pages: string[] =\n                selectedLinks && selectedLinks.length > 0\n                    ? selectedLinks.slice(0, limit === 0 ? undefined : limit)\n                    : relativeLinksMethod === 'webCrawl'\n                    ? await webCrawl(url, limit)\n                    : await xmlScrape(url, limit)\n            if (process.env.DEBUG === 'true') options.logger.info(`pages: ${JSON.stringify(pages)}, length: ${pages.length}`)\n            if (!pages || pages.length === 0) throw new Error('No relative links found')\n            for (const page of pages) {\n                docs.push(...(await cheerioLoader(page)))\n            }\n            if (process.env.DEBUG === 'true') options.logger.info(`Finish ${relativeLinksMethod}`)\n        } else if (selectedLinks && selectedLinks.length > 0) {\n            if (process.env.DEBUG === 'true')\n                options.logger.info(`pages: ${JSON.stringify(selectedLinks)}, length: ${selectedLinks.length}`)\n            for (const page of selectedLinks.slice(0, limit)) {\n                docs.push(...(await cheerioLoader(page)))\n            }\n        } else {\n            docs = await cheerioLoader(url)\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Confluence_DocumentLoaders

{
  "className": "Confluence_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Confluence'\n        this.name = 'confluence'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'confluence.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from a Confluence Document`\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['confluenceCloudApi', 'confluenceServerDCApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_spaceKey": "const spaceKey = nodeData.inputs?.spaceKey as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const limit = nodeData.inputs?.limit as number\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const accessToken = getCredentialParam('accessToken', credentialData, nodeData)\n        const personalAccessToken = getCredentialParam('personalAccessToken', credentialData, nodeData)\n        const username = getCredentialParam('username', credentialData, nodeData)\n\n        let confluenceOptions: ConfluencePagesLoaderParams = {\n            baseUrl,\n            spaceKey,\n            limit\n        }\n\n        if (accessToken) {\n            // Confluence Cloud credentials\n            confluenceOptions.username = username\n            confluenceOptions.accessToken = accessToken\n        } else if (personalAccessToken) {\n            // Confluence Server/Data Center credentials\n            confluenceOptions.personalAccessToken = personalAccessToken\n        }\n\n        const loader = new ConfluencePagesLoader(confluenceOptions)\n\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Csv_DocumentLoaders

{
  "className": "Csv_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Csv File'\n        this.name = 'csvFile'\n        this.version = 2.0\n        this.type = 'Document'\n        this.icon = 'csv.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from CSV files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Csv File',\n                name: 'csvFile',\n                type: 'file',\n                fileType: '.csv'\n            }",
  "if": "if (output === 'document') {\n            return docs\n        }",
  "for": "for (const doc of docs) {\n                finaltext += `${doc.pageContent}",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const csvFileBase64 = nodeData.inputs?.csvFile as string\n        const columnName = nodeData.inputs?.columnName as string\n        const metadata = nodeData.inputs?.metadata\n        const output = nodeData.outputs?.output as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        if (csvFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = csvFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                const loader = new CSVLoader(blob, columnName.trim().length === 0 ? undefined : columnName.trim())\n\n                if (textSplitter) {\n                    docs = await loader.load()\n                    docs = await textSplitter.splitDocuments(docs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        } else {\n            if (csvFileBase64.startsWith('[') && csvFileBase64.endsWith(']')) {\n                files = JSON.parse(csvFileBase64)\n            } else {\n                files = [csvFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new CSVLoader(blob, columnName.trim().length === 0 ? undefined : columnName.trim())\n\n                if (textSplitter) {\n                    docs = await loader.load()\n                    docs = await textSplitter.splitDocuments(docs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        if (output === 'document') {\n            return docs\n        } else {\n            let finaltext = ''\n            for (const doc of docs) {\n                finaltext += `${doc.pageContent}\\n`\n            }\n            return handleEscapeCharacters(finaltext, false)\n        }\n    }\n}"
}

## CustomDocumentLoader_DocumentLoaders

{
  "className": "CustomDocumentLoader_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Custom Document Loader'\n        this.name = 'customDocumentLoader'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'customDocLoader.svg'\n        this.category = 'Document Loaders'\n        this.description = `Custom function for loading documents`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Input Variables',\n                name: 'functionInputVariables',\n                description: 'Input variables can be used in the function with prefix $. For example: $var',\n                type: 'json',\n                optional: true,\n                acceptVariable: true,\n                list: true\n            }",
  "if": "if (output === 'text' && typeof response === 'string') {\n                return handleEscapeCharacters(response, false)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "for": "for (const item in inputVars) {\n                sandbox[`$${item}",
  "run": "run(`module.exports = async function() {${javascriptFunction}",
  "outsideClass_output": "const output = nodeData.outputs?.output as string\n        const javascriptFunction = nodeData.inputs?.javascriptFunction as string\n        const functionInputVariablesRaw = nodeData.inputs?.functionInputVariables\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n        const variables = await getVars(appDataSource, databaseEntities, nodeData)\n        const flow = {\n            chatflowId: options.chatflowid,\n            sessionId: options.sessionId,\n            chatId: options.chatId,\n            input\n        }\n\n        let inputVars: ICommonObject = {}\n        if (functionInputVariablesRaw) {\n            try {\n                inputVars =\n                    typeof functionInputVariablesRaw === 'object' ? functionInputVariablesRaw : JSON.parse(functionInputVariablesRaw)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Custom Document Loader Input Variables: ' + exception)\n            }\n        }\n\n        // Some values might be a stringified JSON, parse it\n        for (const key in inputVars) {\n            let value = inputVars[key]\n            if (typeof value === 'string') {\n                value = handleEscapeCharacters(value, true)\n                if (value.startsWith('{') && value.endsWith('}')) {\n                    try {\n                        value = JSON.parse(value)\n                    } catch (e) {\n                        // ignore\n                    }\n                }\n                inputVars[key] = value\n            }\n        }\n\n        let sandbox: any = { $input: input }\n        sandbox['$vars'] = prepareSandboxVars(variables)\n        sandbox['$flow'] = flow\n\n        if (Object.keys(inputVars).length) {\n            for (const item in inputVars) {\n                sandbox[`$${item}`] = inputVars[item]\n            }\n        }\n\n        const builtinDeps = process.env.TOOL_FUNCTION_BUILTIN_DEP\n            ? defaultAllowBuiltInDep.concat(process.env.TOOL_FUNCTION_BUILTIN_DEP.split(','))\n            : defaultAllowBuiltInDep\n        const externalDeps = process.env.TOOL_FUNCTION_EXTERNAL_DEP ? process.env.TOOL_FUNCTION_EXTERNAL_DEP.split(',') : []\n        const deps = availableDependencies.concat(externalDeps)\n\n        const nodeVMOptions = {\n            console: 'inherit',\n            sandbox,\n            require: {\n                external: { modules: deps },\n                builtin: builtinDeps\n            }\n        } as any\n\n        const vm = new NodeVM(nodeVMOptions)\n        try {\n            const response = await vm.run(`module.exports = async function() {${javascriptFunction}}()`, __dirname)\n\n            if (output === 'document' && Array.isArray(response)) {\n                if (response.length === 0) return response\n                if (\n                    response[0].pageContent &&\n                    typeof response[0].pageContent === 'string' &&\n                    response[0].metadata &&\n                    typeof response[0].metadata === 'object'\n                )\n                    return response\n                throw new Error('Document object must contain pageContent and metadata')\n            }\n\n            if (output === 'text' && typeof response === 'string') {\n                return handleEscapeCharacters(response, false)\n            }\n\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## DocStore_DocumentLoaders

{
  "className": "DocStore_DocumentLoaders",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Document Store'\n        this.name = 'documentStore'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'dstore.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from pre-configured document stores`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Select Store',\n                name: 'selectedStore',\n                type: 'asyncOptions',\n                loadMethod: 'listStores'\n            }",
  "if": "if (output === 'document') {\n            return finalDocs\n        }",
  "for": "for (const doc of finalDocs) {\n                finaltext += `${doc.pageContent}",
  "outsideClass_appDataSource": "const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n            if (appDataSource === undefined || !appDataSource) {\n                return returnData\n            }\n\n            const stores = await appDataSource.getRepository(databaseEntities['DocumentStore']).find()\n            for (const store of stores) {\n                if (store.status === 'SYNC') {\n                    const obj = {\n                        name: store.id,\n                        label: store.name,\n                        description: store.description\n                    }\n                    returnData.push(obj)\n                }\n            }\n            return returnData\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const selectedStore = nodeData.inputs?.selectedStore as string\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chunks = await appDataSource\n            .getRepository(databaseEntities['DocumentStoreFileChunk'])\n            .find({ where: { storeId: selectedStore } })\n        const output = nodeData.outputs?.output as string\n\n        const finalDocs = []\n        for (const chunk of chunks) {\n            finalDocs.push(new Document({ pageContent: chunk.pageContent, metadata: JSON.parse(chunk.metadata) }))\n        }\n\n        if (output === 'document') {\n            return finalDocs\n        } else {\n            let finaltext = ''\n            for (const doc of finalDocs) {\n                finaltext += `${doc.pageContent}\\n`\n            }\n            return handleEscapeCharacters(finaltext, false)\n        }\n    }\n}"
}

## Docx_DocumentLoaders

{
  "className": "Docx_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Docx File'\n        this.name = 'docxFile'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'docx.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from DOCX files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Docx File',\n                name: 'docxFile',\n                type: 'file',\n                fileType: '.docx'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "for": "for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new DocxLoader(blob)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const docxFileBase64 = nodeData.inputs?.docxFile as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        if (docxFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = docxFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                const loader = new DocxLoader(blob)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        } else {\n            if (docxFileBase64.startsWith('[') && docxFileBase64.endsWith(']')) {\n                files = JSON.parse(docxFileBase64)\n            } else {\n                files = [docxFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new DocxLoader(blob)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Figma_DocumentLoaders

{
  "className": "Figma_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Figma'\n        this.name = 'figma'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'figma.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load data from a Figma file'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['figmaApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_nodeIds": "const nodeIds = (nodeData.inputs?.nodeIds as string)?.trim().split(',') || []\n        const fileKey = nodeData.inputs?.fileKey as string\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const accessToken = getCredentialParam('accessToken', credentialData, nodeData)\n\n        const figmaOptions: FigmaLoaderParams = {\n            accessToken,\n            nodeIds,\n            fileKey\n        }\n\n        const loader = new FigmaFileLoader(figmaOptions)\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## File_DocumentLoaders

{
  "className": "File_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor(public fileBlobs: { blob: Blob; ext: string }[], public loaders: LoadersMapping) {\n        super()\n\n        if (Object.keys(loaders).length === 0) {\n            throw new Error('Must provide at least one loader')\n        }",
  "if": "if (yamlFileBase64) {\n        files.push(...removePrefix(yamlFileBase64))\n    }",
  "for": "for (const fileBlob of this.fileBlobs) {\n            const loaderFactory = this.loaders[fileBlob.ext]\n            if (loaderFactory) {\n                const loader = loaderFactory(fileBlob.blob)\n                documents.push(...(await loader.load()))\n            }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const fileBase64 = nodeData.inputs?.file as string\n        const metadata = nodeData.inputs?.metadata\n        const pdfUsage = nodeData.inputs?.pdfUsage\n        const pointerName = nodeData.inputs?.pointerName as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let files: string[] = []\n        const fileBlobs: { blob: Blob; ext: string }[] = []\n\n        //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n        const totalFiles = getOverrideFileInputs(nodeData) || fileBase64\n        if (totalFiles.startsWith('FILE-STORAGE::')) {\n            const fileName = totalFiles.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                fileBlobs.push({ blob, ext: file.split('.').pop() || '' })\n            }\n        } else {\n            if (totalFiles.startsWith('[') && totalFiles.endsWith(']')) {\n                files = JSON.parse(totalFiles)\n            } else {\n                files = [totalFiles]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n\n                let extension = ''\n                // eslint-disable-next-line no-useless-escape\n                const match = file.match(/^data:([A-Za-z-+\\/]+);base64,/)\n\n                if (!match) {\n                    fileBlobs.push({\n                        blob,\n                        ext: extension\n                    })\n                } else {\n                    const mimeType = match[1]\n                    fileBlobs.push({\n                        blob,\n                        ext: mapMimeTypeToExt(mimeType)\n                    })\n                }\n            }\n        }\n\n        const loader = new MultiFileLoader(fileBlobs, {\n            json: (blob) => new JSONLoader(blob),\n            jsonl: (blob) => new JSONLinesLoader(blob, '/' + pointerName.trim()),\n            txt: (blob) => new TextLoader(blob),\n            csv: (blob) => new CSVLoader(blob),\n            xls: (blob) => new CSVLoader(blob),\n            xlsx: (blob) => new CSVLoader(blob),\n            docx: (blob) => new DocxLoader(blob),\n            doc: (blob) => new DocxLoader(blob),\n            pdf: (blob) =>\n                pdfUsage === 'perFile'\n                    ? // @ts-ignore\n                      new PDFLoader(blob, { splitPages: false, pdfjs: () => import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js') })\n                    : // @ts-ignore\n                      new PDFLoader(blob, { pdfjs: () => import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js') }),\n            '': (blob) => new TextLoader(blob)\n        })\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}\n\nconst getOverrideFileInputs = (nodeData: INodeData) => {\n    const txtFileBase64 = nodeData.inputs?.txtFile as string\n    const pdfFileBase64 = nodeData.inputs?.pdfFile as string\n    const jsonFileBase64 = nodeData.inputs?.jsonFile as string\n    const csvFileBase64 = nodeData.inputs?.csvFile as string\n    const jsonlinesFileBase64 = nodeData.inputs?.jsonlinesFile as string\n    const docxFileBase64 = nodeData.inputs?.docxFile as string\n    const yamlFileBase64 = nodeData.inputs?.yamlFile as string\n\n    const removePrefix = (storageFile: string): string[] => {\n        const fileName = storageFile.replace('FILE-STORAGE::', '')\n        if (fileName.startsWith('[') && fileName.endsWith(']')) {\n            return JSON.parse(fileName)\n        }\n        return [fileName]\n    }\n\n    // If exists, combine all file inputs into an array\n    const files: string[] = []\n    if (txtFileBase64) {\n        files.push(...removePrefix(txtFileBase64))\n    }\n    if (pdfFileBase64) {\n        files.push(...removePrefix(pdfFileBase64))\n    }\n    if (jsonFileBase64) {\n        files.push(...removePrefix(jsonFileBase64))\n    }\n    if (csvFileBase64) {\n        files.push(...removePrefix(csvFileBase64))\n    }\n    if (jsonlinesFileBase64) {\n        files.push(...removePrefix(jsonlinesFileBase64))\n    }\n    if (docxFileBase64) {\n        files.push(...removePrefix(docxFileBase64))\n    }\n    if (yamlFileBase64) {\n        files.push(...removePrefix(yamlFileBase64))\n    }\n\n    return files.length ? `FILE-STORAGE::${JSON.stringify(files)}` : ''\n}\n\ninterface LoadersMapping {\n    [extension: string]: (blob: Blob) => BaseDocumentLoader\n}",
  "outsideClass_loaderFactory": "const loaderFactory = this.loaders[fileBlob.ext]\n            if (loaderFactory) {\n                const loader = loaderFactory(fileBlob.blob)\n                documents.push(...(await loader.load()))\n            } else {\n                throw new Error(`Error loading file`)\n            }\n        }\n\n        return documents\n    }\n}"
}

## FireCrawl_DocumentLoaders

{
  "className": "FireCrawl_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'FireCrawl'\n        this.name = 'fireCrawl'\n        this.type = 'Document'\n        this.icon = 'firecrawl.png'\n        this.version = 1.0\n        this.category = 'Document Loaders'\n        this.description = 'Load data from URL using FireCrawl'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Text Splitter',\n                name: 'textSplitter',\n                type: 'TextSplitter',\n                optional: true\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            let finaldocs = []\n            for (const doc of docs) {\n                const newdoc = {\n                    ...doc,\n                    metadata: {\n                        ...doc.metadata,\n                        ...parsedMetadata\n                    }",
  "catch": "catch (error: any) {\n            throw new Error(error.message)\n        }",
  "while": "while (!isJobCompleted) {\n            const statusResponse: AxiosResponse = await this.getRequest(this.apiUrl + `/v0/crawl/status/${jobId}",
  "outsideClass_headers": "const headers = this.prepareHeaders()\n        let jsonData: Params = { url, ...params }\n        if (params?.extractorOptions?.extractionSchema) {\n            let schema = params.extractorOptions.extractionSchema\n            if (schema instanceof z.ZodSchema) {\n                schema = zodToJsonSchema(schema)\n            }\n            jsonData = {\n                ...jsonData,\n                extractorOptions: {\n                    ...params.extractorOptions,\n                    extractionSchema: schema,\n                    mode: params.extractorOptions.mode || 'llm-extraction'\n                }\n            }\n        }\n        try {\n            const response: AxiosResponse = await this.postRequest(this.apiUrl + '/v0/scrape', jsonData, headers)\n            if (response.status === 200) {\n                const responseData = response.data\n                if (responseData.success) {\n                    return responseData\n                } else {\n                    throw new Error(`Failed to scrape URL. Error: ${responseData.error}`)\n                }\n            } else {\n                this.handleError(response, 'scrape URL')\n            }\n        } catch (error: any) {\n            throw new Error(error.message)\n        }\n        return { success: false, error: 'Internal server error.' }\n    }\n\n    async crawlUrl(\n        url: string,\n        params: Params | null = null,\n        waitUntilDone: boolean = true,\n        pollInterval: number = 2,\n        idempotencyKey?: string\n    ): Promise<CrawlResponse | any> {\n        const headers = this.prepareHeaders(idempotencyKey)\n        let jsonData: Params = { url, ...params }\n        try {\n            const response: AxiosResponse = await this.postRequest(this.apiUrl + '/v0/crawl', jsonData, headers)\n            if (response.status === 200) {\n                const jobId: string = response.data.jobId\n                if (waitUntilDone) {\n                    return this.monitorJobStatus(jobId, headers, pollInterval)\n                } else {\n                    return { success: true, jobId }\n                }\n            } else {\n                this.handleError(response, 'start crawl job')\n            }\n        } catch (error: any) {\n            throw new Error(error.message)\n        }\n        return { success: false, error: 'Internal server error.' }\n    }\n\n    private prepareHeaders(idempotencyKey?: string): AxiosRequestHeaders {\n        return {\n            'Content-Type': 'application/json',\n            Authorization: `Bearer ${this.apiKey}`,\n            ...(idempotencyKey ? { 'x-idempotency-key': idempotencyKey } : {})\n        } as AxiosRequestHeaders & { 'x-idempotency-key'?: string }\n    }\n\n    private postRequest(url: string, data: Params, headers: AxiosRequestHeaders): Promise<AxiosResponse> {\n        return axios.post(url, data, { headers })\n    }\n\n    private getRequest(url: string, headers: AxiosRequestHeaders): Promise<AxiosResponse> {\n        return axios.get(url, { headers })\n    }\n\n    private async monitorJobStatus(jobId: string, headers: AxiosRequestHeaders, checkInterval: number): Promise<any> {\n        let isJobCompleted = false\n        while (!isJobCompleted) {\n            const statusResponse: AxiosResponse = await this.getRequest(this.apiUrl + `/v0/crawl/status/${jobId}`, headers)\n            if (statusResponse.status === 200) {\n                const statusData = statusResponse.data\n                switch (statusData.status) {\n                    case 'completed':\n                        isJobCompleted = true\n                        if ('data' in statusData) {\n                            return statusData.data\n                        } else {\n                            throw new Error('Crawl job completed but no data was returned')\n                        }\n                    case 'active':\n                    case 'paused':\n                    case 'pending':\n                    case 'queued':\n                        await new Promise((resolve) => setTimeout(resolve, Math.max(checkInterval, 2) * 1000))\n                        break\n                    default:\n                        throw new Error(`Crawl job failed or was stopped. Status: ${statusData.status}`)\n                }\n            } else {\n                this.handleError(statusResponse, 'check crawl status')\n            }\n        }\n    }\n\n    private handleError(response: AxiosResponse, action: string): void {\n        if ([402, 408, 409, 500].includes(response.status)) {\n            const errorMessage: string = response.data.error || 'Unknown error occurred'\n            throw new Error(`Failed to ${action}. Status code: ${response.status}. Error: ${errorMessage}`)\n        } else {\n            throw new Error(`Unexpected error occurred while trying to ${action}. Status code: ${response.status}`)\n        }\n    }\n}\n\n// FireCrawl Loader\ninterface FirecrawlLoaderParameters {\n    url: string\n    apiKey?: string\n    mode?: 'crawl' | 'scrape'\n    params?: Record<string, unknown>\n}",
  "outsideClass_app": "const app = new FirecrawlApp({ apiKey: this.apiKey })\n        let firecrawlDocs: FirecrawlDocument[]\n\n        if (this.mode === 'scrape') {\n            const response = await app.scrapeUrl(this.url, this.params)\n            if (!response.success) {\n                throw new Error(`Firecrawl: Failed to scrape URL. Error: ${response.error}`)\n            }\n            firecrawlDocs = [response.data as FirecrawlDocument]\n        } else if (this.mode === 'crawl') {\n            const response = await app.crawlUrl(this.url, this.params, true)\n            firecrawlDocs = response as FirecrawlDocument[]\n        } else {\n            throw new Error(`Unrecognized mode '${this.mode}'. Expected one of 'crawl', 'scrape'.`)\n        }\n\n        return firecrawlDocs.map(\n            (doc) =>\n                new Document({\n                    pageContent: doc.markdown || '',\n                    metadata: doc.metadata || {}\n                })\n        )\n    }\n}\n\n// Flowise Node Class",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const url = nodeData.inputs?.url as string\n        const crawlerType = nodeData.inputs?.crawlerType as string\n        const maxCrawlPages = nodeData.inputs?.maxCrawlPages as string\n        const generateImgAltText = nodeData.inputs?.generateImgAltText as boolean\n        const returnOnlyUrls = nodeData.inputs?.returnOnlyUrls as boolean\n        const onlyMainContent = nodeData.inputs?.onlyMainContent as boolean\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const firecrawlApiToken = getCredentialParam('firecrawlApiToken', credentialData, nodeData)\n\n        const urlPatternsExcludes = nodeData.inputs?.urlPatternsExcludes\n            ? (nodeData.inputs.urlPatternsExcludes.split(',') as string[])\n            : undefined\n        const urlPatternsIncludes = nodeData.inputs?.urlPatternsIncludes\n            ? (nodeData.inputs.urlPatternsIncludes.split(',') as string[])\n            : undefined\n\n        const input: FirecrawlLoaderParameters = {\n            url,\n            mode: crawlerType as 'crawl' | 'scrape',\n            apiKey: firecrawlApiToken,\n            params: {\n                crawlerOptions: {\n                    includes: urlPatternsIncludes,\n                    excludes: urlPatternsExcludes,\n                    generateImgAltText,\n                    returnOnlyUrls,\n                    limit: maxCrawlPages ? parseFloat(maxCrawlPages) : undefined\n                },\n                pageOptions: {\n                    onlyMainContent\n                }\n            }\n        }\n\n        const loader = new FireCrawlLoader(input)\n\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.loadAndSplit(textSplitter)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            let finaldocs = []\n            for (const doc of docs) {\n                const newdoc = {\n                    ...doc,\n                    metadata: {\n                        ...doc.metadata,\n                        ...parsedMetadata\n                    }\n                }\n                finaldocs.push(newdoc)\n            }\n            return finaldocs\n        }\n\n        return docs\n    }\n}"
}

## Folder_DocumentLoaders

{
  "className": "Folder_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Folder with Files'\n        this.name = 'folderFiles'\n        this.version = 3.0\n        this.type = 'Document'\n        this.icon = 'folder.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from folder with multiple files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Folder Path',\n                name: 'folderPath',\n                type: 'string',\n                placeholder: ''\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const folderPath = nodeData.inputs?.folderPath as string\n        const metadata = nodeData.inputs?.metadata\n        const recursive = nodeData.inputs?.recursive as boolean\n        const pdfUsage = nodeData.inputs?.pdfUsage\n        const pointerName = nodeData.inputs?.pointerName as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const loader = new DirectoryLoader(\n            folderPath,\n            {\n                '.json': (path) => new JSONLoader(path),\n                '.jsonl': (blob) => new JSONLinesLoader(blob, '/' + pointerName.trim()),\n                '.txt': (path) => new TextLoader(path),\n                '.csv': (path) => new CSVLoader(path),\n                '.xls': (path) => new CSVLoader(path),\n                '.xlsx': (path) => new CSVLoader(path),\n                '.doc': (path) => new DocxLoader(path),\n                '.docx': (path) => new DocxLoader(path),\n                '.pdf': (path) =>\n                    pdfUsage === 'perFile'\n                        ? // @ts-ignore\n                          new PDFLoader(path, { splitPages: false, pdfjs: () => import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js') })\n                        : // @ts-ignore\n                          new PDFLoader(path, { pdfjs: () => import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js') }),\n                '.aspx': (path) => new TextLoader(path),\n                '.asp': (path) => new TextLoader(path),\n                '.cpp': (path) => new TextLoader(path), // C++\n                '.c': (path) => new TextLoader(path),\n                '.cs': (path) => new TextLoader(path),\n                '.css': (path) => new TextLoader(path),\n                '.go': (path) => new TextLoader(path), // Go\n                '.h': (path) => new TextLoader(path), // C++ Header files\n                '.kt': (path) => new TextLoader(path), // Kotlin\n                '.java': (path) => new TextLoader(path), // Java\n                '.js': (path) => new TextLoader(path), // JavaScript\n                '.less': (path) => new TextLoader(path), // Less files\n                '.ts': (path) => new TextLoader(path), // TypeScript\n                '.php': (path) => new TextLoader(path), // PHP\n                '.proto': (path) => new TextLoader(path), // Protocol Buffers\n                '.python': (path) => new TextLoader(path), // Python\n                '.py': (path) => new TextLoader(path), // Python\n                '.rst': (path) => new TextLoader(path), // reStructuredText\n                '.ruby': (path) => new TextLoader(path), // Ruby\n                '.rb': (path) => new TextLoader(path), // Ruby\n                '.rs': (path) => new TextLoader(path), // Rust\n                '.scala': (path) => new TextLoader(path), // Scala\n                '.sc': (path) => new TextLoader(path), // Scala\n                '.scss': (path) => new TextLoader(path), // Sass\n                '.sol': (path) => new TextLoader(path), // Solidity\n                '.sql': (path) => new TextLoader(path), //SQL\n                '.swift': (path) => new TextLoader(path), // Swift\n                '.markdown': (path) => new TextLoader(path), // Markdown\n                '.md': (path) => new TextLoader(path), // Markdown\n                '.tex': (path) => new TextLoader(path), // LaTeX\n                '.ltx': (path) => new TextLoader(path), // LaTeX\n                '.html': (path) => new TextLoader(path), // HTML\n                '.vb': (path) => new TextLoader(path), // Visual Basic\n                '.xml': (path) => new TextLoader(path) // XML\n            },\n            recursive\n        )\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Gitbook_DocumentLoaders

{
  "className": "Gitbook_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GitBook'\n        this.name = 'gitbook'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'gitbook.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from GitBook`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Web Path',\n                name: 'webPath',\n                type: 'string',\n                placeholder: 'https://docs.gitbook.com/product-tour/navigation',\n                description: 'If want to load all paths from the GitBook provide only root path e.g.https://docs.gitbook.com/ '\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_webPath": "const webPath = nodeData.inputs?.webPath as string\n        const shouldLoadAllPaths = nodeData.inputs?.shouldLoadAllPaths as boolean\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const loader = shouldLoadAllPaths ? new GitbookLoader(webPath, { shouldLoadAllPaths }) : new GitbookLoader(webPath)\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Github_DocumentLoaders

{
  "className": "Github_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Github'\n        this.name = 'github'\n        this.version = 2.0\n        this.type = 'Document'\n        this.icon = 'github.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from a GitHub repository`\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Only needed when accessing private repo',\n            optional: true,\n            credentialNames: ['githubApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_repoLink": "const repoLink = nodeData.inputs?.repoLink as string\n        const branch = nodeData.inputs?.branch as string\n        const recursive = nodeData.inputs?.recursive as boolean\n        const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const maxConcurrency = nodeData.inputs?.maxConcurrency as string\n        const maxRetries = nodeData.inputs?.maxRetries as string\n        const ignorePath = nodeData.inputs?.ignorePath as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const accessToken = getCredentialParam('accessToken', credentialData, nodeData)\n\n        const githubOptions: GithubRepoLoaderParams = {\n            branch,\n            recursive,\n            unknown: 'warn'\n        }\n\n        if (accessToken) githubOptions.accessToken = accessToken\n        if (maxConcurrency) githubOptions.maxConcurrency = parseInt(maxConcurrency, 10)\n        if (maxRetries) githubOptions.maxRetries = parseInt(maxRetries, 10)\n        if (ignorePath) githubOptions.ignorePaths = JSON.parse(ignorePath)\n\n        const loader = new GithubRepoLoader(repoLink, githubOptions)\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Json_DocumentLoaders

{
  "className": "Json_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Json File'\n        this.name = 'jsonFile'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'json.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from JSON files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Json File',\n                name: 'jsonFile',\n                type: 'file',\n                fileType: '.json'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "for": "for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new JSONLoader(blob, pointers.length != 0 ? pointers : undefined)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const jsonFileBase64 = nodeData.inputs?.jsonFile as string\n        const pointersName = nodeData.inputs?.pointersName as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let pointers: string[] = []\n        if (pointersName) {\n            const outputString = pointersName.replace(/[^a-zA-Z0-9,]+/g, ',')\n            pointers = outputString.split(',').map((pointer) => '/' + pointer.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n        if (jsonFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = jsonFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                const loader = new JSONLoader(blob, pointers.length != 0 ? pointers : undefined)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        } else {\n            if (jsonFileBase64.startsWith('[') && jsonFileBase64.endsWith(']')) {\n                files = JSON.parse(jsonFileBase64)\n            } else {\n                files = [jsonFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new JSONLoader(blob, pointers.length != 0 ? pointers : undefined)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Jsonlines_DocumentLoaders

{
  "className": "Jsonlines_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Json Lines File'\n        this.name = 'jsonlinesFile'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'jsonlines.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from JSON Lines files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Jsonlines File',\n                name: 'jsonlinesFile',\n                type: 'file',\n                fileType: '.jsonl'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "for": "for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new JSONLinesLoader(blob, pointer)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const jsonLinesFileBase64 = nodeData.inputs?.jsonlinesFile as string\n        const pointerName = nodeData.inputs?.pointerName as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        let pointer = '/' + pointerName.trim()\n        //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n        if (jsonLinesFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = jsonLinesFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                const loader = new JSONLinesLoader(blob, pointer)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        } else {\n            if (jsonLinesFileBase64.startsWith('[') && jsonLinesFileBase64.endsWith(']')) {\n                files = JSON.parse(jsonLinesFileBase64)\n            } else {\n                files = [jsonLinesFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new JSONLinesLoader(blob, pointer)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## NotionDB_DocumentLoaders

{
  "className": "NotionDB_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Notion Database'\n        this.name = 'notionDB'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'notion-db.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load data from Notion Database (each row is a separate document with all properties as metadata)'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['notionApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const databaseId = nodeData.inputs?.databaseId as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const notionIntegrationToken = getCredentialParam('notionIntegrationToken', credentialData, nodeData)\n\n        const obj: NotionAPILoaderOptions = {\n            clientOptions: {\n                auth: notionIntegrationToken\n            },\n            id: databaseId,\n            callerOptions: {\n                maxConcurrency: 64 // Default value\n            },\n            propertiesAsHeader: true, // Prepends a front matter header of the page properties to the page contents\n            type: 'database'\n        }\n        const loader = new NotionAPILoader(obj)\n\n        let docs: IDocument[] = []\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## NotionFolder_DocumentLoaders

{
  "className": "NotionFolder_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Notion Folder'\n        this.name = 'notionFolder'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'notion-folder.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load data from the exported and unzipped Notion folder'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Notion Folder',\n                name: 'notionFolder',\n                type: 'string',\n                description: 'Get folder path',\n                placeholder: 'Paste folder path'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const notionFolder = nodeData.inputs?.notionFolder as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const loader = new NotionLoader(notionFolder)\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## NotionPage_DocumentLoaders

{
  "className": "NotionPage_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Notion Page'\n        this.name = 'notionPage'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'notion-page.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load data from Notion Page (including child pages all as separate documents)'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['notionApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const pageId = nodeData.inputs?.pageId as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const notionIntegrationToken = getCredentialParam('notionIntegrationToken', credentialData, nodeData)\n\n        const obj: NotionAPILoaderOptions = {\n            clientOptions: {\n                auth: notionIntegrationToken\n            },\n            id: pageId,\n            type: 'page'\n        }\n        const loader = new NotionAPILoader(obj)\n\n        let docs: IDocument[] = []\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Pdf_DocumentLoaders

{
  "className": "Pdf_DocumentLoaders",
  "init": "[Function: init]",
  "extractDocs": "extractDocs(usage: string, bf: Buffer, legacyBuild: boolean, textSplitter: TextSplitter, docs: IDocument[]) {\n        if (usage === 'perFile') {\n            const loader = new PDFLoader(new Blob([bf]), {\n                splitPages: false,\n                pdfjs: () =>\n                    // @ts-ignore\n                    legacyBuild ? import('pdfjs-dist/legacy/build/pdf.js') : import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js')\n            }",
  "constructor": "constructor() {\n        this.label = 'Pdf File'\n        this.name = 'pdfFile'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'pdf.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from PDF files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Pdf File',\n                name: 'pdfFile',\n                type: 'file',\n                fileType: '.pdf'\n            }",
  "if": "if (textSplitter) {\n                let splittedDocs = await loader.load()\n                splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                docs.push(...splittedDocs)\n            }",
  "for": "for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                await this.extractDocs(usage, bf, legacyBuild, textSplitter, docs)\n            }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const pdfFileBase64 = nodeData.inputs?.pdfFile as string\n        const usage = nodeData.inputs?.usage as string\n        const metadata = nodeData.inputs?.metadata\n        const legacyBuild = nodeData.inputs?.legacyBuild as boolean\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n        if (pdfFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = pdfFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const bf = Buffer.from(fileData)\n                await this.extractDocs(usage, bf, legacyBuild, textSplitter, docs)\n            }\n        } else {\n            if (pdfFileBase64.startsWith('[') && pdfFileBase64.endsWith(']')) {\n                files = JSON.parse(pdfFileBase64)\n            } else {\n                files = [pdfFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                await this.extractDocs(usage, bf, legacyBuild, textSplitter, docs)\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n\n    private async extractDocs(usage: string, bf: Buffer, legacyBuild: boolean, textSplitter: TextSplitter, docs: IDocument[]) {\n        if (usage === 'perFile') {\n            const loader = new PDFLoader(new Blob([bf]), {\n                splitPages: false,\n                pdfjs: () =>\n                    // @ts-ignore\n                    legacyBuild ? import('pdfjs-dist/legacy/build/pdf.js') : import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js')\n            })\n            if (textSplitter) {\n                let splittedDocs = await loader.load()\n                splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                docs.push(...splittedDocs)\n            } else {\n                docs.push(...(await loader.load()))\n            }\n        } else {\n            const loader = new PDFLoader(new Blob([bf]), {\n                pdfjs: () =>\n                    // @ts-ignore\n                    legacyBuild ? import('pdfjs-dist/legacy/build/pdf.js') : import('pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js')\n            })\n            if (textSplitter) {\n                let splittedDocs = await loader.load()\n                splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                docs.push(...splittedDocs)\n            } else {\n                docs.push(...(await loader.load()))\n            }\n        }\n    }\n}"
}

## PlainText_DocumentLoaders

{
  "className": "PlainText_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Plain Text'\n        this.name = 'plainText'\n        this.version = 2.0\n        this.type = 'Document'\n        this.icon = 'plaintext.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from plain text`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Text',\n                name: 'text',\n                type: 'string',\n                rows: 4,\n                placeholder:\n                    'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...'\n            }",
  "if": "if (output === 'document') {\n            return docs\n        }",
  "for": "for (const doc of docs) {\n                finaltext += `${doc.pageContent}",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const text = nodeData.inputs?.text as string\n        const metadata = nodeData.inputs?.metadata\n        const output = nodeData.outputs?.output as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n\n        if (textSplitter) {\n            docs.push(...(await textSplitter.createDocuments([text])))\n        } else {\n            docs.push(\n                new Document({\n                    pageContent: text\n                })\n            )\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        if (output === 'document') {\n            return docs\n        } else {\n            let finaltext = ''\n            for (const doc of docs) {\n                finaltext += `${doc.pageContent}\\n`\n            }\n            return handleEscapeCharacters(finaltext, false)\n        }\n    }\n}"
}

## Playwright_DocumentLoaders

{
  "className": "Playwright_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Playwright Web Scraper'\n        this.name = 'playwrightWebScraper'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'playwright.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from webpages`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'URL',\n                name: 'url',\n                type: 'string'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "catch": "catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in PlaywrightWebBaseLoader: ${err.message}",
  "for": "for (const page of pages) {\n                docs.push(...(await playwrightLoader(page)))\n            }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const relativeLinksMethod = nodeData.inputs?.relativeLinksMethod as string\n        const selectedLinks = nodeData.inputs?.selectedLinks as string[]\n        let limit = parseInt(nodeData.inputs?.limit as string)\n        let waitUntilGoToOption = nodeData.inputs?.waitUntilGoToOption as 'load' | 'domcontentloaded' | 'networkidle' | 'commit' | undefined\n        let waitForSelector = nodeData.inputs?.waitForSelector as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let url = nodeData.inputs?.url as string\n        url = url.trim()\n        if (!test(url)) {\n            throw new Error('Invalid URL')\n        }\n\n        async function playwrightLoader(url: string): Promise<any> {\n            try {\n                let docs = []\n                const config: PlaywrightWebBaseLoaderOptions = {\n                    launchOptions: {\n                        args: ['--no-sandbox'],\n                        headless: true\n                    }\n                }\n                if (waitUntilGoToOption) {\n                    config['gotoOptions'] = {\n                        waitUntil: waitUntilGoToOption\n                    }\n                }\n                if (waitForSelector) {\n                    config['evaluate'] = async (page: Page, _: Browser): Promise<string> => {\n                        await page.waitForSelector(waitForSelector)\n\n                        const result = await page.evaluate(() => document.body.innerHTML)\n                        return result\n                    }\n                }\n                const loader = new PlaywrightWebBaseLoader(url, config)\n                if (textSplitter) {\n                    docs = await loader.load()\n                    docs = await textSplitter.splitDocuments(docs)\n                } else {\n                    docs = await loader.load()\n                }\n                return docs\n            } catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in PlaywrightWebBaseLoader: ${err.message}, on page: ${url}`)\n            }\n        }\n\n        let docs: IDocument[] = []\n        if (relativeLinksMethod) {\n            if (process.env.DEBUG === 'true') options.logger.info(`Start ${relativeLinksMethod}`)\n            // if limit is 0 we don't want it to default to 10 so we check explicitly for null or undefined\n            // so when limit is 0 we can fetch all the links\n            if (limit === null || limit === undefined) limit = 10\n            else if (limit < 0) throw new Error('Limit cannot be less than 0')\n            const pages: string[] =\n                selectedLinks && selectedLinks.length > 0\n                    ? selectedLinks.slice(0, limit === 0 ? undefined : limit)\n                    : relativeLinksMethod === 'webCrawl'\n                    ? await webCrawl(url, limit)\n                    : await xmlScrape(url, limit)\n            if (process.env.DEBUG === 'true') options.logger.info(`pages: ${JSON.stringify(pages)}, length: ${pages.length}`)\n            if (!pages || pages.length === 0) throw new Error('No relative links found')\n            for (const page of pages) {\n                docs.push(...(await playwrightLoader(page)))\n            }\n            if (process.env.DEBUG === 'true') options.logger.info(`Finish ${relativeLinksMethod}`)\n        } else if (selectedLinks && selectedLinks.length > 0) {\n            if (process.env.DEBUG === 'true')\n                options.logger.info(`pages: ${JSON.stringify(selectedLinks)}, length: ${selectedLinks.length}`)\n            for (const page of selectedLinks.slice(0, limit)) {\n                docs.push(...(await playwrightLoader(page)))\n            }\n        } else {\n            docs = await playwrightLoader(url)\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Puppeteer_DocumentLoaders

{
  "className": "Puppeteer_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Puppeteer Web Scraper'\n        this.name = 'puppeteerWebScraper'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'puppeteer.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from webpages`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'URL',\n                name: 'url',\n                type: 'string'\n            }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "catch": "catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in PuppeteerWebBaseLoader: ${err.message}",
  "for": "for (const page of pages) {\n                docs.push(...(await puppeteerLoader(page)))\n            }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const metadata = nodeData.inputs?.metadata\n        const relativeLinksMethod = nodeData.inputs?.relativeLinksMethod as string\n        const selectedLinks = nodeData.inputs?.selectedLinks as string[]\n        let limit = parseInt(nodeData.inputs?.limit as string)\n        let waitUntilGoToOption = nodeData.inputs?.waitUntilGoToOption as PuppeteerLifeCycleEvent\n        let waitForSelector = nodeData.inputs?.waitForSelector as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let url = nodeData.inputs?.url as string\n        url = url.trim()\n        if (!test(url)) {\n            throw new Error('Invalid URL')\n        }\n\n        async function puppeteerLoader(url: string): Promise<any> {\n            try {\n                let docs = []\n                const config: PuppeteerWebBaseLoaderOptions = {\n                    launchOptions: {\n                        args: ['--no-sandbox'],\n                        headless: 'new'\n                    }\n                }\n                if (waitUntilGoToOption) {\n                    config['gotoOptions'] = {\n                        waitUntil: waitUntilGoToOption\n                    }\n                }\n                if (waitForSelector) {\n                    config['evaluate'] = async (page: Page, _: Browser): Promise<string> => {\n                        await page.waitForSelector(waitForSelector)\n\n                        const result = await page.evaluate(() => document.body.innerHTML)\n                        return result\n                    }\n                }\n                const loader = new PuppeteerWebBaseLoader(url, config)\n                if (textSplitter) {\n                    docs = await loader.load()\n                    docs = await textSplitter.splitDocuments(docs)\n                } else {\n                    docs = await loader.load()\n                }\n                return docs\n            } catch (err) {\n                if (process.env.DEBUG === 'true') options.logger.error(`error in PuppeteerWebBaseLoader: ${err.message}, on page: ${url}`)\n            }\n        }\n\n        let docs: IDocument[] = []\n        if (relativeLinksMethod) {\n            if (process.env.DEBUG === 'true') options.logger.info(`Start ${relativeLinksMethod}`)\n            // if limit is 0 we don't want it to default to 10 so we check explicitly for null or undefined\n            // so when limit is 0 we can fetch all the links\n            if (limit === null || limit === undefined) limit = 10\n            else if (limit < 0) throw new Error('Limit cannot be less than 0')\n            const pages: string[] =\n                selectedLinks && selectedLinks.length > 0\n                    ? selectedLinks.slice(0, limit === 0 ? undefined : limit)\n                    : relativeLinksMethod === 'webCrawl'\n                    ? await webCrawl(url, limit)\n                    : await xmlScrape(url, limit)\n            if (process.env.DEBUG === 'true') options.logger.info(`pages: ${JSON.stringify(pages)}, length: ${pages.length}`)\n            if (!pages || pages.length === 0) throw new Error('No relative links found')\n            for (const page of pages) {\n                docs.push(...(await puppeteerLoader(page)))\n            }\n            if (process.env.DEBUG === 'true') options.logger.info(`Finish ${relativeLinksMethod}`)\n        } else if (selectedLinks && selectedLinks.length > 0) {\n            if (process.env.DEBUG === 'true')\n                options.logger.info(`pages: ${JSON.stringify(selectedLinks)}, length: ${selectedLinks.length}`)\n            for (const page of selectedLinks.slice(0, limit)) {\n                docs.push(...(await puppeteerLoader(page)))\n            }\n        } else {\n            docs = await puppeteerLoader(url)\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## S3_DocumentLoaders

{
  "className": "S3_DocumentLoaders",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'S3'\n        this.name = 'S3'\n        this.version = 3.0\n        this.type = 'Document'\n        this.icon = 's3.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load Data from S3 Buckets'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'AWS Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['awsApi'],\n            optional: true\n        }",
  "if": "if (metadata) {\n                    const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n                    docs = docs.map((doc) => ({\n                        ...doc,\n                        metadata:\n                            _omitMetadataKeys === '*'\n                                ? {\n                                      ...parsedMetadata\n                                  }",
  "catch": "catch (e: any) {\n                throw new Error(`Failed to download file ${keyName}",
  "outsideClass_bucketName": "const bucketName = nodeData.inputs?.bucketName as string\n        const keyName = nodeData.inputs?.keyName as string\n        const region = nodeData.inputs?.region as string\n        const unstructuredAPIUrl = nodeData.inputs?.unstructuredAPIUrl as string\n        const unstructuredAPIKey = nodeData.inputs?.unstructuredAPIKey as string\n        const strategy = nodeData.inputs?.strategy as UnstructuredLoaderStrategy\n        const encoding = nodeData.inputs?.encoding as string\n        const coordinates = nodeData.inputs?.coordinates as boolean\n        const skipInferTableTypes = nodeData.inputs?.skipInferTableTypes\n            ? JSON.parse(nodeData.inputs?.skipInferTableTypes as string)\n            : ([] as SkipInferTableTypes[])\n        const hiResModelName = nodeData.inputs?.hiResModelName as HiResModelName\n        const includePageBreaks = nodeData.inputs?.includePageBreaks as boolean\n        const chunkingStrategy = nodeData.inputs?.chunkingStrategy as 'None' | 'by_title'\n        const metadata = nodeData.inputs?.metadata\n        const sourceIdKey = (nodeData.inputs?.sourceIdKey as string) || 'source'\n        const ocrLanguages = nodeData.inputs?.ocrLanguages ? JSON.parse(nodeData.inputs?.ocrLanguages as string) : ([] as string[])\n        const xmlKeepTags = nodeData.inputs?.xmlKeepTags as boolean\n        const multiPageSections = nodeData.inputs?.multiPageSections as boolean\n        const combineUnderNChars = nodeData.inputs?.combineUnderNChars as number\n        const newAfterNChars = nodeData.inputs?.newAfterNChars as number\n        const maxCharacters = nodeData.inputs?.maxCharacters as number\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let credentials: S3ClientConfig['credentials'] | undefined\n\n        if (nodeData.credential) {\n            const credentialData = await getCredentialData(nodeData.credential, options)\n            const accessKeyId = getCredentialParam('awsKey', credentialData, nodeData)\n            const secretAccessKey = getCredentialParam('awsSecret', credentialData, nodeData)\n\n            if (accessKeyId && secretAccessKey) {\n                credentials = {\n                    accessKeyId,\n                    secretAccessKey\n                }\n            }\n        }\n\n        const s3Config: S3ClientConfig = {\n            region,\n            credentials\n        }\n\n        const loader = new S3Loader({\n            bucket: bucketName,\n            key: keyName,\n            s3Config,\n            unstructuredAPIURL: unstructuredAPIUrl,\n            unstructuredAPIKey: unstructuredAPIKey\n        })\n\n        loader.load = async () => {\n            const tempDir = fsDefault.mkdtempSync(path.join(os.tmpdir(), 's3fileloader-'))\n\n            const filePath = path.join(tempDir, keyName)\n\n            try {\n                const s3Client = new S3Client(s3Config)\n\n                const getObjectCommand = new GetObjectCommand({\n                    Bucket: bucketName,\n                    Key: keyName\n                })\n\n                const response = await s3Client.send(getObjectCommand)\n\n                const objectData = await new Promise<Buffer>((resolve, reject) => {\n                    const chunks: Buffer[] = []\n\n                    if (response.Body instanceof Readable) {\n                        response.Body.on('data', (chunk: Buffer) => chunks.push(chunk))\n                        response.Body.on('end', () => resolve(Buffer.concat(chunks)))\n                        response.Body.on('error', reject)\n                    } else {\n                        reject(new Error('Response body is not a readable stream.'))\n                    }\n                })\n\n                fsDefault.mkdirSync(path.dirname(filePath), { recursive: true })\n\n                fsDefault.writeFileSync(filePath, objectData)\n            } catch (e: any) {\n                throw new Error(`Failed to download file ${keyName} from S3 bucket ${bucketName}: ${e.message}`)\n            }\n\n            try {\n                const obj: UnstructuredLoaderOptions = {\n                    apiUrl: unstructuredAPIUrl,\n                    strategy,\n                    encoding,\n                    coordinates,\n                    skipInferTableTypes,\n                    hiResModelName,\n                    includePageBreaks,\n                    chunkingStrategy,\n                    ocrLanguages,\n                    xmlKeepTags,\n                    multiPageSections,\n                    combineUnderNChars,\n                    newAfterNChars,\n                    maxCharacters\n                }\n\n                if (unstructuredAPIKey) obj.apiKey = unstructuredAPIKey\n\n                const unstructuredLoader = new UnstructuredLoader(filePath, obj)\n\n                let docs = await unstructuredLoader.load()\n\n                if (metadata) {\n                    const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n                    docs = docs.map((doc) => ({\n                        ...doc,\n                        metadata:\n                            _omitMetadataKeys === '*'\n                                ? {\n                                      ...parsedMetadata\n                                  }\n                                : omit(\n                                      {\n                                          ...doc.metadata,\n                                          ...parsedMetadata,\n                                          [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                                      },\n                                      omitMetadataKeys\n                                  )\n                    }))\n                } else {\n                    docs = docs.map((doc) => ({\n                        ...doc,\n                        metadata:\n                            _omitMetadataKeys === '*'\n                                ? {}\n                                : omit(\n                                      {\n                                          ...doc.metadata,\n                                          [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                                      },\n                                      omitMetadataKeys\n                                  )\n                    }))\n                }\n\n                fsDefault.rmSync(path.dirname(filePath), { recursive: true })\n\n                return docs\n            } catch {\n                fsDefault.rmSync(path.dirname(filePath), { recursive: true })\n                throw new Error(`Failed to load file ${filePath} using unstructured loader.`)\n            }\n        }\n\n        return loader.load()\n    }\n}"
}

## SearchAPI_DocumentLoaders

{
  "className": "SearchAPI_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SearchApi For Web Search'\n        this.name = 'searchApi'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'searchapi.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load data from real-time search results'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: false,\n            credentialNames: ['searchApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const query = nodeData.inputs?.query as string\n        const customParameters = nodeData.inputs?.customParameters\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        // Fetch the API credentials for this node\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const searchApiKey = getCredentialParam('searchApiKey', credentialData, nodeData)\n\n        // Check and parse custom parameters (should be JSON or object)\n        const parsedParameters = typeof customParameters === 'object' ? customParameters : JSON.parse(customParameters || '{}')\n\n        // Prepare the configuration for the SearchApiLoader\n        const loaderConfig = {\n            q: query,\n            apiKey: searchApiKey,\n            ...parsedParameters\n        }\n\n        // Initialize the loader with the given configuration\n        const loader = new SearchApiLoader(loaderConfig)\n\n        // Fetch documents, split if a text splitter is provided\n        let docs: IDocument[] = []\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## SerpAPI_DocumentLoaders

{
  "className": "SerpAPI_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SerpApi For Web Search'\n        this.name = 'serpApi'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'serp.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Load and process data from web search results'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: false,\n            credentialNames: ['serpApi']\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const query = nodeData.inputs?.query as string\n        const metadata = nodeData.inputs?.metadata\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const serpApiKey = getCredentialParam('serpApiKey', credentialData, nodeData)\n        const loader = new SerpAPILoader({ q: query, apiKey: serpApiKey })\n\n        let docs: IDocument[] = []\n        if (textSplitter) {\n            docs = await loader.load()\n            docs = await textSplitter.splitDocuments(docs)\n        } else {\n            docs = await loader.load()\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## Spider_DocumentLoaders

{
  "className": "Spider_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Spider Document Loaders'\n        this.name = 'spiderDocumentLoaders'\n        this.version = 1.0\n        this.type = 'Document'\n        this.icon = 'spider.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Scrape & Crawl the web with Spider'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Text Splitter',\n                name: 'textSplitter',\n                type: 'TextSplitter',\n                optional: true\n            }",
  "if": "if (textSplitter) {\n            docs = await loader.loadAndSplit(textSplitter)\n        }",
  "catch": "catch (e) {\n                    console.error('Invalid JSON string provided for additional metadata')\n                }",
  "outsideClass_app": "const app = new SpiderApp({ apiKey: this.apiKey })\n        let spiderDocs: any[]\n\n        if (this.mode === 'scrape') {\n            const response = await app.scrapeUrl(this.url, this.params)\n            if (!response.success) {\n                throw new Error(`Spider: Failed to scrape URL. Error: ${response.error}`)\n            }\n            spiderDocs = [response.data]\n        } else if (this.mode === 'crawl') {\n            if (this.params) {\n                this.params.limit = this.limit\n            }\n            const response = await app.crawlUrl(this.url, this.params)\n            if (!response.success) {\n                throw new Error(`Spider: Failed to crawl URL. Error: ${response.error}`)\n            }\n            spiderDocs = response.data\n        } else {\n            throw new Error(`Unrecognized mode '${this.mode}'. Expected one of 'crawl', 'scrape'.`)\n        }\n\n        return spiderDocs.map(\n            (doc) =>\n                new Document({\n                    pageContent: doc.content || '',\n                    metadata: {\n                        ...(this.additionalMetadata || {}),\n                        source: doc.url\n                    }\n                })\n        )\n    }\n}",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const url = nodeData.inputs?.url as string\n        const mode = nodeData.inputs?.mode as 'crawl' | 'scrape'\n        const limit = nodeData.inputs?.limit as number\n        let additionalMetadata = nodeData.inputs?.additional_metadata\n        let params = nodeData.inputs?.params || {}\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const spiderApiKey = getCredentialParam('spiderApiKey', credentialData, nodeData)\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        if (typeof params === 'string') {\n            try {\n                params = JSON.parse(params)\n            } catch (e) {\n                console.error('Invalid JSON string provided for params')\n            }\n        }\n\n        if (additionalMetadata) {\n            if (typeof additionalMetadata === 'string') {\n                try {\n                    additionalMetadata = JSON.parse(additionalMetadata)\n                } catch (e) {\n                    console.error('Invalid JSON string provided for additional metadata')\n                }\n            } else if (typeof additionalMetadata !== 'object') {\n                console.error('Additional metadata must be a valid JSON object')\n            }\n        } else {\n            additionalMetadata = {}\n        }\n\n        // Ensure return_format is set to markdown\n        params.return_format = 'markdown'\n\n        const input: SpiderLoaderParameters = {\n            url,\n            mode: mode as 'crawl' | 'scrape',\n            apiKey: spiderApiKey,\n            limit: limit as number,\n            additionalMetadata: additionalMetadata as Record<string, unknown>,\n            params: params as Record<string, unknown>\n        }\n\n        const loader = new SpiderLoader(input)\n\n        let docs = []\n\n        if (textSplitter) {\n            docs = await loader.loadAndSplit(textSplitter)\n        } else {\n            docs = await loader.load()\n        }\n\n        docs = docs.map((doc: DocumentInterface) => ({\n            ...doc,\n            metadata:\n                _omitMetadataKeys === '*'\n                    ? additionalMetadata\n                    : omit(\n                          {\n                              ...doc.metadata,\n                              ...additionalMetadata\n                          },\n                          omitMetadataKeys\n                      )\n        }))\n\n        return docs\n    }\n}"
}

## Text_DocumentLoaders

{
  "className": "Text_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Text File'\n        this.name = 'textFile'\n        this.version = 3.0\n        this.type = 'Document'\n        this.icon = 'Txt.svg'\n        this.category = 'Document Loaders'\n        this.description = `Load data from text files`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Txt File',\n                name: 'txtFile',\n                type: 'file',\n                fileType:\n                    '.txt, .html, .aspx, .asp, .cpp, .c, .cs, .css, .go, .h, .java, .js, .less, .ts, .php, .proto, .python, .py, .rst, .ruby, .rb, .rs, .scala, .sc, .scss, .sol, .sql, .swift, .markdown, .md, .tex, .ltx, .vb, .xml'\n            }",
  "if": "if (output === 'document') {\n            return docs\n        }",
  "for": "for (const doc of docs) {\n                finaltext += `${doc.pageContent}",
  "outsideClass_textSplitter": "const textSplitter = nodeData.inputs?.textSplitter as TextSplitter\n        const txtFileBase64 = nodeData.inputs?.txtFile as string\n        const metadata = nodeData.inputs?.metadata\n        const output = nodeData.outputs?.output as string\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n        if (txtFileBase64.startsWith('FILE-STORAGE::')) {\n            const fileName = txtFileBase64.replace('FILE-STORAGE::', '')\n            if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                files = JSON.parse(fileName)\n            } else {\n                files = [fileName]\n            }\n            const chatflowid = options.chatflowid\n\n            for (const file of files) {\n                if (!file) continue\n                const fileData = await getFileFromStorage(file, chatflowid)\n                const blob = new Blob([fileData])\n                const loader = new TextLoader(blob)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        } else {\n            if (txtFileBase64.startsWith('[') && txtFileBase64.endsWith(']')) {\n                files = JSON.parse(txtFileBase64)\n            } else {\n                files = [txtFileBase64]\n            }\n\n            for (const file of files) {\n                if (!file) continue\n                const splitDataURI = file.split(',')\n                splitDataURI.pop()\n                const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                const blob = new Blob([bf])\n                const loader = new TextLoader(blob)\n\n                if (textSplitter) {\n                    let splittedDocs = await loader.load()\n                    splittedDocs = await textSplitter.splitDocuments(splittedDocs)\n                    docs.push(...splittedDocs)\n                } else {\n                    docs.push(...(await loader.load()))\n                }\n            }\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        if (output === 'document') {\n            return docs\n        } else {\n            let finaltext = ''\n            for (const doc of docs) {\n                finaltext += `${doc.pageContent}\\n`\n            }\n            return handleEscapeCharacters(finaltext, false)\n        }\n    }\n}"
}

## UnstructuredFile_DocumentLoaders

{
  "className": "UnstructuredFile_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Unstructured File Loader'\n        this.name = 'unstructuredFileLoader'\n        this.version = 3.0\n        this.type = 'Document'\n        this.icon = 'unstructured-file.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Use Unstructured.io to load data from a file path'\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['unstructuredApi'],\n            optional: true\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "for": "for (const file of files) {\n                    if (!file) continue\n                    const splitDataURI = file.split(',')\n                    const filename = splitDataURI.pop()?.split(':')[1] ?? ''\n                    const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                    const loaderDocs = await loader.loadAndSplitBuffer(bf, filename)\n                    docs.push(...loaderDocs)\n                }",
  "outsideClass_filePath": "const filePath = nodeData.inputs?.filePath as string\n        const unstructuredAPIUrl = nodeData.inputs?.unstructuredAPIUrl as string\n        const strategy = nodeData.inputs?.strategy as UnstructuredLoaderStrategy\n        const encoding = nodeData.inputs?.encoding as string\n        const coordinates = nodeData.inputs?.coordinates as boolean\n        const skipInferTableTypes = nodeData.inputs?.skipInferTableTypes\n            ? JSON.parse(nodeData.inputs?.skipInferTableTypes as string)\n            : ([] as SkipInferTableTypes[])\n        const hiResModelName = nodeData.inputs?.hiResModelName as HiResModelName\n        const includePageBreaks = nodeData.inputs?.includePageBreaks as boolean\n        const chunkingStrategy = nodeData.inputs?.chunkingStrategy as 'None' | 'by_title'\n        const metadata = nodeData.inputs?.metadata\n        const sourceIdKey = (nodeData.inputs?.sourceIdKey as string) || 'source'\n        const ocrLanguages = nodeData.inputs?.ocrLanguages ? JSON.parse(nodeData.inputs?.ocrLanguages as string) : ([] as string[])\n        const xmlKeepTags = nodeData.inputs?.xmlKeepTags as boolean\n        const multiPageSections = nodeData.inputs?.multiPageSections as boolean\n        const combineUnderNChars = nodeData.inputs?.combineUnderNChars as number\n        const newAfterNChars = nodeData.inputs?.newAfterNChars as number\n        const maxCharacters = nodeData.inputs?.maxCharacters as number\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n        // give priority to upload with upsert then to fileObject (upload from UI component)\n        const fileBase64 =\n            nodeData.inputs?.pdfFile ||\n            nodeData.inputs?.txtFile ||\n            nodeData.inputs?.yamlFile ||\n            nodeData.inputs?.docxFile ||\n            nodeData.inputs?.jsonlinesFile ||\n            nodeData.inputs?.csvFile ||\n            nodeData.inputs?.jsonFile ||\n            (nodeData.inputs?.fileObject as string)\n\n        const obj: UnstructuredLoaderOptions = {\n            apiUrl: unstructuredAPIUrl,\n            strategy,\n            encoding,\n            coordinates,\n            skipInferTableTypes,\n            hiResModelName,\n            includePageBreaks,\n            chunkingStrategy,\n            ocrLanguages,\n            xmlKeepTags,\n            multiPageSections,\n            combineUnderNChars,\n            newAfterNChars,\n            maxCharacters\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const unstructuredAPIKey = getCredentialParam('unstructuredAPIKey', credentialData, nodeData)\n        if (unstructuredAPIKey) obj.apiKey = unstructuredAPIKey\n\n        let docs: IDocument[] = []\n        let files: string[] = []\n\n        if (fileBase64) {\n            const loader = new UnstructuredLoader(obj)\n            //FILE-STORAGE::[\"CONTRIBUTING.md\",\"LICENSE.md\",\"README.md\"]\n            if (fileBase64.startsWith('FILE-STORAGE::')) {\n                const fileName = fileBase64.replace('FILE-STORAGE::', '')\n                if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                    files = JSON.parse(fileName)\n                } else {\n                    files = [fileName]\n                }\n                const chatflowid = options.chatflowid\n\n                for (const file of files) {\n                    if (!file) continue\n                    const fileData = await getFileFromStorage(file, chatflowid)\n                    const loaderDocs = await loader.loadAndSplitBuffer(fileData, file)\n                    docs.push(...loaderDocs)\n                }\n            } else {\n                if (fileBase64.startsWith('[') && fileBase64.endsWith(']')) {\n                    files = JSON.parse(fileBase64)\n                } else {\n                    files = [fileBase64]\n                }\n\n                for (const file of files) {\n                    if (!file) continue\n                    const splitDataURI = file.split(',')\n                    const filename = splitDataURI.pop()?.split(':')[1] ?? ''\n                    const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                    const loaderDocs = await loader.loadAndSplitBuffer(bf, filename)\n                    docs.push(...loaderDocs)\n                }\n            }\n        } else if (filePath) {\n            const loader = new LCUnstructuredLoader(filePath, obj)\n            const loaderDocs = await loader.load()\n            docs.push(...loaderDocs)\n        } else {\n            throw new Error('File path or File upload is required')\n        }\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata,\n                                  [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## UnstructuredFolder_DocumentLoaders

{
  "className": "UnstructuredFolder_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Unstructured Folder Loader'\n        this.name = 'unstructuredFolderLoader'\n        this.version = 2.0\n        this.type = 'Document'\n        this.icon = 'unstructured-folder.svg'\n        this.category = 'Document Loaders'\n        this.description =\n            \"Use Unstructured.io to load data from a folder. Note: Currently doesn't support .png and .heic until unstructured is updated.\"\n        this.baseClasses = [this.type]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['unstructuredApi'],\n            optional: true\n        }",
  "if": "if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }",
  "outsideClass_folderPath": "const folderPath = nodeData.inputs?.folderPath as string\n        const unstructuredAPIUrl = nodeData.inputs?.unstructuredAPIUrl as string\n        const strategy = nodeData.inputs?.strategy as UnstructuredLoaderStrategy\n        const encoding = nodeData.inputs?.encoding as string\n        const coordinates = nodeData.inputs?.coordinates as boolean\n        const skipInferTableTypes = nodeData.inputs?.skipInferTableTypes\n            ? JSON.parse(nodeData.inputs?.skipInferTableTypes as string)\n            : ([] as SkipInferTableTypes[])\n        const hiResModelName = nodeData.inputs?.hiResModelName as HiResModelName\n        const includePageBreaks = nodeData.inputs?.includePageBreaks as boolean\n        const chunkingStrategy = nodeData.inputs?.chunkingStrategy as 'None' | 'by_title'\n        const metadata = nodeData.inputs?.metadata\n        const sourceIdKey = (nodeData.inputs?.sourceIdKey as string) || 'source'\n        const ocrLanguages = nodeData.inputs?.ocrLanguages ? JSON.parse(nodeData.inputs?.ocrLanguages as string) : ([] as string[])\n        const xmlKeepTags = nodeData.inputs?.xmlKeepTags as boolean\n        const multiPageSections = nodeData.inputs?.multiPageSections as boolean\n        const combineUnderNChars = nodeData.inputs?.combineUnderNChars as number\n        const newAfterNChars = nodeData.inputs?.newAfterNChars as number\n        const maxCharacters = nodeData.inputs?.maxCharacters as number\n        const _omitMetadataKeys = nodeData.inputs?.omitMetadataKeys as string\n\n        let omitMetadataKeys: string[] = []\n        if (_omitMetadataKeys) {\n            omitMetadataKeys = _omitMetadataKeys.split(',').map((key) => key.trim())\n        }\n\n        const obj: UnstructuredLoaderOptions = {\n            apiUrl: unstructuredAPIUrl,\n            strategy,\n            encoding,\n            coordinates,\n            skipInferTableTypes,\n            hiResModelName,\n            includePageBreaks,\n            chunkingStrategy,\n            ocrLanguages,\n            xmlKeepTags,\n            multiPageSections,\n            combineUnderNChars,\n            newAfterNChars,\n            maxCharacters\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const unstructuredAPIKey = getCredentialParam('unstructuredAPIKey', credentialData, nodeData)\n        if (unstructuredAPIKey) obj.apiKey = unstructuredAPIKey\n\n        const loader = new UnstructuredDirectoryLoader(folderPath, obj)\n        let docs = await loader.load()\n\n        if (metadata) {\n            const parsedMetadata = typeof metadata === 'object' ? metadata : JSON.parse(metadata)\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {\n                              ...parsedMetadata\n                          }\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  ...parsedMetadata,\n                                  [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        } else {\n            docs = docs.map((doc) => ({\n                ...doc,\n                metadata:\n                    _omitMetadataKeys === '*'\n                        ? {}\n                        : omit(\n                              {\n                                  ...doc.metadata,\n                                  [sourceIdKey]: doc.metadata[sourceIdKey] || sourceIdKey\n                              },\n                              omitMetadataKeys\n                          )\n            }))\n        }\n\n        return docs\n    }\n}"
}

## VectorStoreToDocument_DocumentLoaders

{
  "className": "VectorStoreToDocument_DocumentLoaders",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'VectorStore To Document'\n        this.name = 'vectorStoreToDocument'\n        this.version = 2.0\n        this.type = 'Document'\n        this.icon = 'vectorretriever.svg'\n        this.category = 'Document Loaders'\n        this.description = 'Search documents with scores from vector store'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Vector Store',\n                name: 'vectorStore',\n                type: 'VectorStore'\n            }",
  "if": "if (output === 'document') {\n            let finaldocs = []\n            for (const doc of docs) {\n                if (minScore && doc[1] < minScore / 100) continue\n                finaldocs.push(doc[0])\n            }",
  "for": "for (const doc of docs) {\n                if (minScore && doc[1] < minScore / 100) continue\n                finaltext += `${doc[0].pageContent}",
  "outsideClass_vectorStore": "const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n        const minScore = nodeData.inputs?.minScore as number\n        const query = nodeData.inputs?.query as string\n        const output = nodeData.outputs?.output as string\n\n        const topK = (vectorStore as any)?.k ?? 4\n        const _filter = (vectorStore as any)?.filter\n\n        // If it is already pre-defined in lc_kwargs, then don't pass it again\n        const filter = vectorStore.lc_kwargs.filter ? undefined : _filter\n        if (vectorStore.lc_kwargs.filter) {\n            ;(vectorStore as any).filter = vectorStore.lc_kwargs.filter\n        }\n\n        const docs = await vectorStore.similaritySearchWithScore(query ?? input, topK, filter)\n        // eslint-disable-next-line no-console\n        console.log('\\x1b[94m\\x1b[1m\\n*****VectorStore Documents*****\\n\\x1b[0m\\x1b[0m')\n        // eslint-disable-next-line no-console\n        console.log(JSON.stringify(docs, null, 2))\n\n        if (output === 'document') {\n            let finaldocs = []\n            for (const doc of docs) {\n                if (minScore && doc[1] < minScore / 100) continue\n                finaldocs.push(doc[0])\n            }\n            return finaldocs\n        } else {\n            let finaltext = ''\n            for (const doc of docs) {\n                if (minScore && doc[1] < minScore / 100) continue\n                finaltext += `${doc[0].pageContent}\\n`\n            }\n            return handleEscapeCharacters(finaltext, false)\n        }\n    }\n}"
}

## AWSBedrockEmbedding_Embeddings

{
  "className": "AWSBedrockEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'AWS Bedrock Embeddings'\n        this.name = 'AWSBedrockEmbeddings'\n        this.version = 5.0\n        this.type = 'AWSBedrockEmbeddings'\n        this.icon = 'aws.svg'\n        this.category = 'Embeddings'\n        this.description = 'AWSBedrock embedding models to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(BedrockEmbeddings)]\n        this.credential = {\n            label: 'AWS Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['awsApi'],\n            optional: true\n        }",
  "catch": "catch (e) {\n            if (retryCounter < maxRetries && e.name.includes('ThrottlingException')) {\n                retryCounter = retryCounter + 1\n                i = i - batchSize\n                sleepTime = sleepTime + 100\n            }",
  "for": "for (let i = 0; i < documents.length; i += batchSize) {\n        let chunk = documents.slice(i, i + batchSize)\n        try {\n            let chunkResult = await Promise.all(chunk.map(processFunc))\n            result.push(...chunkResult)\n            retryCounter = 0\n        }",
  "outsideClass_iRegion": "const iRegion = nodeData.inputs?.region as string\n        const iModel = nodeData.inputs?.model as string\n        const customModel = nodeData.inputs?.customModel as string\n        const inputType = nodeData.inputs?.inputType as string\n\n        if (iModel.startsWith('cohere') && !inputType) {\n            throw new Error('Input Type must be selected for Cohere models.')\n        }\n\n        const obj: BedrockEmbeddingsParams = {\n            model: customModel ? customModel : iModel,\n            region: iRegion\n        }\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        if (credentialData && Object.keys(credentialData).length !== 0) {\n            const credentialApiKey = getCredentialParam('awsKey', credentialData, nodeData)\n            const credentialApiSecret = getCredentialParam('awsSecret', credentialData, nodeData)\n            const credentialApiSession = getCredentialParam('awsSession', credentialData, nodeData)\n\n            obj.credentials = {\n                accessKeyId: credentialApiKey,\n                secretAccessKey: credentialApiSecret,\n                sessionToken: credentialApiSession\n            }\n        }\n\n        const client = new BedrockRuntimeClient({\n            region: obj.region,\n            credentials: obj.credentials\n        })\n\n        const model = new BedrockEmbeddings(obj)\n\n        model.embedQuery = async (document: string): Promise<number[]> => {\n            if (iModel.startsWith('cohere')) {\n                const embeddings = await embedTextCohere([document], client, iModel, inputType)\n                return embeddings[0]\n            } else {\n                return await embedTextTitan(document, client, iModel)\n            }\n        }\n\n        model.embedDocuments = async (documents: string[]): Promise<number[][]> => {\n            if (iModel.startsWith('cohere')) {\n                return await embedTextCohere(documents, client, iModel, inputType)\n            } else {\n                const batchSize = nodeData.inputs?.batchSize as number\n                const maxRetries = nodeData.inputs?.maxRetries as number\n                return processInBatches(documents, batchSize, maxRetries, (document) => embedTextTitan(document, client, iModel))\n            }\n        }\n        return model\n    }\n}\n\nconst embedTextTitan = async (text: string, client: BedrockRuntimeClient, model: string): Promise<number[]> => {\n    const cleanedText = text.replace(/\\n/g, ' ')\n\n    const res = await client.send(\n        new InvokeModelCommand({\n            modelId: model,\n            body: JSON.stringify({\n                inputText: cleanedText\n            }),\n            contentType: 'application/json',\n            accept: 'application/json'\n        })\n    )\n\n    try {\n        const body = new TextDecoder().decode(res.body)\n        return JSON.parse(body).embedding\n    } catch (e) {\n        throw new Error('An invalid response was returned by Bedrock.')\n    }\n}\n\nconst embedTextCohere = async (texts: string[], client: BedrockRuntimeClient, model: string, inputType: string): Promise<number[][]> => {\n    const cleanedTexts = texts.map((text) => text.replace(/\\n/g, ' '))\n\n    const command = {\n        modelId: model,\n        body: JSON.stringify({\n            texts: cleanedTexts,\n            input_type: inputType,\n            truncate: 'END'\n        }),\n        contentType: 'application/json',\n        accept: 'application/json'\n    }\n    const res = await client.send(new InvokeModelCommand(command))\n    try {\n        const body = new TextDecoder().decode(res.body)\n        return JSON.parse(body).embeddings\n    } catch (e) {\n        throw new Error('An invalid response was returned by Bedrock.')\n    }\n}\n\nconst processInBatches = async (\n    documents: string[],\n    batchSize: number,\n    maxRetries: number,\n    processFunc: (document: string) => Promise<number[]>\n): Promise<number[][]> => {\n    let sleepTime = 0\n    let retryCounter = 0\n    let result: number[][] = []\n    for (let i = 0; i < documents.length; i += batchSize) {\n        let chunk = documents.slice(i, i + batchSize)\n        try {\n            let chunkResult = await Promise.all(chunk.map(processFunc))\n            result.push(...chunkResult)\n            retryCounter = 0\n        } catch (e) {\n            if (retryCounter < maxRetries && e.name.includes('ThrottlingException')) {\n                retryCounter = retryCounter + 1\n                i = i - batchSize\n                sleepTime = sleepTime + 100\n            } else {\n                // Split to distinguish between throttling retry error and other errors in trance\n                if (e.name.includes('ThrottlingException')) {\n                    throw new Error('AWS Bedrock retry limit reached: ' + e)\n                } else {\n                    throw new Error(e)\n                }\n            }\n        }\n        await new Promise((resolve) => setTimeout(resolve, sleepTime))\n    }\n    return result\n}"
}

## AzureOpenAIEmbedding_Embeddings

{
  "className": "AzureOpenAIEmbedding_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Azure OpenAI Embeddings'\n        this.name = 'azureOpenAIEmbeddings'\n        this.version = 1.0\n        this.type = 'AzureOpenAIEmbeddings'\n        this.icon = 'Azure.svg'\n        this.category = 'Embeddings'\n        this.description = 'Azure OpenAI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['azureOpenAIApi']\n        }",
  "outsideClass_batchSize": "const batchSize = nodeData.inputs?.batchSize as string\n        const timeout = nodeData.inputs?.timeout as string\n        const basePath = nodeData.inputs?.basepath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const azureOpenAIApiKey = getCredentialParam('azureOpenAIApiKey', credentialData, nodeData)\n        const azureOpenAIApiInstanceName = getCredentialParam('azureOpenAIApiInstanceName', credentialData, nodeData)\n        const azureOpenAIApiDeploymentName = getCredentialParam('azureOpenAIApiDeploymentName', credentialData, nodeData)\n        const azureOpenAIApiVersion = getCredentialParam('azureOpenAIApiVersion', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbeddingsParams> & Partial<AzureOpenAIInput> = {\n            azureOpenAIApiKey,\n            azureOpenAIApiInstanceName,\n            azureOpenAIApiDeploymentName,\n            azureOpenAIApiVersion,\n            azureOpenAIBasePath: basePath\n        }\n\n        if (batchSize) obj.batchSize = parseInt(batchSize, 10)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n\n        const model = new OpenAIEmbeddings(obj)\n        return model\n    }\n}"
}

## AzureOpenAIEmbedding_LlamaIndex_Embeddings

{
  "className": "AzureOpenAIEmbedding_LlamaIndex_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Azure OpenAI Embeddings'\n        this.name = 'azureOpenAIEmbeddingsLlamaIndex'\n        this.version = 1.0\n        this.type = 'AzureOpenAIEmbeddings'\n        this.icon = 'Azure.svg'\n        this.category = 'Embeddings'\n        this.description = 'Azure OpenAI API embeddings specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseEmbedding_LlamaIndex', ...getBaseClasses(OpenAIEmbedding)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['azureOpenAIApi']\n        }",
  "outsideClass_timeout": "const timeout = nodeData.inputs?.timeout as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const azureOpenAIApiKey = getCredentialParam('azureOpenAIApiKey', credentialData, nodeData)\n        const azureOpenAIApiInstanceName = getCredentialParam('azureOpenAIApiInstanceName', credentialData, nodeData)\n        const azureOpenAIApiDeploymentName = getCredentialParam('azureOpenAIApiDeploymentName', credentialData, nodeData)\n        const azureOpenAIApiVersion = getCredentialParam('azureOpenAIApiVersion', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbedding> & { azure?: AzureOpenAIConfig } = {\n            azure: {\n                apiKey: azureOpenAIApiKey,\n                endpoint: `https://${azureOpenAIApiInstanceName}.openai.azure.com`,\n                apiVersion: azureOpenAIApiVersion,\n                deploymentName: azureOpenAIApiDeploymentName\n            }\n        }\n\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n\n        const model = new OpenAIEmbedding(obj)\n        return model\n    }\n}"
}

## CohereEmbedding_Embeddings

{
  "className": "CohereEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Cohere Embeddings'\n        this.name = 'cohereEmbeddings'\n        this.version = 3.0\n        this.type = 'CohereEmbeddings'\n        this.icon = 'Cohere.svg'\n        this.category = 'Embeddings'\n        this.description = 'Cohere API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(CohereEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['cohereApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const inputType = nodeData.inputs?.inputType as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const cohereApiKey = getCredentialParam('cohereApiKey', credentialData, nodeData)\n\n        const obj: Partial<CohereEmbeddingsParams> & { apiKey?: string } = {\n            apiKey: cohereApiKey\n        }\n\n        if (modelName) obj.model = modelName\n        if (inputType) obj.inputType = inputType\n\n        const model = new CohereEmbeddings(obj)\n        return model\n    }\n}"
}

## GoogleGenerativeAIEmbedding_Embeddings

{
  "className": "GoogleGenerativeAIEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GoogleGenerativeAI Embeddings'\n        this.name = 'googleGenerativeAiEmbeddings'\n        this.version = 2.0\n        this.type = 'GoogleGenerativeAiEmbeddings'\n        this.icon = 'GoogleGemini.svg'\n        this.category = 'Embeddings'\n        this.description = 'Google Generative API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(GoogleGenerativeAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleGenerativeAI'],\n            optional: false,\n            description: 'Google Generative AI credential.'\n        }",
  "switch": "switch (nodeData.inputs?.tasktype as string) {\n            case 'RETRIEVAL_QUERY':\n                taskType = TaskType.RETRIEVAL_QUERY\n                break\n            case 'RETRIEVAL_DOCUMENT':\n                taskType = TaskType.RETRIEVAL_DOCUMENT\n                break\n            case 'SEMANTIC_SIMILARITY':\n                taskType = TaskType.SEMANTIC_SIMILARITY\n                break\n            case 'CLASSIFICATION':\n                taskType = TaskType.CLASSIFICATION\n                break\n            case 'CLUSTERING':\n                taskType = TaskType.CLUSTERING\n                break\n            default:\n                taskType = TaskType.TASK_TYPE_UNSPECIFIED\n                break\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('googleGenerativeAPIKey', credentialData, nodeData)\n\n        let taskType: TaskType\n        switch (nodeData.inputs?.tasktype as string) {\n            case 'RETRIEVAL_QUERY':\n                taskType = TaskType.RETRIEVAL_QUERY\n                break\n            case 'RETRIEVAL_DOCUMENT':\n                taskType = TaskType.RETRIEVAL_DOCUMENT\n                break\n            case 'SEMANTIC_SIMILARITY':\n                taskType = TaskType.SEMANTIC_SIMILARITY\n                break\n            case 'CLASSIFICATION':\n                taskType = TaskType.CLASSIFICATION\n                break\n            case 'CLUSTERING':\n                taskType = TaskType.CLUSTERING\n                break\n            default:\n                taskType = TaskType.TASK_TYPE_UNSPECIFIED\n                break\n        }\n        const obj: GoogleGenerativeAIEmbeddingsParams = {\n            apiKey: apiKey,\n            modelName: modelName,\n            taskType: taskType\n        }\n\n        const model = new GoogleGenerativeAIEmbeddings(obj)\n        return model\n    }\n}"
}

## GooglePaLMEmbedding_Embeddings

{
  "className": "GooglePaLMEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Google PaLM Embeddings'\n        this.name = 'googlePaLMEmbeddings'\n        this.version = 2.0\n        this.type = 'GooglePaLMEmbeddings'\n        this.icon = 'GooglePaLM.svg'\n        this.category = 'Embeddings'\n        this.description = 'Google MakerSuite PaLM API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(GooglePaLMEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleMakerSuite']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleMakerSuiteKey = getCredentialParam('googleMakerSuiteKey', credentialData, nodeData)\n\n        const obj: Partial<GooglePaLMEmbeddingsParams> = {\n            modelName: modelName,\n            apiKey: googleMakerSuiteKey\n        }\n\n        const model = new GooglePaLMEmbeddings(obj)\n        return model\n    }\n}"
}

## GoogleVertexAIEmbedding_Embeddings

{
  "className": "GoogleVertexAIEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GoogleVertexAI Embeddings'\n        this.name = 'googlevertexaiEmbeddings'\n        this.version = 2.0\n        this.type = 'GoogleVertexAIEmbeddings'\n        this.icon = 'GoogleVertex.svg'\n        this.category = 'Embeddings'\n        this.description = 'Google vertexAI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(GoogleVertexAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleVertexAuth'],\n            optional: true,\n            description:\n                'Google Vertex AI credential. If you are using a GCP service like Cloud Run, or if you have installed default credentials on your local machine, you do not need to set this credential.'\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const modelName = nodeData.inputs?.modelName as string\n        const googleApplicationCredentialFilePath = getCredentialParam('googleApplicationCredentialFilePath', credentialData, nodeData)\n        const googleApplicationCredential = getCredentialParam('googleApplicationCredential', credentialData, nodeData)\n        const projectID = getCredentialParam('projectID', credentialData, nodeData)\n\n        const authOptions: GoogleAuthOptions = {}\n        if (Object.keys(credentialData).length !== 0) {\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error('Please specify your Google Application Credential')\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error(\n                    'Error: More than one component has been inputted. Please use only one of the following: Google Application Credential File Path or Google Credential JSON Object'\n                )\n\n            if (googleApplicationCredentialFilePath && !googleApplicationCredential)\n                authOptions.keyFile = googleApplicationCredentialFilePath\n            else if (!googleApplicationCredentialFilePath && googleApplicationCredential)\n                authOptions.credentials = JSON.parse(googleApplicationCredential)\n\n            if (projectID) authOptions.projectId = projectID\n        }\n        const obj: GoogleVertexAIEmbeddingsParams = {}\n        if (modelName) obj.model = modelName\n        if (Object.keys(authOptions).length !== 0) obj.authOptions = authOptions\n\n        const model = new GoogleVertexAIEmbeddings(obj)\n        return model\n    }\n}"
}

## HuggingFaceInferenceEmbedding_Embeddings

{
  "className": "HuggingFaceInferenceEmbedding_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'HuggingFace Inference Embeddings'\n        this.name = 'huggingFaceInferenceEmbeddings'\n        this.version = 1.0\n        this.type = 'HuggingFaceInferenceEmbeddings'\n        this.icon = 'HuggingFace.svg'\n        this.category = 'Embeddings'\n        this.description = 'HuggingFace Inference API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(HuggingFaceInferenceEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['huggingFaceApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const endpoint = nodeData.inputs?.endpoint as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const huggingFaceApiKey = getCredentialParam('huggingFaceApiKey', credentialData, nodeData)\n\n        const obj: Partial<HuggingFaceInferenceEmbeddingsParams> = {\n            apiKey: huggingFaceApiKey\n        }\n\n        if (modelName) obj.model = modelName\n        if (endpoint) obj.endpoint = endpoint\n\n        const model = new HuggingFaceInferenceEmbeddings(obj)\n        return model\n    }\n}"
}

## LocalAIEmbedding_Embeddings

{
  "className": "LocalAIEmbedding_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'LocalAI Embeddings'\n        this.name = 'localAIEmbeddings'\n        this.version = 1.0\n        this.type = 'LocalAI Embeddings'\n        this.icon = 'localai.png'\n        this.category = 'Embeddings'\n        this.description = 'Use local embeddings models like llama.cpp'\n        this.baseClasses = [this.type, 'Embeddings']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['localAIApi'],\n            optional: true\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const basePath = nodeData.inputs?.basePath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const localAIApiKey = getCredentialParam('localAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbeddingsParams> & { openAIApiKey?: string } = {\n            modelName,\n            openAIApiKey: 'sk-'\n        }\n\n        if (localAIApiKey) obj.openAIApiKey = localAIApiKey\n\n        const model = new OpenAIEmbeddings(obj, { basePath })\n\n        return model\n    }\n}"
}

## MistralEmbedding_Embeddings

{
  "className": "MistralEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'MistralAI Embeddings'\n        this.name = 'mistralAIEmbeddings'\n        this.version = 2.0\n        this.type = 'MistralAIEmbeddings'\n        this.icon = 'MistralAI.svg'\n        this.category = 'Embeddings'\n        this.description = 'MistralAI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(MistralAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['mistralAIApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const batchSize = nodeData.inputs?.batchSize as string\n        const stripNewLines = nodeData.inputs?.stripNewLines as boolean\n        const overrideEndpoint = nodeData.inputs?.overrideEndpoint as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('mistralAIAPIKey', credentialData, nodeData)\n\n        const obj: MistralAIEmbeddingsParams = {\n            apiKey: apiKey,\n            modelName: modelName\n        }\n\n        if (batchSize) obj.batchSize = parseInt(batchSize, 10)\n        if (stripNewLines) obj.stripNewLines = stripNewLines\n        if (overrideEndpoint) obj.endpoint = overrideEndpoint\n\n        const model = new MistralAIEmbeddings(obj)\n        return model\n    }\n}"
}

## OllamaEmbedding_Embeddings

{
  "className": "OllamaEmbedding_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Ollama Embeddings'\n        this.name = 'ollamaEmbedding'\n        this.version = 1.0\n        this.type = 'OllamaEmbeddings'\n        this.icon = 'Ollama.svg'\n        this.category = 'Embeddings'\n        this.description = 'Generate embeddings for a given text using open source model on Ollama'\n        this.baseClasses = [this.type, ...getBaseClasses(OllamaEmbeddings)]\n        this.inputs = [\n            {\n                label: 'Base URL',\n                name: 'baseUrl',\n                type: 'string',\n                default: 'http://localhost:11434'\n            }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const numThread = nodeData.inputs?.numThread as string\n        const numGpu = nodeData.inputs?.numGpu as string\n        const useMMap = nodeData.inputs?.useMMap as boolean\n\n        const obj = {\n            model: modelName,\n            baseUrl,\n            requestOptions: {}\n        }\n\n        const requestOptions: OllamaInput = {}\n        if (numThread) requestOptions.numThread = parseFloat(numThread)\n        if (numGpu) requestOptions.numGpu = parseFloat(numGpu)\n\n        // default useMMap to true\n        requestOptions.useMMap = useMMap === undefined ? true : useMMap\n\n        if (Object.keys(requestOptions).length) obj.requestOptions = requestOptions\n\n        const model = new OllamaEmbeddings(obj)\n        return model\n    }\n}"
}

## OpenAIEmbedding_Embeddings

{
  "className": "OpenAIEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAI Embeddings'\n        this.name = 'openAIEmbeddings'\n        this.version = 4.0\n        this.type = 'OpenAIEmbeddings'\n        this.icon = 'openai.svg'\n        this.category = 'Embeddings'\n        this.description = 'OpenAI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "if": "if (nodeData.inputs?.credentialId) {\n            nodeData.credential = nodeData.inputs?.credentialId\n        }",
  "outsideClass_stripNewLines": "const stripNewLines = nodeData.inputs?.stripNewLines as boolean\n        const batchSize = nodeData.inputs?.batchSize as string\n        const timeout = nodeData.inputs?.timeout as string\n        const basePath = nodeData.inputs?.basepath as string\n        const modelName = nodeData.inputs?.modelName as string\n        const dimensions = nodeData.inputs?.dimensions as string\n\n        if (nodeData.inputs?.credentialId) {\n            nodeData.credential = nodeData.inputs?.credentialId\n        }\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbeddingsParams> & { openAIApiKey?: string } = {\n            openAIApiKey,\n            modelName\n        }\n\n        if (stripNewLines) obj.stripNewLines = stripNewLines\n        if (batchSize) obj.batchSize = parseInt(batchSize, 10)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (dimensions) obj.dimensions = parseInt(dimensions, 10)\n\n        const model = new OpenAIEmbeddings(obj, { basePath })\n        return model\n    }\n}"
}

## OpenAIEmbedding_LlamaIndex_Embeddings

{
  "className": "OpenAIEmbedding_LlamaIndex_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAI Embedding'\n        this.name = 'openAIEmbedding_LlamaIndex'\n        this.version = 2.0\n        this.type = 'OpenAIEmbedding'\n        this.icon = 'openai.svg'\n        this.category = 'Embeddings'\n        this.description = 'OpenAI Embedding specific for LlamaIndex'\n        this.baseClasses = [this.type, 'BaseEmbedding_LlamaIndex', ...getBaseClasses(OpenAIEmbedding)]\n        this.tags = ['LlamaIndex']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "if": "if (basePath) {\n            obj.additionalSessionOptions = {\n                baseURL: basePath\n            }",
  "outsideClass_timeout": "const timeout = nodeData.inputs?.timeout as string\n        const modelName = nodeData.inputs?.modelName as string\n        const basePath = nodeData.inputs?.basepath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbedding> = {\n            apiKey: openAIApiKey,\n            model: modelName\n        }\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (basePath) {\n            obj.additionalSessionOptions = {\n                baseURL: basePath\n            }\n        }\n        const model = new OpenAIEmbedding(obj)\n        return model\n    }\n}"
}

## OpenAIEmbeddingCustom_Embeddings

{
  "className": "OpenAIEmbeddingCustom_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAI Embeddings Custom'\n        this.name = 'openAIEmbeddingsCustom'\n        this.version = 2.0\n        this.type = 'OpenAIEmbeddingsCustom'\n        this.icon = 'openai.svg'\n        this.category = 'Embeddings'\n        this.description = 'OpenAI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "outsideClass_stripNewLines": "const stripNewLines = nodeData.inputs?.stripNewLines as boolean\n        const batchSize = nodeData.inputs?.batchSize as string\n        const timeout = nodeData.inputs?.timeout as string\n        const basePath = nodeData.inputs?.basepath as string\n        const modelName = nodeData.inputs?.modelName as string\n        const dimensions = nodeData.inputs?.dimensions as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<OpenAIEmbeddingsParams> & { openAIApiKey?: string } = {\n            openAIApiKey\n        }\n\n        if (stripNewLines) obj.stripNewLines = stripNewLines\n        if (batchSize) obj.batchSize = parseInt(batchSize, 10)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (modelName) obj.modelName = modelName\n        if (dimensions) obj.dimensions = parseInt(dimensions, 10)\n\n        const model = new OpenAIEmbeddings(obj, { basePath })\n        return model\n    }\n}"
}

## TogetherAIEmbedding_Embeddings

{
  "className": "TogetherAIEmbedding_Embeddings",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'TogetherAIEmbedding'\n        this.name = 'togetherAIEmbedding'\n        this.version = 1.0\n        this.type = 'TogetherAIEmbedding'\n        this.icon = 'togetherai.png'\n        this.category = 'Embeddings'\n        this.description = 'TogetherAI Embedding models to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(TogetherAIEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['togetherAIApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const togetherAIApiKey = getCredentialParam('togetherAIApiKey', credentialData, nodeData)\n\n        const obj: Partial<TogetherAIEmbeddingsParams> = {\n            modelName: modelName,\n            apiKey: togetherAIApiKey,\n            model: modelName\n        }\n\n        const model = new TogetherAIEmbeddings(obj)\n        return model\n    }\n}"
}

## VoyageAIEmbedding_Embeddings

{
  "className": "VoyageAIEmbedding_Embeddings",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'VoyageAI Embeddings'\n        this.name = 'voyageAIEmbeddings'\n        this.version = 2.0\n        this.type = 'VoyageAIEmbeddings'\n        this.icon = 'voyageai.png'\n        this.category = 'Embeddings'\n        this.description = 'Voyage AI API to generate embeddings for a given text'\n        this.baseClasses = [this.type, ...getBaseClasses(VoyageEmbeddings)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['voyageAIApi']\n        }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const voyageAiApiKey = getCredentialParam('apiKey', credentialData, nodeData)\n        const voyageAiEndpoint = getCredentialParam('endpoint', credentialData, nodeData)\n\n        const obj: Partial<VoyageEmbeddingsParams> & { apiKey?: string } = {\n            apiKey: voyageAiApiKey\n        }\n\n        if (modelName) obj.modelName = modelName\n\n        const model = new VoyageEmbeddings(obj)\n        if (voyageAiEndpoint) model.apiUrl = voyageAiEndpoint\n        return model\n    }\n}"
}

## ContextChatEngine_LlamaIndex

{
  "className": "ContextChatEngine_LlamaIndex",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Context Chat Engine'\n        this.name = 'contextChatEngine'\n        this.version = 1.0\n        this.type = 'ContextChatEngine'\n        this.icon = 'context-chat-engine.png'\n        this.category = 'Engine'\n        this.description = 'Answer question based on retrieved documents (context) with built-in memory to remember conversation'\n        this.baseClasses = [this.type]\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel_LlamaIndex'\n            }",
  "if": "if (returnSourceDocuments) {\n                sourceDocuments = reformatSourceDocuments(sourceNodes)\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n            }",
  "for": "for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                }",
  "await": "await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }",
  "outsideClass_model": "const model = nodeData.inputs?.model as LLM\n        const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever as BaseRetriever\n        const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const memory = nodeData.inputs?.memory as FlowiseMemory\n        const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n        const prependMessages = options?.prependMessages\n\n        const chatHistory = [] as ChatMessage[]\n\n        if (systemMessagePrompt) {\n            chatHistory.push({\n                content: systemMessagePrompt,\n                role: 'user'\n            })\n        }\n\n        const chatEngine = new ContextChatEngine({ chatModel: model, retriever: vectorStoreRetriever })\n\n        const msgs = (await memory.getChatMessages(this.sessionId, false, prependMessages)) as IMessage[]\n        for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                })\n            } else if (message.type === 'userMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'user'\n                })\n            }\n        }\n\n        let text = ''\n        let isStreamingStarted = false\n        let sourceDocuments: ICommonObject[] = []\n        let sourceNodes: NodeWithScore<Metadata>[] = []\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        if (isStreamingEnabled) {\n            const stream = await chatEngine.chat({ message: input, chatHistory, stream: true })\n            for await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }\n\n                options.socketIO.to(options.socketIOClientId).emit('token', chunk.response)\n            }\n\n            if (returnSourceDocuments) {\n                sourceDocuments = reformatSourceDocuments(sourceNodes)\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n            }\n        } else {\n            const response = await chatEngine.chat({ message: input, chatHistory })\n            text = response?.response\n            sourceDocuments = reformatSourceDocuments(response?.sourceNodes ?? [])\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: text,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        if (returnSourceDocuments) return { text, sourceDocuments }\n        else return { text }\n    }\n}"
}

## SimpleChatEngine_LlamaIndex

{
  "className": "SimpleChatEngine_LlamaIndex",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Simple Chat Engine'\n        this.name = 'simpleChatEngine'\n        this.version = 1.0\n        this.type = 'SimpleChatEngine'\n        this.icon = 'chat-engine.png'\n        this.category = 'Engine'\n        this.description = 'Simple engine to handle back and forth conversations'\n        this.baseClasses = [this.type]\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel_LlamaIndex'\n            }",
  "if": "if (isStreamingEnabled) {\n            const stream = await chatEngine.chat({ message: input, chatHistory, stream: true }",
  "for": "for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                }",
  "await": "await (const chunk of stream) {\n                text += chunk.response\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }",
  "outsideClass_model": "const model = nodeData.inputs?.model as LLM\n        const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const memory = nodeData.inputs?.memory as FlowiseMemory\n        const prependMessages = options?.prependMessages\n\n        const chatHistory = [] as ChatMessage[]\n\n        if (systemMessagePrompt) {\n            chatHistory.push({\n                content: systemMessagePrompt,\n                role: 'user'\n            })\n        }\n\n        const chatEngine = new SimpleChatEngine({ llm: model })\n\n        const msgs = (await memory.getChatMessages(this.sessionId, false, prependMessages)) as IMessage[]\n        for (const message of msgs) {\n            if (message.type === 'apiMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'assistant'\n                })\n            } else if (message.type === 'userMessage') {\n                chatHistory.push({\n                    content: message.message,\n                    role: 'user'\n                })\n            }\n        }\n\n        let text = ''\n        let isStreamingStarted = false\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        if (isStreamingEnabled) {\n            const stream = await chatEngine.chat({ message: input, chatHistory, stream: true })\n            for await (const chunk of stream) {\n                text += chunk.response\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }\n\n                options.socketIO.to(options.socketIOClientId).emit('token', chunk.response)\n            }\n        } else {\n            const response = await chatEngine.chat({ message: input, chatHistory })\n            text = response?.response\n        }\n\n        await memory.addChatMessages(\n            [\n                {\n                    text: input,\n                    type: 'userMessage'\n                },\n                {\n                    text: text,\n                    type: 'apiMessage'\n                }\n            ],\n            this.sessionId\n        )\n\n        return text\n    }\n}"
}

## QueryEngine_LlamaIndex

{
  "className": "QueryEngine_LlamaIndex",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Query Engine'\n        this.name = 'queryEngine'\n        this.version = 2.0\n        this.type = 'QueryEngine'\n        this.icon = 'query-engine.png'\n        this.category = 'Engine'\n        this.description = 'Simple query engine built to answer question over your data, without memory'\n        this.baseClasses = [this.type, 'BaseQueryEngine']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Vector Store Retriever',\n                name: 'vectorStoreRetriever',\n                type: 'VectorIndexRetriever'\n            }",
  "if": "if (responseSynthesizerObj.type === 'SimpleResponseBuilder') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new SimpleResponseBuilder(vectorStoreRetriever.serviceContext),\n                serviceContext: vectorStoreRetriever.serviceContext\n            }",
  "await": "await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }",
  "outsideClass_returnSourceDocuments": "const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n        const queryEngine = prepareEngine(nodeData)\n\n        let text = ''\n        let sourceDocuments: ICommonObject[] = []\n        let sourceNodes: NodeWithScore<Metadata>[] = []\n        let isStreamingStarted = false\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        if (isStreamingEnabled) {\n            const stream = await queryEngine.query({ query: input, stream: true })\n            for await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }\n\n                options.socketIO.to(options.socketIOClientId).emit('token', chunk.response)\n            }\n\n            if (returnSourceDocuments) {\n                sourceDocuments = reformatSourceDocuments(sourceNodes)\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n            }\n        } else {\n            const response = await queryEngine.query({ query: input })\n            text = response?.response\n            sourceDocuments = reformatSourceDocuments(response?.sourceNodes ?? [])\n        }\n\n        if (returnSourceDocuments) return { text, sourceDocuments }\n        else return { text }\n    }\n}\n\nconst prepareEngine = (nodeData: INodeData) => {\n    const vectorStoreRetriever = nodeData.inputs?.vectorStoreRetriever\n    const responseSynthesizerObj = nodeData.inputs?.responseSynthesizer\n\n    let queryEngine = new RetrieverQueryEngine(vectorStoreRetriever)\n\n    if (responseSynthesizerObj) {\n        if (responseSynthesizerObj.type === 'TreeSummarize') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new TreeSummarize(vectorStoreRetriever.serviceContext, responseSynthesizerObj.textQAPromptTemplate),\n                serviceContext: vectorStoreRetriever.serviceContext\n            })\n            queryEngine = new RetrieverQueryEngine(vectorStoreRetriever, responseSynthesizer)\n        } else if (responseSynthesizerObj.type === 'CompactAndRefine') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new CompactAndRefine(\n                    vectorStoreRetriever.serviceContext,\n                    responseSynthesizerObj.textQAPromptTemplate,\n                    responseSynthesizerObj.refinePromptTemplate\n                ),\n                serviceContext: vectorStoreRetriever.serviceContext\n            })\n            queryEngine = new RetrieverQueryEngine(vectorStoreRetriever, responseSynthesizer)\n        } else if (responseSynthesizerObj.type === 'Refine') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new Refine(\n                    vectorStoreRetriever.serviceContext,\n                    responseSynthesizerObj.textQAPromptTemplate,\n                    responseSynthesizerObj.refinePromptTemplate\n                ),\n                serviceContext: vectorStoreRetriever.serviceContext\n            })\n            queryEngine = new RetrieverQueryEngine(vectorStoreRetriever, responseSynthesizer)\n        } else if (responseSynthesizerObj.type === 'SimpleResponseBuilder') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new SimpleResponseBuilder(vectorStoreRetriever.serviceContext),\n                serviceContext: vectorStoreRetriever.serviceContext\n            })\n            queryEngine = new RetrieverQueryEngine(vectorStoreRetriever, responseSynthesizer)\n        }\n    }\n\n    return queryEngine\n}"
}

## SubQuestionQueryEngine_LlamaIndex

{
  "className": "SubQuestionQueryEngine_LlamaIndex",
  "init": "[Function: init]",
  "run": "[Function: run]",
  "constructor": "constructor(fields?: { sessionId?: string }) {\n        this.label = 'Sub Question Query Engine'\n        this.name = 'subQuestionQueryEngine'\n        this.version = 2.0\n        this.type = 'SubQuestionQueryEngine'\n        this.icon = 'subQueryEngine.svg'\n        this.category = 'Engine'\n        this.description =\n            'Breaks complex query into sub questions for each relevant data source, then gather all the intermediate reponses and synthesizes a final response'\n        this.baseClasses = [this.type, 'BaseQueryEngine']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'QueryEngine Tools',\n                name: 'queryEngineTools',\n                type: 'QueryEngineTool',\n                list: true\n            }",
  "if": "if (responseSynthesizerObj.type === 'SimpleResponseBuilder') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new SimpleResponseBuilder(serviceContext),\n                serviceContext\n            }",
  "await": "await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }",
  "outsideClass_returnSourceDocuments": "const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n        const queryEngine = prepareEngine(nodeData)\n\n        let text = ''\n        let sourceDocuments: ICommonObject[] = []\n        let sourceNodes: NodeWithScore<Metadata>[] = []\n        let isStreamingStarted = false\n        const isStreamingEnabled = options.socketIO && options.socketIOClientId\n\n        if (isStreamingEnabled) {\n            const stream = await queryEngine.query({ query: input, stream: true })\n            for await (const chunk of stream) {\n                text += chunk.response\n                if (chunk.sourceNodes) sourceNodes = chunk.sourceNodes\n                if (!isStreamingStarted) {\n                    isStreamingStarted = true\n                    options.socketIO.to(options.socketIOClientId).emit('start', chunk.response)\n                }\n\n                options.socketIO.to(options.socketIOClientId).emit('token', chunk.response)\n            }\n\n            if (returnSourceDocuments) {\n                sourceDocuments = reformatSourceDocuments(sourceNodes)\n                options.socketIO.to(options.socketIOClientId).emit('sourceDocuments', sourceDocuments)\n            }\n        } else {\n            const response = await queryEngine.query({ query: input })\n            text = response?.response\n            sourceDocuments = reformatSourceDocuments(response?.sourceNodes ?? [])\n        }\n\n        if (returnSourceDocuments) return { text, sourceDocuments }\n        else return { text }\n    }\n}\n\nconst prepareEngine = (nodeData: INodeData) => {\n    const embeddings = nodeData.inputs?.embeddings as BaseEmbedding\n    const model = nodeData.inputs?.model\n\n    const serviceContext = serviceContextFromDefaults({\n        llm: model,\n        embedModel: embeddings\n    })\n\n    let queryEngineTools = nodeData.inputs?.queryEngineTools as QueryEngineTool[]\n    queryEngineTools = flatten(queryEngineTools)\n\n    let queryEngine = SubQuestionQueryEngine.fromDefaults({\n        serviceContext,\n        queryEngineTools,\n        questionGen: new LLMQuestionGenerator({ llm: model })\n    })\n\n    const responseSynthesizerObj = nodeData.inputs?.responseSynthesizer\n    if (responseSynthesizerObj) {\n        if (responseSynthesizerObj.type === 'TreeSummarize') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new TreeSummarize(serviceContext, responseSynthesizerObj.textQAPromptTemplate),\n                serviceContext\n            })\n            queryEngine = SubQuestionQueryEngine.fromDefaults({\n                responseSynthesizer,\n                serviceContext,\n                queryEngineTools,\n                questionGen: new LLMQuestionGenerator({ llm: model })\n            })\n        } else if (responseSynthesizerObj.type === 'CompactAndRefine') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new CompactAndRefine(\n                    serviceContext,\n                    responseSynthesizerObj.textQAPromptTemplate,\n                    responseSynthesizerObj.refinePromptTemplate\n                ),\n                serviceContext\n            })\n            queryEngine = SubQuestionQueryEngine.fromDefaults({\n                responseSynthesizer,\n                serviceContext,\n                queryEngineTools,\n                questionGen: new LLMQuestionGenerator({ llm: model })\n            })\n        } else if (responseSynthesizerObj.type === 'Refine') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new Refine(\n                    serviceContext,\n                    responseSynthesizerObj.textQAPromptTemplate,\n                    responseSynthesizerObj.refinePromptTemplate\n                ),\n                serviceContext\n            })\n            queryEngine = SubQuestionQueryEngine.fromDefaults({\n                responseSynthesizer,\n                serviceContext,\n                queryEngineTools,\n                questionGen: new LLMQuestionGenerator({ llm: model })\n            })\n        } else if (responseSynthesizerObj.type === 'SimpleResponseBuilder') {\n            const responseSynthesizer = new ResponseSynthesizer({\n                responseBuilder: new SimpleResponseBuilder(serviceContext),\n                serviceContext\n            })\n            queryEngine = SubQuestionQueryEngine.fromDefaults({\n                responseSynthesizer,\n                serviceContext,\n                queryEngineTools,\n                questionGen: new LLMQuestionGenerator({ llm: model })\n            })\n        }\n    }\n\n    return queryEngine\n}"
}

## AWSBedrock_LLMs

{
  "className": "AWSBedrock_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'AWS Bedrock'\n        this.name = 'awsBedrock'\n        this.version = 4.0\n        this.type = 'AWSBedrock'\n        this.icon = 'aws.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around AWS Bedrock large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(Bedrock)]\n        this.credential = {\n            label: 'AWS Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['awsApi'],\n            optional: true\n        }",
  "outsideClass_iRegion": "const iRegion = nodeData.inputs?.region as string\n        const iModel = nodeData.inputs?.model as string\n        const customModel = nodeData.inputs?.customModel as string\n        const iTemperature = nodeData.inputs?.temperature as string\n        const iMax_tokens_to_sample = nodeData.inputs?.max_tokens_to_sample as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const obj: Partial<BaseBedrockInput> & BaseLLMParams = {\n            model: customModel ? customModel : iModel,\n            region: iRegion,\n            temperature: parseFloat(iTemperature),\n            maxTokens: parseInt(iMax_tokens_to_sample, 10)\n        }\n\n        /**\n         * Long-term credentials specified in LLM configuration are optional.\n         * Bedrock's credential provider falls back to the AWS SDK to fetch\n         * credentials from the running environment.\n         * When specified, we override the default provider with configured values.\n         * @see https://github.com/aws/aws-sdk-js-v3/blob/main/packages/credential-provider-node/README.md\n         */\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        if (credentialData && Object.keys(credentialData).length !== 0) {\n            const credentialApiKey = getCredentialParam('awsKey', credentialData, nodeData)\n            const credentialApiSecret = getCredentialParam('awsSecret', credentialData, nodeData)\n            const credentialApiSession = getCredentialParam('awsSession', credentialData, nodeData)\n\n            obj.credentials = {\n                accessKeyId: credentialApiKey,\n                secretAccessKey: credentialApiSecret,\n                sessionToken: credentialApiSession\n            }\n        }\n        if (cache) obj.cache = cache\n\n        const amazonBedrock = new Bedrock(obj)\n        return amazonBedrock\n    }\n}"
}

## AzureOpenAI_LLMs

{
  "className": "AzureOpenAI_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Azure OpenAI'\n        this.name = 'azureOpenAI'\n        this.version = 4.0\n        this.type = 'AzureOpenAI'\n        this.icon = 'Azure.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around Azure OpenAI large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['azureOpenAIApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const presencePenalty = nodeData.inputs?.presencePenalty as string\n        const timeout = nodeData.inputs?.timeout as string\n        const bestOf = nodeData.inputs?.bestOf as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const basePath = nodeData.inputs?.basepath as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const azureOpenAIApiKey = getCredentialParam('azureOpenAIApiKey', credentialData, nodeData)\n        const azureOpenAIApiInstanceName = getCredentialParam('azureOpenAIApiInstanceName', credentialData, nodeData)\n        const azureOpenAIApiDeploymentName = getCredentialParam('azureOpenAIApiDeploymentName', credentialData, nodeData)\n        const azureOpenAIApiVersion = getCredentialParam('azureOpenAIApiVersion', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<AzureOpenAIInput> & BaseLLMParams & Partial<OpenAIInput> = {\n            temperature: parseFloat(temperature),\n            modelName,\n            azureOpenAIApiKey,\n            azureOpenAIApiInstanceName,\n            azureOpenAIApiDeploymentName,\n            azureOpenAIApiVersion,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (presencePenalty) obj.presencePenalty = parseFloat(presencePenalty)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (bestOf) obj.bestOf = parseInt(bestOf, 10)\n        if (cache) obj.cache = cache\n        if (basePath) obj.azureOpenAIBasePath = basePath\n\n        const model = new OpenAI(obj)\n        return model\n    }\n}"
}

## Cohere_LLMs

{
  "className": "Cohere_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Cohere'\n        this.name = 'cohere'\n        this.version = 3.0\n        this.type = 'Cohere'\n        this.icon = 'Cohere.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around Cohere large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(Cohere)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['cohereApi']\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const cache = nodeData.inputs?.cache as BaseCache\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const cohereApiKey = getCredentialParam('cohereApiKey', credentialData, nodeData)\n\n        const obj: CohereInput = {\n            apiKey: cohereApiKey\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (modelName) obj.model = modelName\n        if (temperature) obj.temperature = parseFloat(temperature)\n        if (cache) obj.cache = cache\n        const model = new Cohere(obj)\n        return model\n    }\n}"
}

## Fireworks_LLMs

{
  "className": "Fireworks_LLMs",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Fireworks'\n        this.name = 'fireworks'\n        this.version = 1.0\n        this.type = 'Fireworks'\n        this.icon = 'fireworks.png'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around Fireworks API for large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(Fireworks)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['fireworksApi']\n        }",
  "outsideClass_cache": "const cache = nodeData.inputs?.cache as BaseCache\n        const modelName = nodeData.inputs?.modelName as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const fireworksKey = getCredentialParam('fireworksApiKey', credentialData, nodeData)\n\n        const obj: any = {\n            fireworksApiKey: fireworksKey,\n            modelName: modelName\n        }\n        if (cache) obj.cache = cache\n\n        const fireworks = new Fireworks(obj)\n        return fireworks\n    }\n}"
}

## GooglePaLM_LLMs

{
  "className": "GooglePaLM_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GooglePaLM'\n        this.name = 'GooglePaLM'\n        this.version = 3.0\n        this.type = 'GooglePaLM'\n        this.icon = 'GooglePaLM.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around Google MakerSuite PaLM large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(GooglePaLM)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleMakerSuite']\n        }",
  "if": "if (stopSequencesObj) {\n            try {\n                parsedStopSequences = typeof stopSequencesObj === 'object' ? stopSequencesObj : JSON.parse(stopSequencesObj)\n                obj.stopSequences = parsedStopSequences.list || []\n            }",
  "catch": "catch (exception) {\n                throw new Error(\"Invalid JSON in the GooglePaLM's stopSequences: \" + exception)\n            }",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.modelName as string\n        const temperature = nodeData.inputs?.temperature as string\n        const maxOutputTokens = nodeData.inputs?.maxOutputTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const stopSequencesObj = nodeData.inputs?.stopSequencesObj\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleMakerSuiteKey = getCredentialParam('googleMakerSuiteKey', credentialData, nodeData)\n\n        const obj: Partial<GooglePaLMTextInput> = {\n            modelName: modelName,\n            temperature: parseFloat(temperature),\n            apiKey: googleMakerSuiteKey\n        }\n\n        if (maxOutputTokens) obj.maxOutputTokens = parseInt(maxOutputTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (cache) obj.cache = cache\n\n        let parsedStopSequences: any | undefined = undefined\n        if (stopSequencesObj) {\n            try {\n                parsedStopSequences = typeof stopSequencesObj === 'object' ? stopSequencesObj : JSON.parse(stopSequencesObj)\n                obj.stopSequences = parsedStopSequences.list || []\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the GooglePaLM's stopSequences: \" + exception)\n            }\n        }\n\n        const model = new GooglePaLM(obj)\n        return model\n    }\n}"
}

## GoogleVertexAI_LLMs

{
  "className": "GoogleVertexAI_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'GoogleVertexAI'\n        this.name = 'googlevertexai'\n        this.version = 3.0\n        this.type = 'GoogleVertexAI'\n        this.icon = 'GoogleVertex.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around GoogleVertexAI large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(GoogleVertexAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleVertexAuth'],\n            optional: true,\n            description:\n                'Google Vertex AI credential. If you are using a GCP service like Cloud Run, or if you have installed default credentials on your local machine, you do not need to set this credential.'\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleApplicationCredentialFilePath = getCredentialParam('googleApplicationCredentialFilePath', credentialData, nodeData)\n        const googleApplicationCredential = getCredentialParam('googleApplicationCredential', credentialData, nodeData)\n        const projectID = getCredentialParam('projectID', credentialData, nodeData)\n\n        const authOptions: GoogleAuthOptions = {}\n        if (Object.keys(credentialData).length !== 0) {\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error('Please specify your Google Application Credential')\n            if (!googleApplicationCredentialFilePath && !googleApplicationCredential)\n                throw new Error(\n                    'Error: More than one component has been inputted. Please use only one of the following: Google Application Credential File Path or Google Credential JSON Object'\n                )\n\n            if (googleApplicationCredentialFilePath && !googleApplicationCredential)\n                authOptions.keyFile = googleApplicationCredentialFilePath\n            else if (!googleApplicationCredentialFilePath && googleApplicationCredential)\n                authOptions.credentials = JSON.parse(googleApplicationCredential)\n\n            if (projectID) authOptions.projectId = projectID\n        }\n\n        const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxOutputTokens = nodeData.inputs?.maxOutputTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<GoogleVertexAITextInput> = {\n            temperature: parseFloat(temperature),\n            model: modelName\n        }\n        if (Object.keys(authOptions).length !== 0) obj.authOptions = authOptions\n\n        if (maxOutputTokens) obj.maxOutputTokens = parseInt(maxOutputTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (cache) obj.cache = cache\n\n        const model = new GoogleVertexAI(obj)\n        return model\n    }\n}"
}

## HuggingFaceInference_LLMs

{
  "className": "HuggingFaceInference_LLMs",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'HuggingFace Inference'\n        this.name = 'huggingFaceInference_LLMs'\n        this.version = 2.0\n        this.type = 'HuggingFaceInference'\n        this.icon = 'HuggingFace.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around HuggingFace large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(HuggingFaceInference)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['huggingFaceApi']\n        }",
  "outsideClass_model": "const model = nodeData.inputs?.model as string\n        const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const hfTopK = nodeData.inputs?.hfTopK as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const endpoint = nodeData.inputs?.endpoint as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const huggingFaceApiKey = getCredentialParam('huggingFaceApiKey', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<HFInput> = {\n            model,\n            apiKey: huggingFaceApiKey\n        }\n\n        if (temperature) obj.temperature = parseFloat(temperature)\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (hfTopK) obj.topK = parseFloat(hfTopK)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (endpoint) obj.endpoint = endpoint\n\n        const huggingFace = new HuggingFaceInference(obj)\n        if (cache) huggingFace.cache = cache\n\n        return huggingFace\n    }\n}"
}

## Ollama_LLMs

{
  "className": "Ollama_LLMs",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Ollama'\n        this.name = 'ollama'\n        this.version = 2.0\n        this.type = 'Ollama'\n        this.icon = 'Ollama.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around open source large language models on Ollama'\n        this.baseClasses = [this.type, ...getBaseClasses(Ollama)]\n        this.inputs = [\n            {\n                label: 'Cache',\n                name: 'cache',\n                type: 'BaseCache',\n                optional: true\n            }",
  "if": "if (stop) {\n            const stopSequences = stop.split(',')\n            obj.stop = stopSequences\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const baseUrl = nodeData.inputs?.baseUrl as string\n        const modelName = nodeData.inputs?.modelName as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const mirostat = nodeData.inputs?.mirostat as string\n        const mirostatEta = nodeData.inputs?.mirostatEta as string\n        const mirostatTau = nodeData.inputs?.mirostatTau as string\n        const numCtx = nodeData.inputs?.numCtx as string\n        const numGqa = nodeData.inputs?.numGqa as string\n        const numGpu = nodeData.inputs?.numGpu as string\n        const numThread = nodeData.inputs?.numThread as string\n        const repeatLastN = nodeData.inputs?.repeatLastN as string\n        const repeatPenalty = nodeData.inputs?.repeatPenalty as string\n        const stop = nodeData.inputs?.stop as string\n        const tfsZ = nodeData.inputs?.tfsZ as string\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: OllamaInput & BaseLLMParams = {\n            baseUrl,\n            temperature: parseFloat(temperature),\n            model: modelName\n        }\n\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (mirostat) obj.mirostat = parseFloat(mirostat)\n        if (mirostatEta) obj.mirostatEta = parseFloat(mirostatEta)\n        if (mirostatTau) obj.mirostatTau = parseFloat(mirostatTau)\n        if (numCtx) obj.numCtx = parseFloat(numCtx)\n        if (numGqa) obj.numGqa = parseFloat(numGqa)\n        if (numGpu) obj.numGpu = parseFloat(numGpu)\n        if (numThread) obj.numThread = parseFloat(numThread)\n        if (repeatLastN) obj.repeatLastN = parseFloat(repeatLastN)\n        if (repeatPenalty) obj.repeatPenalty = parseFloat(repeatPenalty)\n        if (tfsZ) obj.tfsZ = parseFloat(tfsZ)\n        if (stop) {\n            const stopSequences = stop.split(',')\n            obj.stop = stopSequences\n        }\n        if (cache) obj.cache = cache\n\n        const model = new Ollama(obj)\n        return model\n    }\n}"
}

## OpenAI_LLMs

{
  "className": "OpenAI_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAI'\n        this.name = 'openAI'\n        this.version = 4.0\n        this.type = 'OpenAI'\n        this.icon = 'openai.svg'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around OpenAI large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(OpenAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "if": "if (baseOptions) {\n            try {\n                parsedBaseOptions = typeof baseOptions === 'object' ? baseOptions : JSON.parse(baseOptions)\n            }",
  "catch": "catch (exception) {\n                throw new Error(\"Invalid JSON in the OpenAI's BaseOptions: \" + exception)\n            }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const modelName = nodeData.inputs?.modelName as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const frequencyPenalty = nodeData.inputs?.frequencyPenalty as string\n        const presencePenalty = nodeData.inputs?.presencePenalty as string\n        const timeout = nodeData.inputs?.timeout as string\n        const batchSize = nodeData.inputs?.batchSize as string\n        const bestOf = nodeData.inputs?.bestOf as string\n        const streaming = nodeData.inputs?.streaming as boolean\n        const basePath = nodeData.inputs?.basepath as string\n        const baseOptions = nodeData.inputs?.baseOptions\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: Partial<OpenAIInput> & BaseLLMParams & { openAIApiKey?: string } = {\n            temperature: parseFloat(temperature),\n            modelName,\n            openAIApiKey,\n            streaming: streaming ?? true\n        }\n\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (frequencyPenalty) obj.frequencyPenalty = parseFloat(frequencyPenalty)\n        if (presencePenalty) obj.presencePenalty = parseFloat(presencePenalty)\n        if (timeout) obj.timeout = parseInt(timeout, 10)\n        if (batchSize) obj.batchSize = parseInt(batchSize, 10)\n        if (bestOf) obj.bestOf = parseInt(bestOf, 10)\n\n        if (cache) obj.cache = cache\n\n        let parsedBaseOptions: any | undefined = undefined\n        if (baseOptions) {\n            try {\n                parsedBaseOptions = typeof baseOptions === 'object' ? baseOptions : JSON.parse(baseOptions)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the OpenAI's BaseOptions: \" + exception)\n            }\n        }\n\n        const model = new OpenAI(obj, {\n            basePath,\n            baseOptions: parsedBaseOptions\n        })\n        return model\n    }\n}"
}

## Replicate_LLMs

{
  "className": "Replicate_LLMs",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Replicate'\n        this.name = 'replicate'\n        this.version = 2.0\n        this.type = 'Replicate'\n        this.icon = 'replicate.svg'\n        this.category = 'LLMs'\n        this.description = 'Use Replicate to run open source models on cloud'\n        this.baseClasses = [this.type, 'BaseChatModel', ...getBaseClasses(Replicate)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['replicateApi']\n        }",
  "if": "if (additionalInputs) {\n            const parsedInputs =\n                typeof additionalInputs === 'object' ? additionalInputs : additionalInputs ? JSON.parse(additionalInputs) : {}",
  "outsideClass_modelName": "const modelName = nodeData.inputs?.model as `${string}/${string}` | `${string}/${string}:${string}`\n        const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const repetitionPenalty = nodeData.inputs?.repetitionPenalty as string\n        const additionalInputs = nodeData.inputs?.additionalInputs as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('replicateApiKey', credentialData, nodeData)\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const obj: ReplicateInput & BaseLLMParams = {\n            model: modelName,\n            apiKey\n        }\n\n        let inputs: any = {}\n        if (maxTokens) inputs.max_length = parseInt(maxTokens, 10)\n        if (temperature) inputs.temperature = parseFloat(temperature)\n        if (topP) inputs.top_p = parseFloat(topP)\n        if (repetitionPenalty) inputs.repetition_penalty = parseFloat(repetitionPenalty)\n        if (additionalInputs) {\n            const parsedInputs =\n                typeof additionalInputs === 'object' ? additionalInputs : additionalInputs ? JSON.parse(additionalInputs) : {}\n            inputs = { ...inputs, ...parsedInputs }\n        }\n        if (Object.keys(inputs).length) obj.input = inputs\n\n        if (cache) obj.cache = cache\n\n        const model = new Replicate(obj)\n        return model\n    }\n}"
}

## TogetherAI_LLMs

{
  "className": "TogetherAI_LLMs",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'TogetherAI'\n        this.name = 'togetherAI'\n        this.version = 1.0\n        this.type = 'TogetherAI'\n        this.icon = 'togetherai.png'\n        this.category = 'LLMs'\n        this.description = 'Wrapper around TogetherAI large language models'\n        this.baseClasses = [this.type, ...getBaseClasses(TogetherAI)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['togetherAIApi']\n        }",
  "if": "if (stop) {\n            obj.stop = stop.split(',')\n        }",
  "outsideClass_temperature": "const temperature = nodeData.inputs?.temperature as string\n        const maxTokens = nodeData.inputs?.maxTokens as string\n        const topP = nodeData.inputs?.topP as string\n        const topK = nodeData.inputs?.topK as string\n        const repeatPenalty = nodeData.inputs?.repeatPenalty as string\n        const modelName = nodeData.inputs?.modelName as string\n        const stop = nodeData.inputs?.stop as string\n        const streaming = nodeData.inputs?.streaming as boolean\n\n        const cache = nodeData.inputs?.cache as BaseCache\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const togetherAiApiKey = getCredentialParam('togetherAIApiKey', credentialData, nodeData)\n\n        const obj: TogetherAIInputs = {\n            modelName,\n            apiKey: togetherAiApiKey,\n            streaming: streaming ?? false\n        }\n\n        if (temperature) obj.temperature = parseFloat(temperature)\n        if (maxTokens) obj.maxTokens = parseInt(maxTokens, 10)\n        if (topP) obj.topP = parseFloat(topP)\n        if (topK) obj.topK = parseFloat(topK)\n        if (repeatPenalty) obj.repetitionPenalty = parseFloat(repeatPenalty)\n        if (streaming) obj.streaming = streaming\n        if (stop) {\n            obj.stop = stop.split(',')\n        }\n        if (cache) obj.cache = cache\n\n        const togetherAI = new TogetherAI(obj)\n        return togetherAI\n    }\n}"
}

## AgentMemory_Memory

{
  "className": "AgentMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Agent Memory'\n        this.name = 'agentMemory'\n        this.version = 1.0\n        this.type = 'AgentMemory'\n        this.icon = 'agentmemory.svg'\n        this.category = 'Memory'\n        this.description = 'Memory for agentflow to remember the state of the conversation'\n        this.baseClasses = [this.type, ...getBaseClasses(SqliteSaver)]\n        this.inputs = [\n            {\n                label: 'Database',\n                name: 'databaseType',\n                type: 'options',\n                options: [\n                    {\n                        label: 'SQLite',\n                        name: 'sqlite'\n                    }",
  "if": "if (databaseType === 'sqlite') {\n            datasourceOptions.database = databaseFilePath\n                ? path.resolve(databaseFilePath)\n                : path.join(process.env.DATABASE_PATH ?? path.join(getUserHome(), '.flowise'), 'database.sqlite')\n            const args: SaverOptions = {\n                datasourceOptions,\n                threadId,\n                appDataSource,\n                databaseEntities,\n                chatflowid\n            }",
  "catch": "catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }",
  "outsideClass_additionalConfig": "const additionalConfig = nodeData.inputs?.additionalConfig as string\n        const databaseFilePath = nodeData.inputs?.databaseFilePath as string\n        const databaseType = nodeData.inputs?.databaseType as string\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n        const appDataSource = options.appDataSource as DataSource\n\n        let additionalConfiguration = {}\n        if (additionalConfig) {\n            try {\n                additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }\n        }\n\n        const threadId = options.sessionId || options.chatId\n\n        const datasourceOptions: ICommonObject = {\n            ...additionalConfiguration,\n            type: databaseType\n        }\n\n        if (databaseType === 'sqlite') {\n            datasourceOptions.database = databaseFilePath\n                ? path.resolve(databaseFilePath)\n                : path.join(process.env.DATABASE_PATH ?? path.join(getUserHome(), '.flowise'), 'database.sqlite')\n            const args: SaverOptions = {\n                datasourceOptions,\n                threadId,\n                appDataSource,\n                databaseEntities,\n                chatflowid\n            }\n            const recordManager = new SqliteSaver(args)\n            return recordManager\n        }\n\n        return undefined\n    }\n}"
}

## BufferMemory_Memory

{
  "className": "BufferMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.appDataSource = fields.appDataSource\n        this.databaseEntities = fields.databaseEntities\n        this.chatflowid = fields.chatflowid\n    }",
  "if": "if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }",
  "for": "for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            }",
  "outsideClass_sessionId": "const sessionId = nodeData.inputs?.sessionId as string\n        const memoryKey = (nodeData.inputs?.memoryKey as string) ?? 'chat_history'\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n\n        return new BufferMemoryExtended({\n            returnMessages: true,\n            memoryKey,\n            sessionId,\n            appDataSource,\n            databaseEntities,\n            chatflowid\n        })\n    }\n}\n\ninterface BufferMemoryExtendedInput {\n    sessionId: string\n    appDataSource: DataSource\n    databaseEntities: IDatabaseEntity\n    chatflowid: string\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        if (!id) return []\n\n        const chatMessage = await this.appDataSource.getRepository(this.databaseEntities['ChatMessage']).find({\n            where: {\n                sessionId: id,\n                chatflowid: this.chatflowid\n            },\n            order: {\n                createdDate: 'ASC'\n            }\n        })\n\n        if (prependMessages?.length) {\n            chatMessage.unshift(...prependMessages)\n        }\n\n        if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }\n\n        let returnIMessages: IMessage[] = []\n        for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            })\n        }\n\n        return returnIMessages\n    }\n\n    async addChatMessages(): Promise<void> {\n        // adding chat messages is done on server level\n        return\n    }\n\n    async clearChatMessages(): Promise<void> {\n        // clearing chat messages is done on server level\n        return\n    }\n}"
}

## BufferWindowMemory_Memory

{
  "className": "BufferWindowMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: BufferWindowMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.appDataSource = fields.appDataSource\n        this.databaseEntities = fields.databaseEntities\n        this.chatflowid = fields.chatflowid\n    }",
  "if": "if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }",
  "for": "for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            }",
  "outsideClass_k": "const k = nodeData.inputs?.k as string\n        const sessionId = nodeData.inputs?.sessionId as string\n        const memoryKey = (nodeData.inputs?.memoryKey as string) ?? 'chat_history'\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n\n        const obj: Partial<BufferWindowMemoryInput> & BufferMemoryExtendedInput = {\n            returnMessages: true,\n            sessionId,\n            memoryKey,\n            k: parseInt(k, 10),\n            appDataSource,\n            databaseEntities,\n            chatflowid\n        }\n\n        return new BufferWindowMemoryExtended(obj)\n    }\n}\n\ninterface BufferMemoryExtendedInput {\n    sessionId: string\n    appDataSource: DataSource\n    databaseEntities: IDatabaseEntity\n    chatflowid: string\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        if (!id) return []\n\n        let chatMessage = await this.appDataSource.getRepository(this.databaseEntities['ChatMessage']).find({\n            where: {\n                sessionId: id,\n                chatflowid: this.chatflowid\n            },\n            take: this.k + 1,\n            order: {\n                createdDate: 'DESC' // we get the latest top K\n            }\n        })\n\n        // reverse the order of human and ai messages\n        if (chatMessage.length) chatMessage.reverse()\n\n        if (prependMessages?.length) {\n            chatMessage.unshift(...prependMessages)\n        }\n\n        if (returnBaseMessages) {\n            return await mapChatMessageToBaseMessage(chatMessage)\n        }\n\n        let returnIMessages: IMessage[] = []\n        for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            })\n        }\n        return returnIMessages\n    }\n\n    async addChatMessages(): Promise<void> {\n        // adding chat messages is done on server level\n        return\n    }\n\n    async clearChatMessages(): Promise<void> {\n        // clearing chat messages is done on server level\n        return\n    }\n}"
}

## ConversationSummaryBufferMemory_Memory

{
  "className": "ConversationSummaryBufferMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: ConversationSummaryBufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.appDataSource = fields.appDataSource\n        this.databaseEntities = fields.databaseEntities\n        this.chatflowid = fields.chatflowid\n    }",
  "if": "if (returnBaseMessages) {\n            return baseMessages\n        }",
  "for": "for (const m of baseMessages) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m._getType() === 'human' ? 'userMessage' : 'apiMessage'\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const _maxTokenLimit = nodeData.inputs?.maxTokenLimit as string\n        const maxTokenLimit = _maxTokenLimit ? parseInt(_maxTokenLimit, 10) : 2000\n        const sessionId = nodeData.inputs?.sessionId as string\n        const memoryKey = (nodeData.inputs?.memoryKey as string) ?? 'chat_history'\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n\n        const obj: ConversationSummaryBufferMemoryInput & BufferMemoryExtendedInput = {\n            llm: model,\n            sessionId,\n            memoryKey,\n            maxTokenLimit,\n            returnMessages: true,\n            appDataSource,\n            databaseEntities,\n            chatflowid\n        }\n\n        return new ConversationSummaryBufferMemoryExtended(obj)\n    }\n}\n\ninterface BufferMemoryExtendedInput {\n    sessionId: string\n    appDataSource: DataSource\n    databaseEntities: IDatabaseEntity\n    chatflowid: string\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        if (!id) return []\n\n        let chatMessage = await this.appDataSource.getRepository(this.databaseEntities['ChatMessage']).find({\n            where: {\n                sessionId: id,\n                chatflowid: this.chatflowid\n            },\n            order: {\n                createdDate: 'ASC'\n            }\n        })\n\n        if (prependMessages?.length) {\n            chatMessage.unshift(...prependMessages)\n        }\n\n        let baseMessages = await mapChatMessageToBaseMessage(chatMessage)\n\n        // Prune baseMessages if it exceeds max token limit\n        if (this.movingSummaryBuffer) {\n            baseMessages = [new this.summaryChatMessageClass(this.movingSummaryBuffer), ...baseMessages]\n        }\n\n        let currBufferLength = 0\n\n        if (this.llm && typeof this.llm !== 'string') {\n            currBufferLength = await this.llm.getNumTokens(getBufferString(baseMessages, this.humanPrefix, this.aiPrefix))\n            if (currBufferLength > this.maxTokenLimit) {\n                const prunedMemory = []\n                while (currBufferLength > this.maxTokenLimit) {\n                    const poppedMessage = baseMessages.shift()\n                    if (poppedMessage) {\n                        prunedMemory.push(poppedMessage)\n                        currBufferLength = await this.llm.getNumTokens(getBufferString(baseMessages, this.humanPrefix, this.aiPrefix))\n                    }\n                }\n                this.movingSummaryBuffer = await this.predictNewSummary(prunedMemory, this.movingSummaryBuffer)\n            }\n        }\n\n        // ----------- Finished Pruning ---------------\n\n        if (this.movingSummaryBuffer) {\n            baseMessages = [new this.summaryChatMessageClass(this.movingSummaryBuffer), ...baseMessages]\n        }\n\n        if (returnBaseMessages) {\n            return baseMessages\n        }\n\n        let returnIMessages: IMessage[] = []\n        for (const m of baseMessages) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m._getType() === 'human' ? 'userMessage' : 'apiMessage'\n            })\n        }\n\n        return returnIMessages\n    }\n\n    async addChatMessages(): Promise<void> {\n        // adding chat messages is done on server level\n        return\n    }\n\n    async clearChatMessages(): Promise<void> {\n        // clearing chat messages is done on server level\n        return\n    }\n}"
}

## ConversationSummaryMemory_Memory

{
  "className": "ConversationSummaryMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: ConversationSummaryMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.appDataSource = fields.appDataSource\n        this.databaseEntities = fields.databaseEntities\n        this.chatflowid = fields.chatflowid\n    }",
  "if": "if (this.buffer) {\n            return [\n                {\n                    message: this.buffer,\n                    type: 'apiMessage'\n                }",
  "for": "for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const sessionId = nodeData.inputs?.sessionId as string\n        const memoryKey = (nodeData.inputs?.memoryKey as string) ?? 'chat_history'\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const chatflowid = options.chatflowid as string\n\n        const obj: ConversationSummaryMemoryInput & BufferMemoryExtendedInput = {\n            llm: model,\n            memoryKey,\n            returnMessages: true,\n            sessionId,\n            appDataSource,\n            databaseEntities,\n            chatflowid\n        }\n\n        return new ConversationSummaryMemoryExtended(obj)\n    }\n}\n\ninterface BufferMemoryExtendedInput {\n    sessionId: string\n    appDataSource: DataSource\n    databaseEntities: IDatabaseEntity\n    chatflowid: string\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        if (!id) return []\n\n        this.buffer = ''\n        let chatMessage = await this.appDataSource.getRepository(this.databaseEntities['ChatMessage']).find({\n            where: {\n                sessionId: id,\n                chatflowid: this.chatflowid\n            },\n            order: {\n                createdDate: 'ASC'\n            }\n        })\n\n        if (prependMessages?.length) {\n            chatMessage.unshift(...prependMessages)\n        }\n\n        const baseMessages = await mapChatMessageToBaseMessage(chatMessage)\n\n        // Get summary\n        if (this.llm && typeof this.llm !== 'string') {\n            this.buffer = baseMessages.length ? await this.predictNewSummary(baseMessages.slice(-2), this.buffer) : ''\n        }\n\n        if (returnBaseMessages) {\n            return [new SystemMessage(this.buffer)]\n        }\n\n        if (this.buffer) {\n            return [\n                {\n                    message: this.buffer,\n                    type: 'apiMessage'\n                }\n            ]\n        }\n\n        let returnIMessages: IMessage[] = []\n        for (const m of chatMessage) {\n            returnIMessages.push({\n                message: m.content as string,\n                type: m.role\n            })\n        }\n        return returnIMessages\n    }\n\n    async addChatMessages(): Promise<void> {\n        // adding chat messages is done on server level\n        return\n    }\n\n    async clearChatMessages(): Promise<void> {\n        // clearing chat messages is done on server level\n        return\n    }\n}"
}

## DynamoDb_Memory

{
  "className": "DynamoDb_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.dynamodbClient = fields.dynamodbClient\n        this.tableName = fields.tableName\n        this.partitionKey = fields.partitionKey\n        this.dynamoKey = fields.dynamoKey\n    }",
  "if": "if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.addNewMessage(messageToAdd, this.dynamodbClient, tableName, dynamoKey, messageAttributeName)\n        }",
  "overrideDynamoKey": "overrideDynamoKey(overrideSessionId = '') {\n        const existingDynamoKey = this.dynamoKey\n        const partitionKey = this.partitionKey\n\n        let newDynamoKey: Record<string, AttributeValue> = {}",
  "addNewMessage": "addNewMessage(\n        messages: StoredMessage[],\n        client: DynamoDBClient,\n        tableName = '',\n        dynamoKey: Record<string, AttributeValue> = {},\n        messageAttributeName = 'messages'\n    ) {\n        const params: UpdateItemCommandInput = {\n            TableName: tableName,\n            Key: dynamoKey,\n            ExpressionAttributeNames: {\n                '#m': messageAttributeName\n            }",
  "outsideClass_initializeDynamoDB": "const initializeDynamoDB = async (nodeData: INodeData, options: ICommonObject): Promise<BufferMemory> => {\n    const tableName = nodeData.inputs?.tableName as string\n    const partitionKey = nodeData.inputs?.partitionKey as string\n    const region = nodeData.inputs?.region as string\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const sessionId = nodeData.inputs?.sessionId as string\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const accessKeyId = getCredentialParam('accessKey', credentialData, nodeData)\n    const secretAccessKey = getCredentialParam('secretAccessKey', credentialData, nodeData)\n\n    let credentials: DynamoDBClientConfig['credentials'] | undefined\n    if (accessKeyId && secretAccessKey) {\n        credentials = {\n            accessKeyId,\n            secretAccessKey\n        }\n    }\n\n    const config: DynamoDBClientConfig = {\n        region,\n        credentials\n    }\n\n    const client = new DynamoDBClient(config ?? {})\n\n    const dynamoDb = new DynamoDBChatMessageHistory({\n        tableName,\n        partitionKey,\n        sessionId,\n        config\n    })\n\n    const memory = new BufferMemoryExtended({\n        memoryKey: memoryKey ?? 'chat_history',\n        chatHistory: dynamoDb,\n        sessionId,\n        dynamodbClient: client,\n        tableName,\n        partitionKey,\n        dynamoKey: { [partitionKey]: { S: sessionId } }\n    })\n    return memory\n}\n\ninterface BufferMemoryExtendedInput {\n    dynamodbClient: DynamoDBClient\n    sessionId: string\n    tableName: string\n    partitionKey: string\n    dynamoKey: Record<string, AttributeValue>\n}\n\ninterface DynamoDBSerializedChatMessage {\n    M: {\n        type: {\n            S: string\n        }\n        text: {\n            S: string\n        }\n        role?: {\n            S: string\n        }\n    }\n}",
  "outsideClass_existingDynamoKey": "const existingDynamoKey = this.dynamoKey\n        const partitionKey = this.partitionKey\n\n        let newDynamoKey: Record<string, AttributeValue> = {}\n\n        if (Object.keys(existingDynamoKey).includes(partitionKey)) {\n            newDynamoKey[partitionKey] = { S: overrideSessionId }\n        }\n\n        return Object.keys(newDynamoKey).length ? newDynamoKey : existingDynamoKey\n    }\n\n    async addNewMessage(\n        messages: StoredMessage[],\n        client: DynamoDBClient,\n        tableName = '',\n        dynamoKey: Record<string, AttributeValue> = {},\n        messageAttributeName = 'messages'\n    ) {\n        const params: UpdateItemCommandInput = {\n            TableName: tableName,\n            Key: dynamoKey,\n            ExpressionAttributeNames: {\n                '#m': messageAttributeName\n            },\n            ExpressionAttributeValues: {\n                ':empty_list': {\n                    L: []\n                },\n                ':m': {\n                    L: messages.map((message) => {\n                        const dynamoSerializedMessage: DynamoDBSerializedChatMessage = {\n                            M: {\n                                type: {\n                                    S: message.type\n                                },\n                                text: {\n                                    S: message.data.content\n                                }\n                            }\n                        }\n                        if (message.data.role) {\n                            dynamoSerializedMessage.M.role = { S: message.data.role }\n                        }\n                        return dynamoSerializedMessage\n                    })\n                }\n            },\n            UpdateExpression: 'SET #m = list_append(if_not_exists(#m, :empty_list), :m)'\n        }\n\n        await client.send(new UpdateItemCommand(params))\n    }\n\n    async getChatMessages(\n        overrideSessionId = '',\n        returnBaseMessages = false,\n        prependMessages?: IMessage[]\n    ): Promise<IMessage[] | BaseMessage[]> {\n        if (!this.dynamodbClient) return []\n\n        const dynamoKey = overrideSessionId ? this.overrideDynamoKey(overrideSessionId) : this.dynamoKey\n        const tableName = this.tableName\n\n        const messageAttributeName = this.messageAttributeName ? this.messageAttributeName : 'messages'\n        const params: GetItemCommandInput = {\n            TableName: tableName,\n            Key: dynamoKey\n        }\n\n        const response = await this.dynamodbClient.send(new GetItemCommand(params))\n        const items = response.Item ? response.Item[messageAttributeName]?.L ?? [] : []\n        const messages = items\n            .map((item) => ({\n                type: item.M?.type.S,\n                data: {\n                    role: item.M?.role?.S,\n                    content: item.M?.text.S\n                }\n            }))\n            .filter((x): x is StoredMessage => x.type !== undefined && x.data.content !== undefined)\n        const baseMessages = messages.map(mapStoredMessageToChatMessage)\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        if (!this.dynamodbClient) return\n\n        const dynamoKey = overrideSessionId ? this.overrideDynamoKey(overrideSessionId) : this.dynamoKey\n        const tableName = this.tableName\n        const messageAttributeName = this.messageAttributeName\n\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n\n        if (input) {\n            const newInputMessage = new HumanMessage(input.text)\n            const messageToAdd = [newInputMessage].map((msg) => msg.toDict())\n            await this.addNewMessage(messageToAdd, this.dynamodbClient, tableName, dynamoKey, messageAttributeName)\n        }\n\n        if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.addNewMessage(messageToAdd, this.dynamodbClient, tableName, dynamoKey, messageAttributeName)\n        }\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        if (!this.dynamodbClient) return\n\n        const dynamoKey = overrideSessionId ? this.overrideDynamoKey(overrideSessionId) : this.dynamoKey\n        const tableName = this.tableName\n\n        const params: DeleteItemCommandInput = {\n            TableName: tableName,\n            Key: dynamoKey\n        }\n        await this.dynamodbClient.send(new DeleteItemCommand(params))\n        await this.clear()\n    }\n}"
}

## MongoDB_Memory

{
  "className": "MongoDB_Memory",
  "init": "[Function: init]",
  "if": "if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.collection.updateOne(\n                { sessionId: id }",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.collection = fields.collection\n    }",
  "outsideClass_getMongoClient": "const getMongoClient = async (newMongoUrl: string) => {\n    if (!mongoClientSingleton) {\n        // if client does not exist\n        mongoClientSingleton = new MongoClient(newMongoUrl)\n        mongoUrl = newMongoUrl\n        return mongoClientSingleton\n    } else if (mongoClientSingleton && newMongoUrl !== mongoUrl) {\n        // if client exists but url changed\n        mongoClientSingleton.close()\n        mongoClientSingleton = new MongoClient(newMongoUrl)\n        mongoUrl = newMongoUrl\n        return mongoClientSingleton\n    }\n    return mongoClientSingleton\n}",
  "outsideClass_initializeMongoDB": "const initializeMongoDB = async (nodeData: INodeData, options: ICommonObject): Promise<BufferMemory> => {\n    const databaseName = nodeData.inputs?.databaseName as string\n    const collectionName = nodeData.inputs?.collectionName as string\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const sessionId = nodeData.inputs?.sessionId as string\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const mongoDBConnectUrl = getCredentialParam('mongoDBConnectUrl', credentialData, nodeData)\n\n    const client = await getMongoClient(mongoDBConnectUrl)\n    const collection = client.db(databaseName).collection(collectionName)\n\n    const mongoDBChatMessageHistory = new MongoDBChatMessageHistory({\n        collection,\n        sessionId\n    })\n\n    // @ts-ignore\n    mongoDBChatMessageHistory.getMessages = async (): Promise<BaseMessage[]> => {\n        const document = await collection.findOne({\n            sessionId: (mongoDBChatMessageHistory as any).sessionId\n        })\n        const messages = document?.messages || []\n        return messages.map(mapStoredMessageToChatMessage)\n    }\n\n    // @ts-ignore\n    mongoDBChatMessageHistory.addMessage = async (message: BaseMessage): Promise<void> => {\n        const messages = [message].map((msg) => msg.toDict())\n        await collection.updateOne(\n            { sessionId: (mongoDBChatMessageHistory as any).sessionId },\n            {\n                $push: { messages: { $each: messages } }\n            },\n            { upsert: true }\n        )\n    }\n\n    mongoDBChatMessageHistory.clear = async (): Promise<void> => {\n        await collection.deleteOne({ sessionId: (mongoDBChatMessageHistory as any).sessionId })\n    }\n\n    return new BufferMemoryExtended({\n        memoryKey: memoryKey ?? 'chat_history',\n        // @ts-ignore\n        chatHistory: mongoDBChatMessageHistory,\n        sessionId,\n        collection\n    })\n}\n\ninterface BufferMemoryExtendedInput {\n    collection: Collection<Document>\n    sessionId: string\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const document = await this.collection.findOne({ sessionId: id })\n        const messages = document?.messages || []\n        const baseMessages = messages.map(mapStoredMessageToChatMessage)\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        if (!this.collection) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n\n        if (input) {\n            const newInputMessage = new HumanMessage(input.text)\n            const messageToAdd = [newInputMessage].map((msg) => msg.toDict())\n            await this.collection.updateOne(\n                { sessionId: id },\n                {\n                    $push: { messages: { $each: messageToAdd } }\n                },\n                { upsert: true }\n            )\n        }\n\n        if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.collection.updateOne(\n                { sessionId: id },\n                {\n                    $push: { messages: { $each: messageToAdd } }\n                },\n                { upsert: true }\n            )\n        }\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        if (!this.collection) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        await this.collection.deleteOne({ sessionId: id })\n        await this.clear()\n    }\n}"
}

## RedisBackedChatMemory_Memory

{
  "className": "RedisBackedChatMemory_Memory",
  "init": "[Function: init]",
  "if": "if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.redisClient = fields.redisClient\n        this.windowSize = fields.windowSize\n        this.sessionTTL = fields.sessionTTL\n    }",
  "outsideClass_getRedisClientbyOption": "const getRedisClientbyOption = (option: RedisOptions) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    } else if (redisClientSingleton && !isEqual(option, redisClientOption)) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}\n\nconst getRedisClientbyUrl = (url: string) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    } else if (redisClientSingleton && url !== redisClientUrl) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = new Redis(url)\n        redisClientUrl = url\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}",
  "outsideClass_initalizeRedis": "const initalizeRedis = async (nodeData: INodeData, options: ICommonObject): Promise<BufferMemory> => {\n    const sessionTTL = nodeData.inputs?.sessionTTL as number\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const sessionId = nodeData.inputs?.sessionId as string\n    const windowSize = nodeData.inputs?.windowSize as number\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const redisUrl = getCredentialParam('redisUrl', credentialData, nodeData)\n\n    let client: Redis\n\n    if (!redisUrl || redisUrl === '') {\n        const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n        const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n        const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n        const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n        const sslEnabled = getCredentialParam('redisCacheSslEnabled', credentialData, nodeData)\n\n        const tlsOptions = sslEnabled === true ? { tls: { rejectUnauthorized: false } } : {}\n\n        client = getRedisClientbyOption({\n            port: portStr ? parseInt(portStr) : 6379,\n            host,\n            username,\n            password,\n            ...tlsOptions\n        })\n    } else {\n        client = getRedisClientbyUrl(redisUrl)\n    }\n\n    let obj: RedisChatMessageHistoryInput = {\n        sessionId,\n        client\n    }\n\n    if (sessionTTL) {\n        obj = {\n            ...obj,\n            sessionTTL\n        }\n    }\n\n    const redisChatMessageHistory = new RedisChatMessageHistory(obj)\n\n    const memory = new BufferMemoryExtended({\n        memoryKey: memoryKey ?? 'chat_history',\n        chatHistory: redisChatMessageHistory,\n        sessionId,\n        windowSize,\n        redisClient: client,\n        sessionTTL\n    })\n\n    return memory\n}\n\ninterface BufferMemoryExtendedInput {\n    redisClient: Redis\n    sessionId: string\n    windowSize?: number\n    sessionTTL?: number\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const rawStoredMessages = await this.redisClient.lrange(id, this.windowSize ? this.windowSize * -1 : 0, -1)\n        const orderedMessages = rawStoredMessages.reverse().map((message) => JSON.parse(message))\n        const baseMessages = orderedMessages.map(mapStoredMessageToChatMessage)\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        if (!this.redisClient) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n\n        if (input) {\n            const newInputMessage = new HumanMessage(input.text)\n            const messageToAdd = [newInputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }\n\n        if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        if (!this.redisClient) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        await this.redisClient.del(id)\n        await this.clear()\n    }\n}"
}

## UpstashRedisBackedChatMemory_Memory

{
  "className": "UpstashRedisBackedChatMemory_Memory",
  "init": "[Function: init]",
  "if": "if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }",
  "constructor": "constructor(fields: BufferMemoryInput & BufferMemoryExtendedInput) {\n        super(fields)\n        this.sessionId = fields.sessionId\n        this.redisClient = fields.redisClient\n        this.sessionTTL = fields.sessionTTL\n    }",
  "outsideClass_getRedisClientbyOption": "const getRedisClientbyOption = (option: RedisConfigNodejs) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    } else if (redisClientSingleton && !isEqual(option, redisClientOption)) {\n        // if client exists but option changed\n        redisClientSingleton = new Redis(option)\n        redisClientOption = option\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}",
  "outsideClass_initalizeUpstashRedis": "const initalizeUpstashRedis = async (nodeData: INodeData, options: ICommonObject): Promise<BufferMemory> => {\n    const baseURL = nodeData.inputs?.baseURL as string\n    const sessionId = nodeData.inputs?.sessionId as string\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const _sessionTTL = nodeData.inputs?.sessionTTL as string\n    const sessionTTL = _sessionTTL ? parseInt(_sessionTTL, 10) : undefined\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const upstashRestToken = getCredentialParam('upstashRestToken', credentialData, nodeData)\n\n    const client = getRedisClientbyOption({\n        url: baseURL,\n        token: upstashRestToken\n    })\n\n    const redisChatMessageHistory = new UpstashRedisChatMessageHistory({\n        sessionId,\n        sessionTTL,\n        client\n    })\n\n    const memory = new BufferMemoryExtended({\n        memoryKey: memoryKey ?? 'chat_history',\n        chatHistory: redisChatMessageHistory,\n        sessionId,\n        sessionTTL,\n        redisClient: client\n    })\n\n    return memory\n}\n\ninterface BufferMemoryExtendedInput {\n    redisClient: Redis\n    sessionId: string\n    sessionTTL?: number\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const rawStoredMessages: StoredMessage[] = await this.redisClient.lrange<StoredMessage>(id, 0, -1)\n        const orderedMessages = rawStoredMessages.reverse()\n        const previousMessages = orderedMessages.filter((x): x is StoredMessage => x.type !== undefined && x.data.content !== undefined)\n        const baseMessages = previousMessages.map(mapStoredMessageToChatMessage)\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        if (!this.redisClient) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n\n        if (input) {\n            const newInputMessage = new HumanMessage(input.text)\n            const messageToAdd = [newInputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }\n\n        if (output) {\n            const newOutputMessage = new AIMessage(output.text)\n            const messageToAdd = [newOutputMessage].map((msg) => msg.toDict())\n            await this.redisClient.lpush(id, JSON.stringify(messageToAdd[0]))\n            if (this.sessionTTL) await this.redisClient.expire(id, this.sessionTTL)\n        }\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        if (!this.redisClient) return\n\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        await this.redisClient.del(id)\n        await this.clear()\n    }\n}"
}

## ZepMemory_Memory

{
  "className": "ZepMemory_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: ZepMemoryInput & ZepMemoryExtendedInput) {\n        super(fields)\n        this.lastN = fields.k\n    }",
  "if": "if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }",
  "outsideClass_initializeZep": "const initializeZep = async (nodeData: INodeData, options: ICommonObject): Promise<ZepMemory> => {\n    const baseURL = nodeData.inputs?.baseURL as string\n    const aiPrefix = nodeData.inputs?.aiPrefix as string\n    const humanPrefix = nodeData.inputs?.humanPrefix as string\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const inputKey = nodeData.inputs?.inputKey as string\n    const k = nodeData.inputs?.k as string\n    const sessionId = nodeData.inputs?.sessionId as string\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n\n    const obj: ZepMemoryInput & ZepMemoryExtendedInput = {\n        baseURL,\n        aiPrefix,\n        humanPrefix,\n        returnMessages: true,\n        memoryKey,\n        inputKey,\n        sessionId,\n        k: k ? parseInt(k, 10) : undefined\n    }\n    if (apiKey) obj.apiKey = apiKey\n\n    return new ZepMemoryExtended(obj)\n}\n\ninterface ZepMemoryExtendedInput {\n    k?: number\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const memoryVariables = await this.loadMemoryVariables({}, id)\n        const baseMessages = memoryVariables[this.memoryKey]\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n        const inputValues = { [this.inputKey ?? 'input']: input?.text }\n        const outputValues = { output: output?.text }\n\n        await this.saveContext(inputValues, outputValues, id)\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        await this.clear(id)\n    }\n}"
}

## ZepMemoryCloud_Memory

{
  "className": "ZepMemoryCloud_Memory",
  "init": "[Function: init]",
  "constructor": "constructor(fields: ZepMemoryInput & ZepMemoryExtendedInput) {\n        super(fields)\n        this.memoryType = fields.memoryType ?? 'perpetual'\n    }",
  "if": "if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }",
  "outsideClass_initializeZep": "const initializeZep = async (nodeData: INodeData, options: ICommonObject): Promise<ZepMemory> => {\n    const aiPrefix = nodeData.inputs?.aiPrefix as string\n    const humanPrefix = nodeData.inputs?.humanPrefix as string\n    const memoryKey = nodeData.inputs?.memoryKey as string\n    const inputKey = nodeData.inputs?.inputKey as string\n\n    const memoryType = nodeData.inputs?.memoryType as 'perpetual' | 'message_window'\n    const sessionId = nodeData.inputs?.sessionId as string\n\n    const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n    const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n    const obj: ZepMemoryInput & ZepMemoryExtendedInput = {\n        apiKey,\n        aiPrefix,\n        humanPrefix,\n        memoryKey,\n        sessionId,\n        inputKey,\n        memoryType: memoryType,\n        returnMessages: true\n    }\n\n    return new ZepMemoryExtended(obj)\n}\n\ninterface ZepMemoryExtendedInput {\n    memoryType?: 'perpetual' | 'message_window'\n}",
  "outsideClass_id": "const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const memoryVariables = await this.loadMemoryVariables({}, id)\n        const baseMessages = memoryVariables[this.memoryKey]\n        if (prependMessages?.length) {\n            baseMessages.unshift(...(await mapChatMessageToBaseMessage(prependMessages)))\n        }\n        return returnBaseMessages ? baseMessages : convertBaseMessagetoIMessage(baseMessages)\n    }\n\n    async addChatMessages(msgArray: { text: string; type: MessageType }[], overrideSessionId = ''): Promise<void> {\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        const input = msgArray.find((msg) => msg.type === 'userMessage')\n        const output = msgArray.find((msg) => msg.type === 'apiMessage')\n        const inputValues = { [this.inputKey ?? 'input']: input?.text }\n        const outputValues = { output: output?.text }\n\n        await this.saveContext(inputValues, outputValues, id)\n    }\n\n    async clearChatMessages(overrideSessionId = ''): Promise<void> {\n        const id = overrideSessionId ? overrideSessionId : this.sessionId\n        await this.clear(id)\n    }\n}"
}

## OpenAIModeration

{
  "className": "OpenAIModeration",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAI Moderation'\n        this.name = 'inputModerationOpenAI'\n        this.version = 1.0\n        this.type = 'Moderation'\n        this.icon = 'openai.svg'\n        this.category = 'Moderation'\n        this.description = 'Check whether content complies with OpenAI usage policies.'\n        this.baseClasses = [this.type, ...getBaseClasses(Moderation)]\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openAIApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAIApiKey = getCredentialParam('openAIApiKey', credentialData, nodeData)\n\n        const runner = new OpenAIModerationRunner(openAIApiKey)\n        const moderationErrorMessage = nodeData.inputs?.moderationErrorMessage as string\n        if (moderationErrorMessage) runner.setErrorMessage(moderationErrorMessage)\n        return runner\n    }\n}"
}

## SimplePromptModeration

{
  "className": "SimplePromptModeration",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Simple Prompt Moderation'\n        this.name = 'inputModerationSimple'\n        this.version = 2.0\n        this.type = 'Moderation'\n        this.icon = 'moderation.svg'\n        this.category = 'Moderation'\n        this.description = 'Check whether input consists of any text from Deny list, and prevent being sent to LLM'\n        this.baseClasses = [this.type, ...getBaseClasses(Moderation)]\n        this.inputs = [\n            {\n                label: 'Deny List',\n                name: 'denyList',\n                type: 'string',\n                rows: 4,\n                placeholder: `ignore previous instructions\\ndo not follow the directions\\nyou must ignore all previous instructions`,\n                description: 'An array of string literals (enter one per line) that should not appear in the prompt text.'\n            }",
  "outsideClass_denyList": "const denyList = nodeData.inputs?.denyList as string\n        const model = nodeData.inputs?.model as BaseChatModel\n        const moderationErrorMessage = nodeData.inputs?.moderationErrorMessage as string\n\n        return new SimplePromptModerationRunner(denyList, moderationErrorMessage, model)\n    }\n}"
}

## Supervisor_MultiAgents

{
  "className": "Supervisor_MultiAgents",
  "init": "[Function: init]",
  "constructor": "constructor(fields: ICommonObject) {\n        super()\n        this.schema = fields.schema\n    }",
  "if": "if (multiModalMessageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n\n            prompt.promptMessages.splice(index, 0, msg)\n        }",
  "agentNode": "agentNode(\n    {\n        state,\n        agent,\n        nodeId,\n        abortControllerSignal\n    }: { state: ITeamState; agent: AgentExecutor | Runnable; nodeId: string; abortControllerSignal: AbortController },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }",
  "catch": "catch (error) {\n        throw new Error('Aborted!')\n    }",
  "_call": "_call(input: any) {\n        return JSON.stringify(input)\n    }",
  "outsideClass_sysPrompt": "const sysPrompt = `You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.`\n\nconst routerToolName = 'route'\n\nconst defaultSummarization = 'Conversation finished'\nconst defaultInstruction = 'Conversation finished'",
  "outsideClass_llm": "const llm = nodeData.inputs?.model as BaseChatModel\n        const supervisorPrompt = nodeData.inputs?.supervisorPrompt as string\n        const supervisorLabel = nodeData.inputs?.supervisorName as string\n        const _recursionLimit = nodeData.inputs?.recursionLimit as string\n        const recursionLimit = _recursionLimit ? parseFloat(_recursionLimit) : 100\n        const moderations = (nodeData.inputs?.inputModeration as Moderation[]) ?? []\n        const summarization = nodeData.inputs?.summarization as string\n\n        const abortControllerSignal = options.signal as AbortController\n\n        const workersNodes: IMultiAgentNode[] =\n            nodeData.inputs?.workerNodes && nodeData.inputs?.workerNodes.length ? flatten(nodeData.inputs?.workerNodes) : []\n        const workersNodeNames = workersNodes.map((node: IMultiAgentNode) => node.name)\n\n        if (!supervisorLabel) throw new Error('Supervisor name is required!')\n\n        const supervisorName = supervisorLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        let multiModalMessageContent: MessageContentImageUrl[] = []\n\n        async function createTeamSupervisor(llm: BaseChatModel, systemPrompt: string, members: string[]): Promise<Runnable> {\n            const memberOptions = ['FINISH', ...members]\n\n            systemPrompt = systemPrompt.replaceAll('{team_members}', members.join(', '))\n\n            let userPrompt = `Given the conversation above, who should act next? Or should we FINISH? Select one of: ${memberOptions.join(\n                ', '\n            )}`\n\n            const tool = new RouteTool({\n                schema: z.object({\n                    reasoning: z.string(),\n                    next: z.enum(['FINISH', ...members]),\n                    instructions: z.string().describe('The specific instructions of the sub-task the next role should accomplish.')\n                })\n            })\n\n            let supervisor\n\n            if (llm instanceof ChatMistralAI) {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                // Force Mistral to use tool\n                // @ts-ignore\n                const modelWithTool = llm.bind({\n                    tools: [tool],\n                    tool_choice: 'any',\n                    signal: abortControllerSignal ? abortControllerSignal.signal : undefined\n                })\n\n                const outputParser = new JsonOutputToolsParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0]\n                            return {\n                                next: Object.keys(toolAgentAction.args).length ? toolAgentAction.args.next : 'FINISH',\n                                instructions: Object.keys(toolAgentAction.args).length\n                                    ? toolAgentAction.args.instructions\n                                    : 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatAnthropic) {\n                // Force Anthropic to use tool : https://docs.anthropic.com/claude/docs/tool-use#forcing-tool-use\n                userPrompt = `Given the conversation above, who should act next? Or should we FINISH? Select one of: ${memberOptions.join(\n                    ', '\n                )}. Use the ${routerToolName} tool in your response.`\n\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if ((llm as any).bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n\n                const modelWithTool = (llm as any).bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', ')\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', ')\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatOpenAI) {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                // @ts-ignore\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                // Force OpenAI to use tool\n                const modelWithTool = llm.bind({\n                    tools: [tool],\n                    tool_choice: { type: 'function', function: { name: routerToolName } },\n                    signal: abortControllerSignal ? abortControllerSignal.signal : undefined\n                })\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', ')\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', ')\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatGoogleGenerativeAI) {\n                /*\n                 * Gemini doesn't have system message and messages have to be alternate between model and user\n                 * So we have to place the system + human prompt at last\n                 */\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(2, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if (llm.bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n                const modelWithTool = llm.bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', ')\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', ')\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        }\n                    })\n            } else {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if (llm.bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n                const modelWithTool = llm.bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', ')\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', ')\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: 'Conversation finished',\n                                team_members: members.join(', ')\n                            }\n                        }\n                    })\n            }\n\n            return supervisor\n        }\n\n        async function createTeamSupervisorWithSummarize(llm: BaseChatModel, systemPrompt: string, members: string[]): Promise<Runnable> {\n            const memberOptions = ['FINISH', ...members]\n\n            systemPrompt = systemPrompt.replaceAll('{team_members}', members.join(', '))\n\n            let userPrompt = `Given the conversation above, who should act next? Or should we FINISH? Select one of: ${memberOptions.join(\n                ', '\n            )}\n            Remember to give reasonings, instructions and summarization`\n\n            const tool = new RouteTool({\n                schema: z.object({\n                    reasoning: z.string(),\n                    next: z.enum(['FINISH', ...members]),\n                    instructions: z.string().describe('The specific instructions of the sub-task the next role should accomplish.'),\n                    summarization: z.string().optional().describe('Summarization of the conversation')\n                })\n            })\n\n            let supervisor\n\n            if (llm instanceof ChatMistralAI) {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                // Force Mistral to use tool\n                // @ts-ignore\n                const modelWithTool = llm.bind({\n                    tools: [tool],\n                    tool_choice: 'any',\n                    signal: abortControllerSignal ? abortControllerSignal.signal : undefined\n                })\n\n                const outputParser = new JsonOutputToolsParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0]\n                            return {\n                                next: Object.keys(toolAgentAction.args).length ? toolAgentAction.args.next : 'FINISH',\n                                instructions: Object.keys(toolAgentAction.args).length\n                                    ? toolAgentAction.args.instructions\n                                    : defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: Object.keys(toolAgentAction.args).length ? toolAgentAction.args.summarization : ''\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatAnthropic) {\n                // Force Anthropic to use tool : https://docs.anthropic.com/claude/docs/tool-use#forcing-tool-use\n                userPrompt = `Given the conversation above, who should act next? Or should we FINISH? Select one of: ${memberOptions.join(\n                    ', '\n                )}. Remember to give reasonings, instructions and summarization. Use the ${routerToolName} tool in your response.`\n\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if ((llm as any).bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n\n                const modelWithTool = (llm as any).bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', '),\n                                summarization: toolAgentAction.toolInput.summarization\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatOpenAI) {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                // @ts-ignore\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                // Force OpenAI to use tool\n                const modelWithTool = llm.bind({\n                    tools: [tool],\n                    tool_choice: { type: 'function', function: { name: routerToolName } },\n                    signal: abortControllerSignal ? abortControllerSignal.signal : undefined\n                })\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', '),\n                                summarization: toolAgentAction.toolInput.summarization\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        }\n                    })\n            } else if (llm instanceof ChatGoogleGenerativeAI) {\n                /*\n                 * Gemini doesn't have system message and messages have to be alternate between model and user\n                 * So we have to place the system + human prompt at last\n                 */\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(2, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if (llm.bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n                const modelWithTool = llm.bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', '),\n                                summarization: toolAgentAction.toolInput.summarization\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        }\n                    })\n            } else {\n                let prompt = ChatPromptTemplate.fromMessages([\n                    ['system', systemPrompt],\n                    new MessagesPlaceholder('messages'),\n                    ['human', userPrompt]\n                ])\n\n                const messages = await processImageMessage(1, llm, prompt, nodeData, options)\n                prompt = messages.prompt\n                multiModalMessageContent = messages.multiModalMessageContent\n\n                if (llm.bindTools === undefined) {\n                    throw new Error(`This agent only compatible with function calling models.`)\n                }\n                const modelWithTool = llm.bindTools([tool])\n\n                const outputParser = new ToolCallingAgentOutputParser()\n\n                supervisor = prompt\n                    .pipe(modelWithTool)\n                    .pipe(outputParser)\n                    .pipe((x) => {\n                        if (Array.isArray(x) && x.length) {\n                            const toolAgentAction = x[0] as any\n                            return {\n                                next: toolAgentAction.toolInput.next,\n                                instructions: toolAgentAction.toolInput.instructions,\n                                team_members: members.join(', '),\n                                summarization: toolAgentAction.toolInput.summarization\n                            }\n                        } else if (typeof x === 'object' && 'returnValues' in x) {\n                            return {\n                                next: 'FINISH',\n                                instructions: x.returnValues?.output,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        } else {\n                            return {\n                                next: 'FINISH',\n                                instructions: defaultInstruction,\n                                team_members: members.join(', '),\n                                summarization: defaultSummarization\n                            }\n                        }\n                    })\n            }\n\n            return supervisor\n        }\n\n        const supervisorAgent = summarization\n            ? await createTeamSupervisorWithSummarize(llm, supervisorPrompt ? supervisorPrompt : sysPrompt, workersNodeNames)\n            : await createTeamSupervisor(llm, supervisorPrompt ? supervisorPrompt : sysPrompt, workersNodeNames)\n\n        const supervisorNode = async (state: ITeamState, config: RunnableConfig) =>\n            await agentNode(\n                {\n                    state,\n                    agent: supervisorAgent,\n                    nodeId: nodeData.id,\n                    abortControllerSignal\n                },\n                config\n            )\n\n        const returnOutput: IMultiAgentNode = {\n            node: supervisorNode,\n            name: supervisorName ?? 'supervisor',\n            label: supervisorLabel ?? 'Supervisor',\n            type: 'supervisor',\n            workers: workersNodeNames,\n            recursionLimit,\n            llm,\n            moderations,\n            multiModalMessageContent,\n            checkpointMemory: nodeData.inputs?.agentMemory\n        }\n\n        return returnOutput\n    }\n}\n\nasync function agentNode(\n    {\n        state,\n        agent,\n        nodeId,\n        abortControllerSignal\n    }: { state: ITeamState; agent: AgentExecutor | Runnable; nodeId: string; abortControllerSignal: AbortController },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }\n        const result = await agent.invoke({ ...state, signal: abortControllerSignal.signal }, config)\n        const additional_kwargs: ICommonObject = { nodeId, type: 'supervisor' }\n        result.additional_kwargs = { ...result.additional_kwargs, ...additional_kwargs }\n        return result\n    } catch (error) {\n        throw new Error('Aborted!')\n    }\n}\n\nconst processImageMessage = async (\n    index: number,\n    llm: BaseChatModel,\n    prompt: ChatPromptTemplate,\n    nodeData: INodeData,\n    options: ICommonObject\n) => {\n    let multiModalMessageContent: MessageContentImageUrl[] = []\n\n    if (llmSupportsVision(llm)) {\n        const visionChatModel = llm as IVisionChatModal\n        multiModalMessageContent = await addImagesToMessages(nodeData, options, llm.multiModalOption)\n\n        if (multiModalMessageContent?.length) {\n            visionChatModel.setVisionModel()\n\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n\n            prompt.promptMessages.splice(index, 0, msg)\n        } else {\n            visionChatModel.revertToOriginalModel()\n        }\n    }\n\n    return { prompt, multiModalMessageContent }\n}"
}

## Worker_MultiAgents

{
  "className": "Worker_MultiAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Worker'\n        this.name = 'worker'\n        this.version = 2.0\n        this.type = 'Worker'\n        this.icon = 'worker.svg'\n        this.category = 'Multi Agents'\n        this.baseClasses = [this.type]\n        this.hideOutput = true\n        this.inputs = [\n            {\n                label: 'Worker Name',\n                name: 'workerName',\n                type: 'string',\n                placeholder: 'Worker'\n            }",
  "if": "if (result.sourceDocuments) {\n            additional_kwargs.sourceDocuments = result.sourceDocuments\n        }",
  "catch": "catch (error) {\n        throw new Error('Aborted!')\n    }",
  "agentNode": "agentNode(\n    {\n        state,\n        agent,\n        name,\n        nodeId,\n        abortControllerSignal\n    }: { state: ITeamState; agent: AgentExecutor | RunnableSequence; name: string; nodeId: string; abortControllerSignal: AbortController },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }",
  "for": "for (const key in obj) {\n        transformedObject[key] = () => obj[key]\n    }",
  "outsideClass_examplePrompt": "const examplePrompt = 'You are a research assistant who can search for up-to-date info using search engine.'",
  "outsideClass_workerLabel": "const workerLabel = nodeData.inputs?.workerName as string\n        const supervisor = nodeData.inputs?.supervisor as IMultiAgentNode\n        const maxIterations = nodeData.inputs?.maxIterations as string\n        const model = nodeData.inputs?.model as BaseChatModel\n        const promptValuesStr = nodeData.inputs?.promptValues\n\n        if (!workerLabel) throw new Error('Worker name is required!')\n        const workerName = workerLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        if (!workerPrompt) throw new Error('Worker prompt is required!')\n\n        let workerInputVariablesValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                workerInputVariablesValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the Worker's Prompt Input Values: \" + exception)\n            }\n        }\n        workerInputVariablesValues = handleEscapeCharacters(workerInputVariablesValues, true)\n\n        const llm = model || (supervisor.llm as BaseChatModel)\n        const multiModalMessageContent = supervisor?.multiModalMessageContent || []\n\n        const abortControllerSignal = options.signal as AbortController\n        const workerInputVariables = getInputVariables(workerPrompt)\n\n        if (!workerInputVariables.every((element) => Object.keys(workerInputVariablesValues).includes(element))) {\n            throw new Error('Worker input variables values are not provided!')\n        }\n\n        const agent = await createAgent(\n            llm,\n            [...tools],\n            workerPrompt,\n            multiModalMessageContent,\n            workerInputVariablesValues,\n            maxIterations,\n            {\n                sessionId: options.sessionId,\n                chatId: options.chatId,\n                input\n            }\n        )\n\n        const workerNode = async (state: ITeamState, config: RunnableConfig) =>\n            await agentNode(\n                {\n                    state,\n                    agent: agent,\n                    name: workerName,\n                    nodeId: nodeData.id,\n                    abortControllerSignal\n                },\n                config\n            )\n\n        const returnOutput: IMultiAgentNode = {\n            node: workerNode,\n            name: workerName,\n            label: workerLabel,\n            type: 'worker',\n            workerPrompt,\n            workerInputVariables,\n            parentSupervisorName: supervisor.name ?? 'supervisor'\n        }\n\n        return returnOutput\n    }\n}\n\nasync function createAgent(\n    llm: BaseChatModel,\n    tools: any[],\n    systemPrompt: string,\n    multiModalMessageContent: MessageContentImageUrl[],\n    workerInputVariablesValues: ICommonObject,\n    maxIterations?: string,\n    flowObj?: { sessionId?: string; chatId?: string; input?: string }\n): Promise<AgentExecutor | RunnableSequence> {\n    if (tools.length) {\n        const combinedPrompt =\n            systemPrompt +\n            '\\nWork autonomously according to your specialty, using the tools available to you.' +\n            ' Do not ask for clarification.' +\n            ' Your other team members (and other teams) will collaborate with you with their own specialties.' +\n            ' You are chosen for a reason! You are one of the following team members: {team_members}.'\n\n        //const toolNames = tools.length ? tools.map((t) => t.name).join(', ') : ''\n        const prompt = ChatPromptTemplate.fromMessages([\n            ['system', combinedPrompt],\n            new MessagesPlaceholder('messages'),\n            new MessagesPlaceholder('agent_scratchpad')\n            /* Gettind rid of this for now because other LLMs dont support system message at later stage\n            [\n                'system',\n                [\n                    'Supervisor instructions: {instructions}\\n' + tools.length\n                        ? `Remember, you individually can only use these tools: ${toolNames}`\n                        : '' + '\\n\\nEnd if you have already completed the requested task. Communicate the work completed.'\n                ].join('\\n')\n            ]*/\n        ])\n\n        if (multiModalMessageContent.length) {\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n            prompt.promptMessages.splice(1, 0, msg)\n        }\n\n        if (llm.bindTools === undefined) {\n            throw new Error(`This agent only compatible with function calling models.`)\n        }\n        const modelWithTools = llm.bindTools(tools)\n\n        let agent\n\n        if (!workerInputVariablesValues || !Object.keys(workerInputVariablesValues).length) {\n            agent = RunnableSequence.from([\n                RunnablePassthrough.assign({\n                    //@ts-ignore\n                    agent_scratchpad: (input: { steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(input.steps)\n                }),\n                prompt,\n                modelWithTools,\n                new ToolCallingAgentOutputParser()\n            ])\n        } else {\n            agent = RunnableSequence.from([\n                RunnablePassthrough.assign({\n                    //@ts-ignore\n                    agent_scratchpad: (input: { steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(input.steps)\n                }),\n                RunnablePassthrough.assign(transformObjectPropertyToFunction(workerInputVariablesValues)),\n                prompt,\n                modelWithTools,\n                new ToolCallingAgentOutputParser()\n            ])\n        }\n\n        const executor = AgentExecutor.fromAgentAndTools({\n            agent,\n            tools,\n            sessionId: flowObj?.sessionId,\n            chatId: flowObj?.chatId,\n            input: flowObj?.input,\n            verbose: process.env.DEBUG === 'true' ? true : false,\n            maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n        })\n        return executor\n    } else {\n        const combinedPrompt =\n            systemPrompt +\n            '\\nWork autonomously according to your specialty, using the tools available to you.' +\n            ' Do not ask for clarification.' +\n            ' Your other team members (and other teams) will collaborate with you with their own specialties.' +\n            ' You are chosen for a reason! You are one of the following team members: {team_members}.'\n\n        const prompt = ChatPromptTemplate.fromMessages([['system', combinedPrompt], new MessagesPlaceholder('messages')])\n        if (multiModalMessageContent.length) {\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n            prompt.promptMessages.splice(1, 0, msg)\n        }\n\n        let conversationChain\n\n        if (!workerInputVariablesValues || !Object.keys(workerInputVariablesValues).length) {\n            conversationChain = RunnableSequence.from([prompt, llm, new StringOutputParser()])\n        } else {\n            conversationChain = RunnableSequence.from([\n                RunnablePassthrough.assign(transformObjectPropertyToFunction(workerInputVariablesValues)),\n                prompt,\n                llm,\n                new StringOutputParser()\n            ])\n        }\n        return conversationChain\n    }\n}\n\nasync function agentNode(\n    {\n        state,\n        agent,\n        name,\n        nodeId,\n        abortControllerSignal\n    }: { state: ITeamState; agent: AgentExecutor | RunnableSequence; name: string; nodeId: string; abortControllerSignal: AbortController },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }\n\n        const result = await agent.invoke({ ...state, signal: abortControllerSignal.signal }, config)\n        const additional_kwargs: ICommonObject = { nodeId, type: 'worker' }\n        if (result.usedTools) {\n            additional_kwargs.usedTools = result.usedTools\n        }\n        if (result.sourceDocuments) {\n            additional_kwargs.sourceDocuments = result.sourceDocuments\n        }\n        return {\n            messages: [\n                new HumanMessage({\n                    content: typeof result === 'string' ? result : result.output,\n                    name,\n                    additional_kwargs: Object.keys(additional_kwargs).length ? additional_kwargs : undefined\n                })\n            ]\n        }\n    } catch (error) {\n        throw new Error('Aborted!')\n    }\n}\n\nconst transformObjectPropertyToFunction = (obj: ICommonObject) => {\n    const transformedObject: ICommonObject = {}\n\n    for (const key in obj) {\n        transformedObject[key] = () => obj[key]\n    }\n\n    return transformedObject\n}"
}

## CSVListOutputParser

{
  "className": "CSVListOutputParser",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'CSV Output Parser'\n        this.name = 'csvOutputParser'\n        this.version = 1.0\n        this.type = 'CSVListOutputParser'\n        this.description = 'Parse the output of an LLM call as a comma-separated list of values'\n        this.icon = 'csv.svg'\n        this.category = CATEGORY\n        this.baseClasses = [this.type, ...getBaseClasses(BaseOutputParser)]\n        this.inputs = [\n            {\n                label: 'Autofix',\n                name: 'autofixParser',\n                type: 'boolean',\n                optional: true,\n                description: 'In the event that the first call fails, will make another call to the model to fix any errors.'\n            }",
  "outsideClass_autoFix": "const autoFix = nodeData.inputs?.autofixParser as boolean\n\n        const commaSeparatedListOutputParser = new CommaSeparatedListOutputParser()\n        Object.defineProperty(commaSeparatedListOutputParser, 'autoFix', {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: autoFix\n        })\n        return commaSeparatedListOutputParser\n    }\n}"
}

## CustomListOutputParser

{
  "className": "CustomListOutputParser",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Custom List Output Parser'\n        this.name = 'customListOutputParser'\n        this.version = 1.0\n        this.type = 'CustomListOutputParser'\n        this.description = 'Parse the output of an LLM call as a list of values.'\n        this.icon = 'list.svg'\n        this.category = CATEGORY\n        this.baseClasses = [this.type, ...getBaseClasses(BaseOutputParser)]\n        this.inputs = [\n            {\n                label: 'Length',\n                name: 'length',\n                type: 'number',\n                step: 1,\n                description: 'Number of values to return',\n                optional: true\n            }",
  "outsideClass_separator": "const separator = nodeData.inputs?.separator as string\n        const lengthStr = nodeData.inputs?.length as string\n        const autoFix = nodeData.inputs?.autofixParser as boolean\n\n        const parser = new LangchainCustomListOutputParser({\n            length: lengthStr ? parseInt(lengthStr, 10) : undefined,\n            separator: separator\n        })\n        Object.defineProperty(parser, 'autoFix', {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: autoFix\n        })\n        return parser\n    }\n}"
}

## StructuredOutputParser

{
  "className": "StructuredOutputParser",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Structured Output Parser'\n        this.name = 'structuredOutputParser'\n        this.version = 1.0\n        this.type = 'StructuredOutputParser'\n        this.description = 'Parse the output of an LLM call into a given (JSON) structure.'\n        this.icon = 'structure.svg'\n        this.category = CATEGORY\n        this.baseClasses = [this.type, ...getBaseClasses(BaseOutputParser)]\n        this.inputs = [\n            {\n                label: 'Autofix',\n                name: 'autofixParser',\n                type: 'boolean',\n                optional: true,\n                description: 'In the event that the first call fails, will make another call to the model to fix any errors.'\n            }",
  "catch": "catch (exception) {\n            throw new Error('Invalid JSON in StructuredOutputParser: ' + exception)\n        }",
  "outsideClass_jsonStructure": "const jsonStructure = nodeData.inputs?.jsonStructure as string\n        const autoFix = nodeData.inputs?.autofixParser as boolean\n\n        try {\n            const zodSchema = z.object(convertSchemaToZod(jsonStructure)) as any\n            const structuredOutputParser = LangchainStructuredOutputParser.fromZodSchema(zodSchema)\n\n            // NOTE: When we change Flowise to return a json response, the following has to be changed to: JsonStructuredOutputParser\n            Object.defineProperty(structuredOutputParser, 'autoFix', {\n                enumerable: true,\n                configurable: true,\n                writable: true,\n                value: autoFix\n            })\n            return structuredOutputParser\n        } catch (exception) {\n            throw new Error('Invalid JSON in StructuredOutputParser: ' + exception)\n        }\n    }\n}"
}

## AdvancedStructuredOutputParser

{
  "className": "AdvancedStructuredOutputParser",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Advanced Structured Output Parser'\n        this.name = 'advancedStructuredOutputParser'\n        this.version = 1.0\n        this.type = 'AdvancedStructuredOutputParser'\n        this.description = 'Parse the output of an LLM call into a given structure by providing a Zod schema.'\n        this.icon = 'structure.svg'\n        this.category = CATEGORY\n        this.baseClasses = [this.type, ...getBaseClasses(BaseOutputParser)]\n        this.inputs = [\n            {\n                label: 'Autofix',\n                name: 'autofixParser',\n                type: 'boolean',\n                optional: true,\n                description: 'In the event that the first call fails, will make another call to the model to fix any errors.'\n            }",
  "catch": "catch (exception) {\n            throw new Error('Error parsing Zod Schema: ' + exception)\n        }",
  "outsideClass_schemaString": "const schemaString = nodeData.inputs?.exampleJson as string\n        const autoFix = nodeData.inputs?.autofixParser as boolean\n\n        const zodSchemaFunction = new Function('z', `return ${schemaString}`)\n        const zodSchema = zodSchemaFunction(z)\n\n        try {\n            const structuredOutputParser = LangchainStructuredOutputParser.fromZodSchema(zodSchema)\n\n            // NOTE: When we change Flowise to return a json response, the following has to be changed to: JsonStructuredOutputParser\n            Object.defineProperty(structuredOutputParser, 'autoFix', {\n                enumerable: true,\n                configurable: true,\n                writable: true,\n                value: autoFix\n            })\n            return structuredOutputParser\n        } catch (exception) {\n            throw new Error('Error parsing Zod Schema: ' + exception)\n        }\n    }\n}"
}

## ChatPromptTemplate_Prompts

{
  "className": "ChatPromptTemplate_Prompts",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Chat Prompt Template'\n        this.name = 'chatPromptTemplate'\n        this.version = 2.0\n        this.type = 'ChatPromptTemplate'\n        this.icon = 'prompt.svg'\n        this.category = 'Prompts'\n        this.description = 'Schema to represent a chat prompt'\n        this.baseClasses = [this.type, ...getBaseClasses(ChatPromptTemplate)]\n        this.inputs = [\n            {\n                label: 'System Message',\n                name: 'systemMessagePrompt',\n                type: 'string',\n                rows: 4,\n                placeholder: `You are a helpful assistant that translates {input_language}",
  "run": "run(`module.exports = async function() {${messageHistoryCode}",
  "catch": "catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatPromptTemplate's promptValues: \" + exception)\n            }",
  "if": "if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            }",
  "outsideClass_defaultFunc": "const defaultFunc = `const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]`\nconst TAB_IDENTIFIER = 'selectedMessagesTab'",
  "outsideClass_systemMessagePrompt": "const systemMessagePrompt = nodeData.inputs?.systemMessagePrompt as string\n        const humanMessagePrompt = nodeData.inputs?.humanMessagePrompt as string\n        const promptValuesStr = nodeData.inputs?.promptValues\n        const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n        const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'messageHistoryCode'\n        const messageHistoryCode = nodeData.inputs?.messageHistoryCode\n        const messageHistory = nodeData.inputs?.messageHistory\n\n        let prompt = ChatPromptTemplate.fromMessages([\n            SystemMessagePromptTemplate.fromTemplate(systemMessagePrompt),\n            HumanMessagePromptTemplate.fromTemplate(humanMessagePrompt)\n        ])\n\n        if (\n            (messageHistory && messageHistory === 'messageHistoryCode' && messageHistoryCode) ||\n            (selectedTab === 'messageHistoryCode' && messageHistoryCode)\n        ) {\n            const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n            const vm = await getVM(appDataSource, databaseEntities, nodeData, {})\n            try {\n                const response = await vm.run(`module.exports = async function() {${messageHistoryCode}}()`, __dirname)\n                if (!Array.isArray(response)) throw new Error('Returned message history must be an array')\n                prompt = ChatPromptTemplate.fromMessages([\n                    SystemMessagePromptTemplate.fromTemplate(systemMessagePrompt),\n                    ...response,\n                    HumanMessagePromptTemplate.fromTemplate(humanMessagePrompt)\n                ])\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n\n        let promptValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the ChatPromptTemplate's promptValues: \" + exception)\n            }\n        }\n        // @ts-ignore\n        prompt.promptValues = promptValues\n\n        return prompt\n    }\n}"
}

## FewShotPromptTemplate_Prompts

{
  "className": "FewShotPromptTemplate_Prompts",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Few Shot Prompt Template'\n        this.name = 'fewShotPromptTemplate'\n        this.version = 1.0\n        this.type = 'FewShotPromptTemplate'\n        this.icon = 'prompt.svg'\n        this.category = 'Prompts'\n        this.description = 'Prompt template you can build with examples'\n        this.baseClasses = [this.type, ...getBaseClasses(FewShotPromptTemplate)]\n        this.inputs = [\n            {\n                label: 'Examples',\n                name: 'examples',\n                type: 'string',\n                rows: 4,\n                placeholder: `[\n  { \"word\": \"happy\", \"antonym\": \"sad\" }",
  "if": "if (examplesStr) {\n            try {\n                examples = typeof examplesStr === 'object' ? examplesStr : JSON.parse(examplesStr)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "outsideClass_examplesStr": "const examplesStr = nodeData.inputs?.examples\n        const prefix = nodeData.inputs?.prefix as string\n        const suffix = nodeData.inputs?.suffix as string\n        const exampleSeparator = nodeData.inputs?.exampleSeparator as string\n        const templateFormat = nodeData.inputs?.templateFormat as TemplateFormat\n        const examplePrompt = nodeData.inputs?.examplePrompt as PromptTemplate\n\n        const inputVariables = getInputVariables(suffix)\n\n        let examples: Example[] = []\n        if (examplesStr) {\n            try {\n                examples = typeof examplesStr === 'object' ? examplesStr : JSON.parse(examplesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the FewShotPromptTemplate's examples: \" + exception)\n            }\n        }\n\n        try {\n            const obj: FewShotPromptTemplateInput = {\n                examples,\n                examplePrompt,\n                prefix,\n                suffix,\n                inputVariables,\n                exampleSeparator,\n                templateFormat\n            }\n            const prompt = new FewShotPromptTemplate(obj)\n            return prompt\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## PromptLangfuse_Prompts

{
  "className": "PromptLangfuse_Prompts",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'LangFuse Prompt Template'\n        this.name = 'promptLangFuse'\n        this.version = 1.0\n        this.type = 'PromptTemplate'\n        this.icon = 'prompt.svg'\n        this.category = 'Prompts'\n        this.author = 'Lucas Cruz'\n        this.description = 'Fetch schema from LangFuse to represent a prompt for an LLM'\n        this.baseClasses = [...getBaseClasses(PromptTemplate)]\n        this.credential = {\n            label: 'Langfuse Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['langfuseApi']\n        }",
  "if": "if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const langFuseSecretKey = getCredentialParam('langFuseSecretKey', credentialData, nodeData)\n        const langFusePublicKey = getCredentialParam('langFusePublicKey', credentialData, nodeData)\n        const langFuseEndpoint = getCredentialParam('langFuseEndpoint', credentialData, nodeData)\n\n        const langfuse = new Langfuse({\n            secretKey: langFuseSecretKey,\n            publicKey: langFusePublicKey,\n            baseUrl: langFuseEndpoint ?? 'https://cloud.langfuse.com',\n            sdkIntegration: 'Flowise'\n        })\n\n        const langfusePrompt = await langfuse.getPrompt(nodeData.inputs?.template as string)\n        const template = langfusePrompt.getLangchainPrompt()\n\n        const promptValuesStr = nodeData.inputs?.promptValues\n\n        let promptValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the PromptTemplate's promptValues: \" + exception)\n            }\n        }\n\n        const inputVariables = getInputVariables(template)\n\n        try {\n            const options: PromptTemplateInput = {\n                template,\n                inputVariables\n            }\n            const prompt = new PromptTemplate(options)\n            prompt.promptValues = promptValues\n            return prompt\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## PromptTemplate_Prompts

{
  "className": "PromptTemplate_Prompts",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Prompt Template'\n        this.name = 'promptTemplate'\n        this.version = 1.0\n        this.type = 'PromptTemplate'\n        this.icon = 'prompt.svg'\n        this.category = 'Prompts'\n        this.description = 'Schema to represent a basic prompt for an LLM'\n        this.baseClasses = [...getBaseClasses(PromptTemplate)]\n        this.inputs = [\n            {\n                label: 'Template',\n                name: 'template',\n                type: 'string',\n                rows: 4,\n                placeholder: `What is a good name for a company that makes {product}",
  "if": "if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "outsideClass_template": "const template = nodeData.inputs?.template as string\n        const promptValuesStr = nodeData.inputs?.promptValues\n\n        let promptValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                promptValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the PromptTemplate's promptValues: \" + exception)\n            }\n        }\n\n        const inputVariables = getInputVariables(template)\n\n        try {\n            const options: PromptTemplateInput = {\n                template,\n                inputVariables\n            }\n            const prompt = new PromptTemplate(options)\n            prompt.promptValues = promptValues\n            return prompt\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## MySQLRecordManager_RecordManager

{
  "className": "MySQLRecordManager_RecordManager",
  "init": "[Function: init]",
  "constructor": "constructor(namespace: string, config: MySQLRecordManagerOptions) {\n        const { mysqlOptions, tableName }",
  "if": "if (keys.length === 0) {\n            return\n        }",
  "catch": "catch (error) {\n            console.error('Error deleting keys')\n            throw error // Re-throw the error to be handled by the caller\n        }",
  "for": "for (const record of recordsToUpsert) {\n            // Consider using a transaction for batch operations\n            await this.queryRunner.manager.query(query, record.flat())\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const user = getCredentialParam('user', credentialData, nodeData)\n        const password = getCredentialParam('password', credentialData, nodeData)\n        const _tableName = nodeData.inputs?.tableName as string\n        const tableName = _tableName ? _tableName : 'upsertion_records'\n        const additionalConfig = nodeData.inputs?.additionalConfig as string\n        const _namespace = nodeData.inputs?.namespace as string\n        const namespace = _namespace ? _namespace : options.chatflowid\n        const cleanup = nodeData.inputs?.cleanup as string\n        const _sourceIdKey = nodeData.inputs?.sourceIdKey as string\n        const sourceIdKey = _sourceIdKey ? _sourceIdKey : 'source'\n\n        let additionalConfiguration = {}\n        if (additionalConfig) {\n            try {\n                additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }\n        }\n\n        const mysqlOptions = {\n            ...additionalConfiguration,\n            type: 'mysql',\n            host: nodeData.inputs?.host as string,\n            port: nodeData.inputs?.port as number,\n            username: user,\n            password: password,\n            database: nodeData.inputs?.database as string\n        }\n\n        const args = {\n            mysqlOptions,\n            tableName: tableName\n        }\n\n        const recordManager = new MySQLRecordManager(namespace, args)\n\n        ;(recordManager as any).cleanup = cleanup\n        ;(recordManager as any).sourceIdKey = sourceIdKey\n\n        return recordManager\n    }\n}\n\ntype MySQLRecordManagerOptions = {\n    mysqlOptions: any\n    tableName?: string\n}",
  "outsideClass_appDataSource": "const appDataSource = await this.datasource.initialize()\n\n            this.queryRunner = appDataSource.createQueryRunner()\n\n            await this.queryRunner.manager.query(`create table if not exists \\`${this.tableName}\\` (\n                \\`uuid\\` varchar(36) primary key default (UUID()),\n                \\`key\\` varchar(255) not null,\n                \\`namespace\\` varchar(255) not null,\n                \\`updated_at\\` DOUBLE precision not null,\n                \\`group_id\\` longtext,\n                unique key \\`unique_key_namespace\\` (\\`key\\`,\n\\`namespace\\`));`)\n            const columns = [`updated_at`, `key`, `namespace`, `group_id`]\n            for (const column of columns) {\n                // MySQL does not support 'IF NOT EXISTS' function for Index\n                const Check = await this.queryRunner.manager.query(\n                    `SELECT COUNT(1) IndexIsThere FROM INFORMATION_SCHEMA.STATISTICS \n                        WHERE table_schema=DATABASE() AND table_name='${this.tableName}' AND index_name='${column}_index';`\n                )\n                if (Check[0].IndexIsThere === 0)\n                    await this.queryRunner.manager.query(`CREATE INDEX \\`${column}_index\\`\n        ON \\`${this.tableName}\\` (\\`${column}\\`);`)\n            }\n        } catch (e: any) {\n            // This error indicates that the table already exists\n            // Due to asynchronous nature of the code, it is possible that\n            // the table is created between the time we check if it exists\n            // and the time we try to create it. It can be safely ignored.\n            if ('code' in e && e.code === '23505') {\n                return\n            }\n            throw e\n        }\n    }\n\n    async getTime(): Promise<number> {\n        try {\n            const res = await this.queryRunner.manager.query(`SELECT UNIX_TIMESTAMP(NOW()) AS epoch`)\n            return Number.parseFloat(res[0].epoch)\n        } catch (error) {\n            console.error('Error getting time in MySQLRecordManager:')\n            throw error\n        }\n    }\n\n    async update(keys: string[], updateOptions?: UpdateOptions): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const updatedAt = await this.getTime()\n        const { timeAtLeast, groupIds: _groupIds } = updateOptions ?? {}\n\n        if (timeAtLeast && updatedAt < timeAtLeast) {\n            throw new Error(`Time sync issue with database ${updatedAt} < ${timeAtLeast}`)\n        }\n\n        const groupIds = _groupIds ?? keys.map(() => null)\n\n        if (groupIds.length !== keys.length) {\n            throw new Error(`Number of keys (${keys.length}) does not match number of group_ids (${groupIds.length})`)\n        }\n\n        const recordsToUpsert = keys.map((key, i) => [\n            key,\n            this.namespace,\n            updatedAt,\n            groupIds[i] ?? null // Ensure groupIds[i] is null if undefined\n        ])\n\n        const query = `\n            INSERT INTO \\`${this.tableName}\\` (\\`key\\`, \\`namespace\\`, \\`updated_at\\`, \\`group_id\\`)\n            VALUES (?, ?, ?, ?)\n            ON DUPLICATE KEY UPDATE updated_at = updated_at;`\n\n        // To handle multiple files upsert\n        for (const record of recordsToUpsert) {\n            // Consider using a transaction for batch operations\n            await this.queryRunner.manager.query(query, record.flat())\n        }\n    }\n\n    async exists(keys: string[]): Promise<boolean[]> {\n        if (keys.length === 0) {\n            return []\n        }\n\n        // Prepare the placeholders and the query\n        const placeholders = keys.map(() => `?`).join(', ')\n        const query = `\n    SELECT \\`key\\`\n    FROM \\`${this.tableName}\\`\n    WHERE \\`namespace\\` = ? AND \\`key\\` IN (${placeholders})`\n\n        // Initialize an array to fill with the existence checks\n        const existsArray = new Array(keys.length).fill(false)\n\n        try {\n            // Execute the query\n            const rows = await this.queryRunner.manager.query(query, [this.namespace, ...keys.flat()])\n            // Create a set of existing keys for faster lookup\n            const existingKeysSet = new Set(rows.map((row: { key: string }) => row.key))\n            // Map the input keys to booleans indicating if they exist\n            keys.forEach((key, index) => {\n                existsArray[index] = existingKeysSet.has(key)\n            })\n            return existsArray\n        } catch (error) {\n            console.error('Error checking existence of keys')\n            throw error // Allow the caller to handle the error\n        }\n    }\n\n    async listKeys(options?: ListKeyOptions): Promise<string[]> {\n        try {\n            const { before, after, limit, groupIds } = options ?? {}\n            let query = `SELECT \\`key\\` FROM \\`${this.tableName}\\` WHERE \\`namespace\\` = ?`\n            const values: (string | number | string[])[] = [this.namespace]\n\n            if (before) {\n                query += ` AND \\`updated_at\\` < ?`\n                values.push(before)\n            }\n\n            if (after) {\n                query += ` AND \\`updated_at\\` > ?`\n                values.push(after)\n            }\n\n            if (limit) {\n                query += ` LIMIT ?`\n                values.push(limit)\n            }\n\n            if (groupIds && Array.isArray(groupIds)) {\n                query += ` AND \\`group_id\\` IN (${groupIds\n                    .filter((gid) => gid !== null)\n                    .map(() => '?')\n                    .join(', ')})`\n                values.push(...groupIds.filter((gid): gid is string => gid !== null))\n            }\n\n            query += ';'\n\n            // Directly using try/catch with async/await for cleaner flow\n            const result = await this.queryRunner.manager.query(query, values)\n            return result.map((row: { key: string }) => row.key)\n        } catch (error) {\n            console.error('MySQLRecordManager listKeys Error: ')\n            throw error // Re-throw the error to be handled by the caller\n        }\n    }\n\n    async deleteKeys(keys: string[]): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const placeholders = keys.map(() => '?').join(', ')\n        const query = `DELETE FROM \\`${this.tableName}\\` WHERE \\`namespace\\` = ? AND \\`key\\` IN (${placeholders});`\n        const values = [this.namespace, ...keys].map((v) => (typeof v !== 'string' ? `${v}` : v))\n\n        // Directly using try/catch with async/await for cleaner flow\n        try {\n            await this.queryRunner.manager.query(query, values)\n        } catch (error) {\n            console.error('Error deleting keys')\n            throw error // Re-throw the error to be handled by the caller\n        }\n    }\n}"
}

## PostgresRecordManager_RecordManager

{
  "className": "PostgresRecordManager_RecordManager",
  "init": "[Function: init]",
  "constructor": "constructor(namespace: string, config: PostgresRecordManagerOptions) {\n        const { postgresConnectionOptions, tableName }",
  "if": "if (keys.length === 0) {\n            return\n        }",
  "catch": "catch (e: any) {\n            // This error indicates that the table already exists\n            // Due to asynchronous nature of the code, it is possible that\n            // the table is created between the time we check if it exists\n            // and the time we try to create it. It can be safely ignored.\n            if ('code' in e && e.code === '23505') {\n                return\n            }",
  "for": "for (let i = 0; i < numOfColumns; i += 1) {\n            placeholders.push(`$${index * numOfColumns + i + 1}",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const user = getCredentialParam('user', credentialData, nodeData)\n        const password = getCredentialParam('password', credentialData, nodeData)\n        const _tableName = nodeData.inputs?.tableName as string\n        const tableName = _tableName ? _tableName : 'upsertion_records'\n        const additionalConfig = nodeData.inputs?.additionalConfig as string\n        const _namespace = nodeData.inputs?.namespace as string\n        const namespace = _namespace ? _namespace : options.chatflowid\n        const cleanup = nodeData.inputs?.cleanup as string\n        const _sourceIdKey = nodeData.inputs?.sourceIdKey as string\n        const sourceIdKey = _sourceIdKey ? _sourceIdKey : 'source'\n\n        let additionalConfiguration = {}\n        if (additionalConfig) {\n            try {\n                additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }\n        }\n\n        const postgresConnectionOptions = {\n            ...additionalConfiguration,\n            type: 'postgres',\n            host: nodeData.inputs?.host as string,\n            port: nodeData.inputs?.port as number,\n            username: user,\n            password: password,\n            database: nodeData.inputs?.database as string\n        }\n\n        const args = {\n            postgresConnectionOptions: postgresConnectionOptions,\n            tableName: tableName\n        }\n\n        const recordManager = new PostgresRecordManager(namespace, args)\n\n        ;(recordManager as any).cleanup = cleanup\n        ;(recordManager as any).sourceIdKey = sourceIdKey\n\n        return recordManager\n    }\n}\n\ntype PostgresRecordManagerOptions = {\n    postgresConnectionOptions: any\n    tableName?: string\n}",
  "outsideClass_appDataSource": "const appDataSource = await this.datasource.initialize()\n\n            this.queryRunner = appDataSource.createQueryRunner()\n\n            await this.queryRunner.manager.query(`\n  CREATE TABLE IF NOT EXISTS \"${this.tableName}\" (\n    uuid UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    key TEXT NOT NULL,\n    namespace TEXT NOT NULL,\n    updated_at Double PRECISION NOT NULL,\n    group_id TEXT,\n    UNIQUE (key, namespace)\n  );\n  CREATE INDEX IF NOT EXISTS updated_at_index ON \"${this.tableName}\" (updated_at);\n  CREATE INDEX IF NOT EXISTS key_index ON \"${this.tableName}\" (key);\n  CREATE INDEX IF NOT EXISTS namespace_index ON \"${this.tableName}\" (namespace);\n  CREATE INDEX IF NOT EXISTS group_id_index ON \"${this.tableName}\" (group_id);`)\n        } catch (e: any) {\n            // This error indicates that the table already exists\n            // Due to asynchronous nature of the code, it is possible that\n            // the table is created between the time we check if it exists\n            // and the time we try to create it. It can be safely ignored.\n            if ('code' in e && e.code === '23505') {\n                return\n            }\n            throw e\n        }\n    }\n\n    async getTime(): Promise<number> {\n        const res = await this.queryRunner.manager.query('SELECT EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)')\n        return Number.parseFloat(res[0].extract)\n    }\n\n    /**\n     * Generates the SQL placeholders for a specific row at the provided index.\n     *\n     * @param index - The index of the row for which placeholders need to be generated.\n     * @param numOfColumns - The number of columns we are inserting data into.\n     * @returns The SQL placeholders for the row values.\n     */\n    private generatePlaceholderForRowAt(index: number, numOfColumns: number): string {\n        const placeholders = []\n        for (let i = 0; i < numOfColumns; i += 1) {\n            placeholders.push(`$${index * numOfColumns + i + 1}`)\n        }\n        return `(${placeholders.join(', ')})`\n    }\n\n    async update(keys: string[], updateOptions?: UpdateOptions): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const updatedAt = await this.getTime()\n        const { timeAtLeast, groupIds: _groupIds } = updateOptions ?? {}\n\n        if (timeAtLeast && updatedAt < timeAtLeast) {\n            throw new Error(`Time sync issue with database ${updatedAt} < ${timeAtLeast}`)\n        }\n\n        const groupIds = _groupIds ?? keys.map(() => null)\n\n        if (groupIds.length !== keys.length) {\n            throw new Error(`Number of keys (${keys.length}) does not match number of group_ids ${groupIds.length})`)\n        }\n\n        const recordsToUpsert = keys.map((key, i) => [key, this.namespace, updatedAt, groupIds[i]])\n\n        const valuesPlaceholders = recordsToUpsert.map((_, j) => this.generatePlaceholderForRowAt(j, recordsToUpsert[0].length)).join(', ')\n\n        const query = `INSERT INTO \"${this.tableName}\" (key, namespace, updated_at, group_id) VALUES ${valuesPlaceholders} ON CONFLICT (key, namespace) DO UPDATE SET updated_at = EXCLUDED.updated_at;`\n        await this.queryRunner.manager.query(query, recordsToUpsert.flat())\n    }\n\n    async exists(keys: string[]): Promise<boolean[]> {\n        if (keys.length === 0) {\n            return []\n        }\n\n        const startIndex = 2\n        const arrayPlaceholders = keys.map((_, i) => `$${i + startIndex}`).join(', ')\n\n        const query = `\n        SELECT k, (key is not null) ex from unnest(ARRAY[${arrayPlaceholders}]) k left join \"${this.tableName}\" on k=key and namespace = $1;\n        `\n        const res = await this.queryRunner.manager.query(query, [this.namespace, ...keys.flat()])\n        return res.map((row: { ex: boolean }) => row.ex)\n    }\n\n    async listKeys(options?: ListKeyOptions): Promise<string[]> {\n        const { before, after, limit, groupIds } = options ?? {}\n        let query = `SELECT key FROM \"${this.tableName}\" WHERE namespace = $1`\n        const values: (string | number | (string | null)[])[] = [this.namespace]\n\n        let index = 2\n        if (before) {\n            values.push(before)\n            query += ` AND updated_at < $${index}`\n            index += 1\n        }\n\n        if (after) {\n            values.push(after)\n            query += ` AND updated_at > $${index}`\n            index += 1\n        }\n\n        if (limit) {\n            values.push(limit)\n            query += ` LIMIT $${index}`\n            index += 1\n        }\n\n        if (groupIds) {\n            values.push(groupIds)\n            query += ` AND group_id = ANY($${index})`\n            index += 1\n        }\n\n        query += ';'\n        const res = await this.queryRunner.manager.query(query, values)\n        return res.map((row: { key: string }) => row.key)\n    }\n\n    async deleteKeys(keys: string[]): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const query = `DELETE FROM \"${this.tableName}\" WHERE namespace = $1 AND key = ANY($2);`\n        await this.queryRunner.manager.query(query, [this.namespace, keys])\n    }\n\n    /**\n     * Terminates the connection pool.\n     * @returns {Promise<void>}\n     */\n    async end(): Promise<void> {\n        if (this.datasource && this.datasource.isInitialized) await this.datasource.destroy()\n    }\n}"
}

## SQLiteRecordManager_RecordManager

{
  "className": "SQLiteRecordManager_RecordManager",
  "init": "[Function: init]",
  "constructor": "constructor(namespace: string, config: SQLiteRecordManagerOptions) {\n        const { sqliteOptions, tableName }",
  "if": "if (keys.length === 0) {\n            return\n        }",
  "catch": "catch (error) {\n            console.error('Error deleting keys')\n            throw error // Re-throw the error to be handled by the caller\n        }",
  "for": "for (const record of recordsToUpsert) {\n            // Consider using a transaction for batch operations\n            await this.queryRunner.manager.query(query, record.flat())\n        }",
  "outsideClass__tableName": "const _tableName = nodeData.inputs?.tableName as string\n        const tableName = _tableName ? _tableName : 'upsertion_records'\n        const additionalConfig = nodeData.inputs?.additionalConfig as string\n        const _namespace = nodeData.inputs?.namespace as string\n        const namespace = _namespace ? _namespace : options.chatflowid\n        const cleanup = nodeData.inputs?.cleanup as string\n        const _sourceIdKey = nodeData.inputs?.sourceIdKey as string\n        const sourceIdKey = _sourceIdKey ? _sourceIdKey : 'source'\n        const databaseFilePath = nodeData.inputs?.databaseFilePath as string\n\n        let additionalConfiguration = {}\n        if (additionalConfig) {\n            try {\n                additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }\n        }\n\n        const sqliteOptions = {\n            ...additionalConfiguration,\n            type: 'sqlite',\n            database: path.resolve(databaseFilePath)\n        }\n\n        const args = {\n            sqliteOptions,\n            tableName: tableName\n        }\n\n        const recordManager = new SQLiteRecordManager(namespace, args)\n\n        ;(recordManager as any).cleanup = cleanup\n        ;(recordManager as any).sourceIdKey = sourceIdKey\n\n        return recordManager\n    }\n}\n\ntype SQLiteRecordManagerOptions = {\n    sqliteOptions: any\n    tableName?: string\n}",
  "outsideClass_appDataSource": "const appDataSource = await this.datasource.initialize()\n\n            this.queryRunner = appDataSource.createQueryRunner()\n\n            await this.queryRunner.manager.query(`\nCREATE TABLE IF NOT EXISTS \"${this.tableName}\" (\n  uuid TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),\n  key TEXT NOT NULL,\n  namespace TEXT NOT NULL,\n  updated_at REAL NOT NULL,\n  group_id TEXT,\n  UNIQUE (key, namespace)\n);\nCREATE INDEX IF NOT EXISTS updated_at_index ON \"${this.tableName}\" (updated_at);\nCREATE INDEX IF NOT EXISTS key_index ON \"${this.tableName}\" (key);\nCREATE INDEX IF NOT EXISTS namespace_index ON \"${this.tableName}\" (namespace);\nCREATE INDEX IF NOT EXISTS group_id_index ON \"${this.tableName}\" (group_id);`)\n        } catch (e: any) {\n            // This error indicates that the table already exists\n            // Due to asynchronous nature of the code, it is possible that\n            // the table is created between the time we check if it exists\n            // and the time we try to create it. It can be safely ignored.\n            if ('code' in e && e.code === '23505') {\n                return\n            }\n            throw e\n        }\n    }\n\n    async getTime(): Promise<number> {\n        try {\n            const res = await this.queryRunner.manager.query(`SELECT strftime('%s', 'now') AS epoch`)\n            return Number.parseFloat(res[0].epoch)\n        } catch (error) {\n            console.error('Error getting time in SQLiteRecordManager:')\n            throw error\n        }\n    }\n\n    async update(keys: string[], updateOptions?: UpdateOptions): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const updatedAt = await this.getTime()\n        const { timeAtLeast, groupIds: _groupIds } = updateOptions ?? {}\n\n        if (timeAtLeast && updatedAt < timeAtLeast) {\n            throw new Error(`Time sync issue with database ${updatedAt} < ${timeAtLeast}`)\n        }\n\n        const groupIds = _groupIds ?? keys.map(() => null)\n\n        if (groupIds.length !== keys.length) {\n            throw new Error(`Number of keys (${keys.length}) does not match number of group_ids (${groupIds.length})`)\n        }\n\n        const recordsToUpsert = keys.map((key, i) => [\n            key,\n            this.namespace,\n            updatedAt,\n            groupIds[i] ?? null // Ensure groupIds[i] is null if undefined\n        ])\n\n        const query = `\n        INSERT INTO \"${this.tableName}\" (key, namespace, updated_at, group_id)\n        VALUES (?, ?, ?, ?)\n        ON CONFLICT (key, namespace) DO UPDATE SET updated_at = excluded.updated_at`\n\n        // To handle multiple files upsert\n        for (const record of recordsToUpsert) {\n            // Consider using a transaction for batch operations\n            await this.queryRunner.manager.query(query, record.flat())\n        }\n    }\n\n    async exists(keys: string[]): Promise<boolean[]> {\n        if (keys.length === 0) {\n            return []\n        }\n\n        // Prepare the placeholders and the query\n        const placeholders = keys.map(() => `?`).join(', ')\n        const sql = `\n    SELECT key\n    FROM \"${this.tableName}\"\n    WHERE namespace = ? AND key IN (${placeholders})`\n\n        // Initialize an array to fill with the existence checks\n        const existsArray = new Array(keys.length).fill(false)\n\n        try {\n            // Execute the query\n            const rows = await this.queryRunner.manager.query(sql, [this.namespace, ...keys.flat()])\n            // Create a set of existing keys for faster lookup\n            const existingKeysSet = new Set(rows.map((row: { key: string }) => row.key))\n            // Map the input keys to booleans indicating if they exist\n            keys.forEach((key, index) => {\n                existsArray[index] = existingKeysSet.has(key)\n            })\n            return existsArray\n        } catch (error) {\n            console.error('Error checking existence of keys')\n            throw error // Allow the caller to handle the error\n        }\n    }\n\n    async listKeys(options?: ListKeyOptions): Promise<string[]> {\n        const { before, after, limit, groupIds } = options ?? {}\n        let query = `SELECT key FROM \"${this.tableName}\" WHERE namespace = ?`\n        const values: (string | number | string[])[] = [this.namespace]\n\n        if (before) {\n            query += ` AND updated_at < ?`\n            values.push(before)\n        }\n\n        if (after) {\n            query += ` AND updated_at > ?`\n            values.push(after)\n        }\n\n        if (limit) {\n            query += ` LIMIT ?`\n            values.push(limit)\n        }\n\n        if (groupIds && Array.isArray(groupIds)) {\n            query += ` AND group_id IN (${groupIds\n                .filter((gid) => gid !== null)\n                .map(() => '?')\n                .join(', ')})`\n            values.push(...groupIds.filter((gid): gid is string => gid !== null))\n        }\n\n        query += ';'\n\n        // Directly using try/catch with async/await for cleaner flow\n        try {\n            const result = await this.queryRunner.manager.query(query, values)\n            return result.map((row: { key: string }) => row.key)\n        } catch (error) {\n            console.error('Error listing keys.')\n            throw error // Re-throw the error to be handled by the caller\n        }\n    }\n\n    async deleteKeys(keys: string[]): Promise<void> {\n        if (keys.length === 0) {\n            return\n        }\n\n        const placeholders = keys.map(() => '?').join(', ')\n        const query = `DELETE FROM \"${this.tableName}\" WHERE namespace = ? AND key IN (${placeholders});`\n        const values = [this.namespace, ...keys].map((v) => (typeof v !== 'string' ? `${v}` : v))\n\n        // Directly using try/catch with async/await for cleaner flow\n        try {\n            await this.queryRunner.manager.query(query, values)\n        } catch (error) {\n            console.error('Error deleting keys')\n            throw error // Re-throw the error to be handled by the caller\n        }\n    }\n}"
}

## CompactRefine_LlamaIndex

{
  "className": "CompactRefine_LlamaIndex",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Compact and Refine'\n        this.name = 'compactrefineLlamaIndex'\n        this.version = 1.0\n        this.type = 'CompactRefine'\n        this.icon = 'compactrefine.svg'\n        this.category = 'Response Synthesizer'\n        this.description =\n            'CompactRefine is a slight variation of Refine that first compacts the text chunks into the smallest possible number of chunks.'\n        this.baseClasses = [this.type, 'ResponseSynthesizer']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Refine Prompt',\n                name: 'refinePrompt',\n                type: 'string',\n                rows: 4,\n                default: `The original query is as follows: {query}",
  "outsideClass_refinePrompt": "const refinePrompt = nodeData.inputs?.refinePrompt as string\n        const textQAPrompt = nodeData.inputs?.textQAPrompt as string\n\n        const refinePromptTemplate = ({ context = '', existingAnswer = '', query = '' }) =>\n            refinePrompt.replace('{existingAnswer}', existingAnswer).replace('{context}', context).replace('{query}', query)\n        const textQAPromptTemplate = ({ context = '', query = '' }) => textQAPrompt.replace('{context}', context).replace('{query}', query)\n\n        return new ResponseSynthesizerClass({ textQAPromptTemplate, refinePromptTemplate, type: 'CompactAndRefine' })\n    }\n}"
}

## Refine_LlamaIndex

{
  "className": "Refine_LlamaIndex",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Refine'\n        this.name = 'refineLlamaIndex'\n        this.version = 1.0\n        this.type = 'Refine'\n        this.icon = 'refine.svg'\n        this.category = 'Response Synthesizer'\n        this.description =\n            'Create and refine an answer by sequentially going through each retrieved text chunk. This makes a separate LLM call per Node. Good for more detailed answers.'\n        this.baseClasses = [this.type, 'ResponseSynthesizer']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Refine Prompt',\n                name: 'refinePrompt',\n                type: 'string',\n                rows: 4,\n                default: `The original query is as follows: {query}",
  "outsideClass_refinePrompt": "const refinePrompt = nodeData.inputs?.refinePrompt as string\n        const textQAPrompt = nodeData.inputs?.textQAPrompt as string\n\n        const refinePromptTemplate = ({ context = '', existingAnswer = '', query = '' }) =>\n            refinePrompt.replace('{existingAnswer}', existingAnswer).replace('{context}', context).replace('{query}', query)\n        const textQAPromptTemplate = ({ context = '', query = '' }) => textQAPrompt.replace('{context}', context).replace('{query}', query)\n\n        return new ResponseSynthesizerClass({ textQAPromptTemplate, refinePromptTemplate, type: 'Refine' })\n    }\n}"
}

## SimpleResponseBuilder_LlamaIndex

{
  "className": "SimpleResponseBuilder_LlamaIndex",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Simple Response Builder'\n        this.name = 'simpleResponseBuilderLlamaIndex'\n        this.version = 1.0\n        this.type = 'SimpleResponseBuilder'\n        this.icon = 'simplerb.svg'\n        this.category = 'Response Synthesizer'\n        this.description = `Apply a query to a collection of text chunks, gathering the responses in an array, and return a combined string of all responses. Useful for individual queries on each text chunk.`\n        this.baseClasses = [this.type, 'ResponseSynthesizer']\n        this.tags = ['LlamaIndex']\n        this.inputs = []\n    }"
}

## TreeSummarize_LlamaIndex

{
  "className": "TreeSummarize_LlamaIndex",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'TreeSummarize'\n        this.name = 'treeSummarizeLlamaIndex'\n        this.version = 1.0\n        this.type = 'TreeSummarize'\n        this.icon = 'treesummarize.svg'\n        this.category = 'Response Synthesizer'\n        this.description =\n            'Given a set of text chunks and the query, recursively construct a tree and return the root node as the response. Good for summarization purposes.'\n        this.baseClasses = [this.type, 'ResponseSynthesizer']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Prompt',\n                name: 'prompt',\n                type: 'string',\n                rows: 4,\n                default: `Context information from multiple sources is below.\n---------------------\n{context}",
  "outsideClass_prompt": "const prompt = nodeData.inputs?.prompt as string\n\n        const textQAPromptTemplate = ({ context = '', query = '' }) => prompt.replace('{context}', context).replace('{query}', query)\n\n        return new ResponseSynthesizerClass({ textQAPromptTemplate, type: 'TreeSummarize' })\n    }\n}"
}

## AWSBedrockKBRetriever_Retrievers

{
  "className": "AWSBedrockKBRetriever_Retrievers",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'AWS Bedrock Knowledge Base Retriever'\n        this.name = 'awsBedrockKBRetriever'\n        this.version = 1.0\n        this.type = 'AWSBedrockKBRetriever'\n        this.icon = 'AWSBedrockKBRetriever.svg'\n        this.category = 'Retrievers'\n        this.badge = 'NEW'\n        this.description = 'Connect to AWS Bedrock Knowledge Base API and retrieve relevant chunks'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.credential = {\n            label: 'AWS Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['awsApi'],\n            optional: true\n        }",
  "outsideClass_knoledgeBaseID": "const knoledgeBaseID = nodeData.inputs?.knoledgeBaseID as string\n        const region = nodeData.inputs?.region as string\n        const topK = nodeData.inputs?.topK as number\n        const overrideSearchType = (nodeData.inputs?.searchType != '' ? nodeData.inputs?.searchType : undefined) as 'HYBRID' | 'SEMANTIC'\n        const filter = (nodeData.inputs?.filter != '' ? JSON.parse(nodeData.inputs?.filter) : undefined) as RetrievalFilter\n        let credentialApiKey = ''\n        let credentialApiSecret = ''\n        let credentialApiSession = ''\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        if (credentialData && Object.keys(credentialData).length !== 0) {\n            credentialApiKey = getCredentialParam('awsKey', credentialData, nodeData)\n            credentialApiSecret = getCredentialParam('awsSecret', credentialData, nodeData)\n            credentialApiSession = getCredentialParam('awsSession', credentialData, nodeData)\n        }\n\n        const retriever = new AmazonKnowledgeBaseRetriever({\n            topK: topK,\n            knowledgeBaseId: knoledgeBaseID,\n            region: region,\n            filter,\n            overrideSearchType,\n            clientOptions: {\n                credentials: {\n                    accessKeyId: credentialApiKey,\n                    secretAccessKey: credentialApiSecret,\n                    sessionToken: credentialApiSession\n                }\n            }\n        })\n\n        return retriever\n    }\n}"
}

## CohereRerankRetriever_Retrievers

{
  "className": "CohereRerankRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Cohere Rerank Retriever'\n        this.name = 'cohereRerankRetriever'\n        this.version = 1.0\n        this.type = 'Cohere Rerank Retriever'\n        this.icon = 'Cohere.svg'\n        this.category = 'Retrievers'\n        this.description = 'Cohere Rerank indexes the documents from most to least semantically relevant to the query.'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['cohereApi']\n        }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_baseRetriever": "const baseRetriever = nodeData.inputs?.baseRetriever as BaseRetriever\n        const model = nodeData.inputs?.model as string\n        const query = nodeData.inputs?.query as string\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const cohereApiKey = getCredentialParam('cohereApiKey', credentialData, nodeData)\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : (baseRetriever as VectorStoreRetriever).k ?? 4\n        const maxChunksPerDoc = nodeData.inputs?.maxChunksPerDoc as string\n        const max_chunks_per_doc = maxChunksPerDoc ? parseFloat(maxChunksPerDoc) : 10\n        const output = nodeData.outputs?.output as string\n\n        const cohereCompressor = new CohereRerank(cohereApiKey, model, k, max_chunks_per_doc)\n\n        const retriever = new ContextualCompressionRetriever({\n            baseCompressor: cohereCompressor,\n            baseRetriever: baseRetriever\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## CustomRetriever_Retrievers

{
  "className": "CustomRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor(input: RetrieverInput<V>) {\n        super(input)\n        this.topK = input.topK ?? this.topK\n        this.resultFormat = input.resultFormat ?? this.resultFormat\n    }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "for": "for (const result of results) {\n            let res = this.resultFormat.replace(/{{context}",
  "outsideClass_defaultReturnFormat": "const defaultReturnFormat = '{{context}}\\nSource: {{metadata.source}}'",
  "outsideClass_vectorStore": "const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n        const query = nodeData.inputs?.query as string\n        const topK = nodeData.inputs?.topK as string\n        const resultFormat = nodeData.inputs?.resultFormat as string\n\n        const output = nodeData.outputs?.output as string\n\n        const retriever = CustomRetriever.fromVectorStore(vectorStore, {\n            resultFormat,\n            topK: topK ? parseInt(topK, 10) : (vectorStore as any)?.k ?? 4\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}\n\ntype RetrieverInput<V extends VectorStore> = Omit<VectorStoreRetrieverInput<V>, 'k'> & {\n    topK?: number\n    resultFormat?: string\n}",
  "outsideClass_results": "const results = await this.vectorStore.similaritySearchWithScore(query, this.topK, this.filter)\n\n        const finalDocs: Document[] = []\n        for (const result of results) {\n            let res = this.resultFormat.replace(/{{context}}/g, result[0].pageContent)\n            res = replaceMetadata(res, result[0].metadata)\n            finalDocs.push(\n                new Document({\n                    pageContent: res,\n                    metadata: result[0].metadata\n                })\n            )\n        }\n        return finalDocs\n    }\n\n    static fromVectorStore<V extends VectorStore>(vectorStore: V, options: Omit<RetrieverInput<V>, 'vectorStore'>) {\n        return new this<V>({ ...options, vectorStore })\n    }\n}\n\nfunction replaceMetadata(template: string, metadata: Record<string, any>): string {\n    const metadataRegex = /{{metadata\\.([\\w.]+)}}/g\n\n    return template.replace(metadataRegex, (match, path) => {\n        const value = get(metadata, path)\n        return value !== undefined ? String(value) : match\n    })\n}"
}

## EmbeddingsFilterRetriever_Retrievers

{
  "className": "EmbeddingsFilterRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Embeddings Filter Retriever'\n        this.name = 'embeddingsFilterRetriever'\n        this.version = 1.0\n        this.type = 'EmbeddingsFilterRetriever'\n        this.icon = 'compressionRetriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'A document compressor that uses embeddings to drop documents unrelated to the query'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Vector Store Retriever',\n                name: 'baseRetriever',\n                type: 'VectorStoreRetriever'\n            }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_baseRetriever": "const baseRetriever = nodeData.inputs?.baseRetriever as BaseRetriever\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const query = nodeData.inputs?.query as string\n        const similarityThreshold = nodeData.inputs?.similarityThreshold as string\n        const k = nodeData.inputs?.k as string\n        const output = nodeData.outputs?.output as string\n\n        if (k === undefined && similarityThreshold === undefined) {\n            throw new Error(`Must specify one of \"k\" or \"similarity_threshold\".`)\n        }\n\n        const similarityThresholdNumber = similarityThreshold ? parseFloat(similarityThreshold) : 0.8\n        const kNumber = k ? parseFloat(k) : undefined\n\n        const baseCompressor = new EmbeddingsFilter({\n            embeddings: embeddings,\n            similarityThreshold: similarityThresholdNumber,\n            k: kNumber\n        })\n\n        const retriever = new ContextualCompressionRetriever({\n            baseCompressor,\n            baseRetriever: baseRetriever\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## HydeRetriever_Retrievers

{
  "className": "HydeRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'HyDE Retriever'\n        this.name = 'HydeRetriever'\n        this.version = 3.0\n        this.type = 'HydeRetriever'\n        this.icon = 'hyderetriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'Use HyDE retriever to retrieve from a vector store'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_llm": "const llm = nodeData.inputs?.model as BaseLanguageModel\n        const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n        const promptKey = nodeData.inputs?.promptKey as PromptKey\n        const customPrompt = nodeData.inputs?.customPrompt as string\n        const query = nodeData.inputs?.query as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n        const output = nodeData.outputs?.output as string\n\n        const obj: HydeRetrieverOptions<any> = {\n            llm,\n            vectorStore,\n            k\n        }\n\n        if (customPrompt) obj.promptTemplate = PromptTemplate.fromTemplate(customPrompt)\n        else if (promptKey) obj.promptTemplate = promptKey\n\n        const retriever = new HydeRetriever(obj)\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## LLMFilterCompressionRetriever_Retrievers

{
  "className": "LLMFilterCompressionRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'LLM Filter Retriever'\n        this.name = 'llmFilterRetriever'\n        this.version = 1.0\n        this.type = 'LLMFilterRetriever'\n        this.icon = 'llmFilterRetriever.svg'\n        this.category = 'Retrievers'\n        this.description =\n            'Iterate over the initially returned documents and extract, from each, only the content that is relevant to the query'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Vector Store Retriever',\n                name: 'baseRetriever',\n                type: 'VectorStoreRetriever'\n            }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_baseRetriever": "const baseRetriever = nodeData.inputs?.baseRetriever as BaseRetriever\n        const model = nodeData.inputs?.model as BaseLanguageModel\n        const query = nodeData.inputs?.query as string\n        const output = nodeData.outputs?.output as string\n\n        if (!model) throw new Error('There must be a LLM model connected to LLM Filter Retriever')\n\n        const retriever = new ContextualCompressionRetriever({\n            baseCompressor: LLMChainExtractor.fromLLM(model),\n            baseRetriever: baseRetriever\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## MultiQueryRetriever_Retrievers

{
  "className": "MultiQueryRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Multi Query Retriever'\n        this.name = 'multiQueryRetriever'\n        this.version = 1.0\n        this.type = 'MultiQueryRetriever'\n        this.icon = 'multiQueryRetriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'Generate multiple queries from different perspectives for a given user input query'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Vector Store',\n                name: 'vectorStore',\n                type: 'VectorStore'\n            }",
  "outsideClass_defaultPrompt": "const defaultPrompt = `You are an AI language model assistant. Your task is\nto generate 3 different versions of the given user\nquestion to retrieve relevant documents from a vector database.\nBy generating multiple perspectives on the user question,\nyour goal is to help the user overcome some of the limitations\nof distance-based similarity search.\n\nProvide these alternative questions separated by newlines between XML tags. For example:\n\n<questions>\nQuestion 1\nQuestion 2\nQuestion 3\n</questions>\n\nOriginal question: {question}`",
  "outsideClass_model": "const model = nodeData.inputs?.model\n        const vectorStore = nodeData.inputs?.vectorStore\n\n        let prompt = nodeData.inputs?.modelPrompt || (defaultPrompt as string)\n        prompt = prompt.replaceAll('{question}', input)\n\n        const retriever = MultiQueryRetriever.fromLLM({\n            llm: model,\n            retriever: vectorStore.asRetriever(),\n            verbose: process.env.DEBUG === 'true',\n            // @ts-ignore\n            prompt: PromptTemplate.fromTemplate(prompt)\n        })\n        return retriever\n    }\n}"
}

## PromptRetriever_Retrievers

{
  "className": "PromptRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Prompt Retriever'\n        this.name = 'promptRetriever'\n        this.version = 1.0\n        this.type = 'PromptRetriever'\n        this.icon = 'promptretriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'Store prompt template with name & description to be later queried by MultiPromptChain'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Prompt Name',\n                name: 'name',\n                type: 'string',\n                placeholder: 'physics-qa'\n            }",
  "outsideClass_name": "const name = nodeData.inputs?.name as string\n        const description = nodeData.inputs?.description as string\n        const systemMessage = nodeData.inputs?.systemMessage as string\n\n        const obj = {\n            name,\n            description,\n            systemMessage\n        } as PromptRetrieverInput\n\n        const retriever = new PromptRetriever(obj)\n        return retriever\n    }\n}"
}

## RRFRetriever_Retrievers

{
  "className": "RRFRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Reciprocal Rank Fusion Retriever'\n        this.name = 'RRFRetriever'\n        this.version = 1.0\n        this.type = 'RRFRetriever'\n        this.icon = 'rrfRetriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'Reciprocal Rank Fusion to re-rank search results by multiple query generation.'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Vector Store Retriever',\n                name: 'baseRetriever',\n                type: 'VectorStoreRetriever'\n            }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_llm": "const llm = nodeData.inputs?.model as BaseLanguageModel\n        const baseRetriever = nodeData.inputs?.baseRetriever as BaseRetriever\n        const query = nodeData.inputs?.query as string\n        const queryCount = nodeData.inputs?.queryCount as string\n        const q = queryCount ? parseFloat(queryCount) : 4\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : (baseRetriever as VectorStoreRetriever).k ?? 4\n        const constantC = nodeData.inputs?.c as string\n        const c = topK ? parseFloat(constantC) : 60\n        const output = nodeData.outputs?.output as string\n\n        const ragFusion = new ReciprocalRankFusion(llm, baseRetriever as VectorStoreRetriever, q, k, c)\n        const retriever = new ContextualCompressionRetriever({\n            baseCompressor: ragFusion,\n            baseRetriever: baseRetriever\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## SimilarityThresholdRetriever_Retrievers

{
  "className": "SimilarityThresholdRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Similarity Score Threshold Retriever'\n        this.name = 'similarityThresholdRetriever'\n        this.version = 2.0\n        this.type = 'SimilarityThresholdRetriever'\n        this.icon = 'similaritythreshold.svg'\n        this.category = 'Retrievers'\n        this.description = 'Return results based on the minimum similarity percentage'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Vector Store',\n                name: 'vectorStore',\n                type: 'VectorStore'\n            }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_vectorStore": "const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n        const minSimilarityScore = nodeData.inputs?.minSimilarityScore as number\n        const query = nodeData.inputs?.query as string\n        const maxK = nodeData.inputs?.maxK as string\n        const kIncrement = nodeData.inputs?.kIncrement as string\n\n        const output = nodeData.outputs?.output as string\n\n        const retriever = ScoreThresholdRetriever.fromVectorStore(vectorStore, {\n            minSimilarityScore: minSimilarityScore ? minSimilarityScore / 100 : 0.9,\n            maxK: maxK ? parseInt(maxK, 10) : 100,\n            kIncrement: kIncrement ? parseInt(kIncrement, 10) : 2\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## VectorStoreRetriever_Retrievers

{
  "className": "VectorStoreRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Vector Store Retriever'\n        this.name = 'vectorStoreRetriever'\n        this.version = 1.0\n        this.type = 'VectorStoreRetriever'\n        this.icon = 'vectorretriever.svg'\n        this.category = 'Retrievers'\n        this.description = 'Store vector store as retriever to be later queried by MultiRetrievalQAChain'\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Vector Store',\n                name: 'vectorStore',\n                type: 'VectorStore'\n            }",
  "outsideClass_name": "const name = nodeData.inputs?.name as string\n        const description = nodeData.inputs?.description as string\n        const vectorStore = nodeData.inputs?.vectorStore as VectorStore\n\n        const obj = {\n            name,\n            description,\n            vectorStore\n        } as VectorStoreRetrieverInput\n\n        const retriever = new VectorStoreRetriever(obj)\n        return retriever\n    }\n}"
}

## VoyageAIRerankRetriever_Retrievers

{
  "className": "VoyageAIRerankRetriever_Retrievers",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Voyage AI Rerank Retriever'\n        this.name = 'voyageAIRerankRetriever'\n        this.version = 1.0\n        this.type = 'VoyageAIRerankRetriever'\n        this.icon = 'voyageai.png'\n        this.category = 'Retrievers'\n        this.description = 'Voyage AI Rerank indexes the documents from most to least semantically relevant to the query.'\n        this.baseClasses = [this.type, 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['voyageAIApi']\n        }",
  "if": "if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}",
  "outsideClass_baseRetriever": "const baseRetriever = nodeData.inputs?.baseRetriever as BaseRetriever\n        const model = nodeData.inputs?.model as string\n        const query = nodeData.inputs?.query as string\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const voyageAiApiKey = getCredentialParam('apiKey', credentialData, nodeData)\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : (baseRetriever as VectorStoreRetriever).k ?? 4\n        const output = nodeData.outputs?.output as string\n\n        const voyageAICompressor = new VoyageAIRerank(voyageAiApiKey, model, k)\n\n        const retriever = new ContextualCompressionRetriever({\n            baseCompressor: voyageAICompressor,\n            baseRetriever: baseRetriever\n        })\n\n        if (output === 'retriever') return retriever\n        else if (output === 'document') return await retriever.getRelevantDocuments(query ? query : input)\n        else if (output === 'text') {\n            let finaltext = ''\n\n            const docs = await retriever.getRelevantDocuments(query ? query : input)\n\n            for (const doc of docs) finaltext += `${doc.pageContent}\\n`\n\n            return handleEscapeCharacters(finaltext, false)\n        }\n\n        return retriever\n    }\n}"
}

## Agent_SeqAgents

{
  "className": "Agent_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor(\n        tools: StructuredTool[],\n        nodeData: INodeData,\n        inputQuery: string,\n        options: ICommonObject,\n        name: string = 'tools',\n        tags: string[] = [],\n        metadata: ICommonObject = {}\n    ) {\n        super({ name, metadata, tags, func: (input, config) => this.run(input, config) }",
  "if": "if (tool === undefined) {\n                    throw new Error(`Tool ${call.name}",
  "catch": "catch (e) {\n                        console.error('Error parsing source documents from tool')\n                    }",
  "agentNode": "agentNode(\n    {\n        state,\n        llm,\n        interrupt,\n        agent,\n        name,\n        abortControllerSignal,\n        nodeData,\n        input,\n        options\n    }: {\n        state: ISeqAgentsState\n        llm: BaseChatModel\n        interrupt: boolean\n        agent: AgentExecutor | RunnableSequence\n        name: string\n        abortControllerSignal: AbortController\n        nodeData: INodeData\n        input: string\n        options: ICommonObject\n    },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }",
  "for": "for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                }",
  "outsideClass_defaultApprovalPrompt": "const defaultApprovalPrompt = `You are about to execute tool: {tools}. Ask if user want to proceed`\nconst examplePrompt = 'You are a research assistant who can search for up-to-date info using search engine.'\nconst customOutputFuncDesc = `This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values`\nconst howToUseCode = `\n1. Return the key value JSON object. For example: if you have the following State:\n    \\`\\`\\`json\n    {\n        \"user\": null\n    }\n    \\`\\`\\`\n\n    You can update the \"user\" value by returning the following:\n    \\`\\`\\`js\n    return {\n        \"user\": \"john doe\"\n    }\n    \\`\\`\\`\n\n2. If you want to use the agent's output as the value to update state, it is available as \\`$flow.output\\` with the following structure:\n    \\`\\`\\`json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    \\`\\`\\`\n\n    For example, if the \\`toolOutput\\` is the value you want to update the state with, you can return the following:\n    \\`\\`\\`js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    \\`\\`\\`\n\n3. You can also get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\nconst howToUse = `\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as \\`$flow.output\\` with the following structure:\n    \\`\\`\\`json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    \\`\\`\\`\n\n    For example, if the \\`toolOutput\\` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | \\`$flow.output.usedTools[0].toolOutput\\`  |\n\n3. You can get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\nconst defaultFunc = `const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};`\n\nconst messageHistoryExample = `const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]`\nconst TAB_IDENTIFIER = 'selectedUpdateStateMemoryTab'",
  "outsideClass_agentLabel": "const agentLabel = nodeData.inputs?.agentName as string\n        const sequentialNodes = nodeData.inputs?.sequentialNode as ISeqAgentNode[]\n        const maxIterations = nodeData.inputs?.maxIterations as string\n        const model = nodeData.inputs?.model as BaseChatModel\n        const promptValuesStr = nodeData.inputs?.promptValues\n        const output = nodeData.outputs?.output as string\n        const approvalPrompt = nodeData.inputs?.approvalPrompt as string\n\n        if (!agentLabel) throw new Error('Agent name is required!')\n        const agentName = agentLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        if (!sequentialNodes || !sequentialNodes.length) throw new Error('Agent must have a predecessor!')\n\n        let agentInputVariablesValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                agentInputVariablesValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the Agent's Prompt Input Values: \" + exception)\n            }\n        }\n        agentInputVariablesValues = handleEscapeCharacters(agentInputVariablesValues, true)\n\n        const startLLM = sequentialNodes[0].startLLM\n        const llm = model || startLLM\n        if (nodeData.inputs) nodeData.inputs.model = llm\n\n        const multiModalMessageContent = sequentialNodes[0]?.multiModalMessageContent || (await processImageMessage(llm, nodeData, options))\n        const abortControllerSignal = options.signal as AbortController\n        const agentInputVariables = uniq([...getInputVariables(agentSystemPrompt), ...getInputVariables(agentHumanPrompt)])\n\n        if (!agentInputVariables.every((element) => Object.keys(agentInputVariablesValues).includes(element))) {\n            throw new Error('Agent input variables values are not provided!')\n        }\n\n        const interrupt = nodeData.inputs?.interrupt as boolean\n\n        const toolName = `tool_${nodeData.id}`\n        const toolNode = new ToolNode(tools, nodeData, input, options, toolName, [], { sequentialNodeName: toolName })\n\n        ;(toolNode as any).seekPermissionMessage = async (usedTools: IUsedTool[]) => {\n            const prompt = ChatPromptTemplate.fromMessages([['human', approvalPrompt || defaultApprovalPrompt]])\n            const chain = prompt.pipe(startLLM)\n            const response = (await chain.invoke({\n                input: 'Hello there!',\n                tools: JSON.stringify(usedTools)\n            })) as AIMessageChunk\n            return response.content\n        }\n\n        const workerNode = async (state: ISeqAgentsState, config: RunnableConfig) => {\n            return await agentNode(\n                {\n                    state,\n                    llm,\n                    interrupt,\n                    agent: await createAgent(\n                        nodeData,\n                        options,\n                        agentName,\n                        state,\n                        llm,\n                        interrupt,\n                        [...tools],\n                        agentSystemPrompt,\n                        agentHumanPrompt,\n                        multiModalMessageContent,\n                        agentInputVariablesValues,\n                        maxIterations,\n                        {\n                            sessionId: options.sessionId,\n                            chatId: options.chatId,\n                            input\n                        }\n                    ),\n                    name: agentName,\n                    abortControllerSignal,\n                    nodeData,\n                    input,\n                    options\n                },\n                config\n            )\n        }\n\n        const toolInterrupt = async (\n            graph: StateGraph<any>,\n            nextNodeName?: string,\n            runCondition?: any,\n            conditionalMapping: ICommonObject = {}\n        ) => {\n            const routeMessage = async (state: ISeqAgentsState) => {\n                const messages = state.messages as unknown as BaseMessage[]\n                const lastMessage = messages[messages.length - 1] as AIMessage\n\n                if (!lastMessage?.tool_calls?.length) {\n                    // if next node is condition node, run the condition\n                    if (runCondition) {\n                        const returnNodeName = await runCondition(state)\n                        return returnNodeName\n                    }\n                    return nextNodeName || END\n                }\n                return toolName\n            }\n\n            graph.addNode(toolName, toolNode)\n\n            if (nextNodeName) {\n                // @ts-ignore\n                graph.addConditionalEdges(agentName, routeMessage, {\n                    [toolName]: toolName,\n                    [END]: END,\n                    [nextNodeName]: nextNodeName,\n                    ...conditionalMapping\n                })\n            } else {\n                // @ts-ignore\n                graph.addConditionalEdges(agentName, routeMessage, { [toolName]: toolName, [END]: END, ...conditionalMapping })\n            }\n\n            // @ts-ignore\n            graph.addEdge(toolName, agentName)\n\n            return graph\n        }\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: workerNode,\n            name: agentName,\n            label: agentLabel,\n            type: 'agent',\n            llm,\n            startLLM,\n            output,\n            predecessorAgents: sequentialNodes,\n            multiModalMessageContent,\n            moderations: sequentialNodes[0]?.moderations,\n            agentInterruptToolNode: interrupt ? toolNode : undefined,\n            agentInterruptToolFunc: interrupt ? toolInterrupt : undefined\n        }\n\n        return returnOutput\n    }\n}\n\nasync function createAgent(\n    nodeData: INodeData,\n    options: ICommonObject,\n    agentName: string,\n    state: ISeqAgentsState,\n    llm: BaseChatModel,\n    interrupt: boolean,\n    tools: any[],\n    systemPrompt: string,\n    humanPrompt: string,\n    multiModalMessageContent: MessageContentImageUrl[],\n    agentInputVariablesValues: ICommonObject,\n    maxIterations?: string,\n    flowObj?: { sessionId?: string; chatId?: string; input?: string }\n): Promise<any> {\n    if (tools.length && !interrupt) {\n        const promptArrays = [\n            new MessagesPlaceholder('messages'),\n            new MessagesPlaceholder('agent_scratchpad')\n        ] as BaseMessagePromptTemplateLike[]\n        if (systemPrompt) promptArrays.unshift(['system', systemPrompt])\n        if (humanPrompt) promptArrays.push(['human', humanPrompt])\n\n        let prompt = ChatPromptTemplate.fromMessages(promptArrays)\n        prompt = await checkMessageHistory(nodeData, options, prompt, promptArrays, systemPrompt)\n\n        if (multiModalMessageContent.length) {\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n            prompt.promptMessages.splice(1, 0, msg)\n        }\n\n        if (llm.bindTools === undefined) {\n            throw new Error(`This agent only compatible with function calling models.`)\n        }\n        const modelWithTools = llm.bindTools(tools)\n\n        let agent\n\n        if (!agentInputVariablesValues || !Object.keys(agentInputVariablesValues).length) {\n            agent = RunnableSequence.from([\n                RunnablePassthrough.assign({\n                    //@ts-ignore\n                    agent_scratchpad: (input: { steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(input.steps)\n                }),\n                prompt,\n                modelWithTools,\n                new ToolCallingAgentOutputParser()\n            ]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        } else {\n            agent = RunnableSequence.from([\n                RunnablePassthrough.assign({\n                    //@ts-ignore\n                    agent_scratchpad: (input: { steps: ToolsAgentStep[] }) => formatToOpenAIToolMessages(input.steps)\n                }),\n                RunnablePassthrough.assign(transformObjectPropertyToFunction(agentInputVariablesValues, state)),\n                prompt,\n                modelWithTools,\n                new ToolCallingAgentOutputParser()\n            ]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        }\n\n        const executor = AgentExecutor.fromAgentAndTools({\n            agent,\n            tools,\n            sessionId: flowObj?.sessionId,\n            chatId: flowObj?.chatId,\n            input: flowObj?.input,\n            verbose: process.env.DEBUG === 'true' ? true : false,\n            maxIterations: maxIterations ? parseFloat(maxIterations) : undefined\n        })\n        return executor\n    } else if (tools.length && interrupt) {\n        if (llm.bindTools === undefined) {\n            throw new Error(`Agent Node only compatible with function calling models.`)\n        }\n        // @ts-ignore\n        llm = llm.bindTools(tools)\n\n        const promptArrays = [new MessagesPlaceholder('messages')] as BaseMessagePromptTemplateLike[]\n        if (systemPrompt) promptArrays.unshift(['system', systemPrompt])\n        if (humanPrompt) promptArrays.push(['human', humanPrompt])\n\n        let prompt = ChatPromptTemplate.fromMessages(promptArrays)\n        prompt = await checkMessageHistory(nodeData, options, prompt, promptArrays, systemPrompt)\n\n        if (multiModalMessageContent.length) {\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n            prompt.promptMessages.splice(1, 0, msg)\n        }\n\n        let agent\n\n        if (!agentInputVariablesValues || !Object.keys(agentInputVariablesValues).length) {\n            agent = RunnableSequence.from([prompt, llm]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        } else {\n            agent = RunnableSequence.from([\n                RunnablePassthrough.assign(transformObjectPropertyToFunction(agentInputVariablesValues, state)),\n                prompt,\n                llm\n            ]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        }\n        return agent\n    } else {\n        const promptArrays = [new MessagesPlaceholder('messages')] as BaseMessagePromptTemplateLike[]\n        if (systemPrompt) promptArrays.unshift(['system', systemPrompt])\n        if (humanPrompt) promptArrays.push(['human', humanPrompt])\n\n        let prompt = ChatPromptTemplate.fromMessages(promptArrays)\n        prompt = await checkMessageHistory(nodeData, options, prompt, promptArrays, systemPrompt)\n\n        if (multiModalMessageContent.length) {\n            const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n            prompt.promptMessages.splice(1, 0, msg)\n        }\n\n        let conversationChain\n\n        if (!agentInputVariablesValues || !Object.keys(agentInputVariablesValues).length) {\n            conversationChain = RunnableSequence.from([prompt, llm, new StringOutputParser()]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        } else {\n            conversationChain = RunnableSequence.from([\n                RunnablePassthrough.assign(transformObjectPropertyToFunction(agentInputVariablesValues, state)),\n                prompt,\n                llm,\n                new StringOutputParser()\n            ]).withConfig({\n                metadata: { sequentialNodeName: agentName }\n            })\n        }\n\n        return conversationChain\n    }\n}\n\nasync function agentNode(\n    {\n        state,\n        llm,\n        interrupt,\n        agent,\n        name,\n        abortControllerSignal,\n        nodeData,\n        input,\n        options\n    }: {\n        state: ISeqAgentsState\n        llm: BaseChatModel\n        interrupt: boolean\n        agent: AgentExecutor | RunnableSequence\n        name: string\n        abortControllerSignal: AbortController\n        nodeData: INodeData\n        input: string\n        options: ICommonObject\n    },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }\n\n        // @ts-ignore\n        state.messages = restructureMessages(llm, state)\n\n        let result = await agent.invoke({ ...state, signal: abortControllerSignal.signal }, config)\n\n        if (interrupt) {\n            const messages = state.messages as unknown as BaseMessage[]\n            const lastMessage = messages[messages.length - 1]\n\n            // If the last message is a tool message and is an interrupted message, format output into standard agent output\n            if (lastMessage._getType() === 'tool' && lastMessage.additional_kwargs?.nodeId === nodeData.id) {\n                let formattedAgentResult: { output?: string; usedTools?: IUsedTool[]; sourceDocuments?: IDocument[] } = {}\n                formattedAgentResult.output = result.content\n                if (lastMessage.additional_kwargs?.usedTools) {\n                    formattedAgentResult.usedTools = lastMessage.additional_kwargs.usedTools as IUsedTool[]\n                }\n                if (lastMessage.additional_kwargs?.sourceDocuments) {\n                    formattedAgentResult.sourceDocuments = lastMessage.additional_kwargs.sourceDocuments as IDocument[]\n                }\n                result = formattedAgentResult\n            } else {\n                result.name = name\n                result.additional_kwargs = { ...result.additional_kwargs, nodeId: nodeData.id, interrupt: true }\n                return {\n                    messages: [result]\n                }\n            }\n        }\n\n        const additional_kwargs: ICommonObject = { nodeId: nodeData.id }\n\n        if (result.usedTools) {\n            additional_kwargs.usedTools = result.usedTools\n        }\n        if (result.sourceDocuments) {\n            additional_kwargs.sourceDocuments = result.sourceDocuments\n        }\n        if (result.output) {\n            result.content = result.output\n            delete result.output\n        }\n\n        const outputContent = typeof result === 'string' ? result : result.content || result.output\n\n        if (nodeData.inputs?.updateStateMemoryUI || nodeData.inputs?.updateStateMemoryCode) {\n            let formattedOutput = {\n                ...result,\n                content: outputContent\n            }\n            const returnedOutput = await getReturnOutput(nodeData, input, options, formattedOutput, state)\n            return {\n                ...returnedOutput,\n                messages: convertCustomMessagesToBaseMessages([outputContent], name, additional_kwargs)\n            }\n        } else {\n            return {\n                messages: [\n                    new HumanMessage({\n                        content: outputContent,\n                        name,\n                        additional_kwargs: Object.keys(additional_kwargs).length ? additional_kwargs : undefined\n                    })\n                ]\n            }\n        }\n    } catch (error) {\n        throw new Error(error)\n    }\n}\n\nconst getReturnOutput = async (nodeData: INodeData, input: string, options: ICommonObject, output: any, state: ISeqAgentsState) => {\n    const appDataSource = options.appDataSource as DataSource\n    const databaseEntities = options.databaseEntities as IDatabaseEntity\n    const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n    const updateStateMemoryUI = nodeData.inputs?.updateStateMemoryUI as string\n    const updateStateMemoryCode = nodeData.inputs?.updateStateMemoryCode as string\n    const updateStateMemory = nodeData.inputs?.updateStateMemory as string\n\n    const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'updateStateMemoryUI'\n    const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n    const flow = {\n        chatflowId: options.chatflowid,\n        sessionId: options.sessionId,\n        chatId: options.chatId,\n        input,\n        output,\n        state,\n        vars: prepareSandboxVars(variables)\n    }\n\n    if (updateStateMemory && updateStateMemory !== 'updateStateMemoryUI' && updateStateMemory !== 'updateStateMemoryCode') {\n        try {\n            const parsedSchema = typeof updateStateMemory === 'string' ? JSON.parse(updateStateMemory) : updateStateMemory\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.Key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.Value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.Value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.Value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n\n    if (selectedTab === 'updateStateMemoryUI' && updateStateMemoryUI) {\n        try {\n            const parsedSchema = typeof updateStateMemoryUI === 'string' ? JSON.parse(updateStateMemoryUI) : updateStateMemoryUI\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    } else if (selectedTab === 'updateStateMemoryCode' && updateStateMemoryCode) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${updateStateMemoryCode}}()`, __dirname)\n            if (typeof response !== 'object') throw new Error('Return output must be an object')\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n\n    return {}\n}\n\nconst convertCustomMessagesToBaseMessages = (messages: string[], name: string, additional_kwargs: ICommonObject) => {\n    return messages.map((message) => {\n        return new HumanMessage({\n            content: message,\n            name,\n            additional_kwargs: Object.keys(additional_kwargs).length ? additional_kwargs : undefined\n        })\n    })\n}",
  "outsideClass_message": "const message = Array.isArray(input) ? input[input.length - 1] : input.messages[input.messages.length - 1]\n\n        if (message._getType() !== 'ai') {\n            throw new Error('ToolNode only accepts AIMessages as input.')\n        }\n\n        const outputs = await Promise.all(\n            (message as AIMessage).tool_calls?.map(async (call) => {\n                const tool = this.tools.find((tool) => tool.name === call.name)\n                if (tool === undefined) {\n                    throw new Error(`Tool ${call.name} not found.`)\n                }\n                let output = await tool.invoke(call.args, config)\n                let sourceDocuments: Document[] = []\n                if (output?.includes(SOURCE_DOCUMENTS_PREFIX)) {\n                    const outputArray = output.split(SOURCE_DOCUMENTS_PREFIX)\n                    output = outputArray[0]\n                    const docs = outputArray[1]\n                    try {\n                        sourceDocuments = JSON.parse(docs)\n                    } catch (e) {\n                        console.error('Error parsing source documents from tool')\n                    }\n                }\n                return new ToolMessage({\n                    name: tool.name,\n                    content: typeof output === 'string' ? output : JSON.stringify(output),\n                    tool_call_id: call.id!,\n                    additional_kwargs: {\n                        sourceDocuments,\n                        args: call.args,\n                        usedTools: [\n                            {\n                                tool: tool.name ?? '',\n                                toolInput: call.args,\n                                toolOutput: output\n                            }\n                        ]\n                    }\n                })\n            }) ?? []\n        )\n\n        const additional_kwargs: ICommonObject = { nodeId: this.nodeData.id }\n        outputs.forEach((result) => (result.additional_kwargs = { ...result.additional_kwargs, ...additional_kwargs }))\n        return Array.isArray(input) ? outputs : { messages: outputs }\n    }\n}"
}

## Condition_SeqAgents

{
  "className": "Condition_SeqAgents",
  "init": "[Function: init]",
  "if": "if (messageOutput) {\n                        if (checkCondition(messageOutput.content as string, item.operation, item.value)) {\n                            return item.output\n                        }",
  "constructor": "constructor() {\n        this.label = 'Condition'\n        this.name = 'seqCondition'\n        this.version = 2.0\n        this.type = 'Condition'\n        this.icon = 'condition.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'Conditional function to determine which route to take next'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-7.-conditional-node'\n        this.inputs = [\n            {\n                label: 'Condition Name',\n                name: 'conditionName',\n                type: 'string',\n                optional: true,\n                placeholder: 'If X, then Y'\n            }",
  "catch": "catch (exception) {\n            throw new Error('Invalid Condition: ' + exception)\n        }",
  "outsideClass_howToUseCode": "const howToUseCode = `\n1. Must return a string value at the end of function. For example:\n    \\`\\`\\`js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    \\`\\`\\`\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: \\`$flow.state.messages\\`:\n    \\`\\`\\`json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    \\`\\`\\`\n\n    For example, to get the last message content:\n    \\`\\`\\`js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    \\`\\`\\`\n\n3. You can get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\n\nconst defaultFunc = `const state = $flow.state;\n                \nconst messages = state.messages;\n\nconst lastMessage = messages[messages.length - 1];\n\n/* Check if the last message has content */\nif (lastMessage.content) {\n    return \"Agent\";\n}\n\nreturn \"End\";`\n\nconst TAB_IDENTIFIER = 'selectedConditionFunctionTab'\n\ninterface IConditionGridItem {\n    variable: string\n    operation: string\n    value: string\n    output: string\n}",
  "outsideClass_conditionLabel": "const conditionLabel = nodeData.inputs?.conditionName as string\n        const conditionName = conditionLabel.toLowerCase().replace(/\\s/g, '_').trim()\n        const output = nodeData.outputs?.output as string\n        const sequentialNodes = nodeData.inputs?.sequentialNode as ISeqAgentNode[]\n\n        if (!sequentialNodes || !sequentialNodes.length) throw new Error('Condition must have a predecessor!')\n\n        const startLLM = sequentialNodes[0].startLLM\n\n        const conditionalEdge = async (state: ISeqAgentsState) => await runCondition(nodeData, input, options, state)\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: conditionalEdge,\n            name: conditionName,\n            label: conditionLabel,\n            type: 'condition',\n            output,\n            llm: startLLM,\n            startLLM,\n            multiModalMessageContent: sequentialNodes[0]?.multiModalMessageContent,\n            predecessorAgents: sequentialNodes\n        }\n\n        return returnOutput\n    }\n}\n\nconst runCondition = async (nodeData: INodeData, input: string, options: ICommonObject, state: ISeqAgentsState) => {\n    const appDataSource = options.appDataSource as DataSource\n    const databaseEntities = options.databaseEntities as IDatabaseEntity\n    const conditionUI = nodeData.inputs?.conditionUI as string\n    const conditionFunction = nodeData.inputs?.conditionFunction as string\n    const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n\n    const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'conditionUI'\n    const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n    const flow = {\n        chatflowId: options.chatflowid,\n        sessionId: options.sessionId,\n        chatId: options.chatId,\n        input,\n        state,\n        vars: prepareSandboxVars(variables)\n    }\n\n    if (selectedTab === 'conditionFunction' && conditionFunction) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${conditionFunction}}()`, __dirname)\n            if (typeof response !== 'string') throw new Error('Condition function must return a string')\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    } else if (selectedTab === 'conditionUI' && conditionUI) {\n        try {\n            const conditionItems: IConditionGridItem[] = typeof conditionUI === 'string' ? JSON.parse(conditionUI) : conditionUI\n\n            for (const item of conditionItems) {\n                if (!item.variable) throw new Error('Condition variable is required!')\n\n                if (item.variable.startsWith('$flow')) {\n                    const variableValue = customGet(flow, item.variable.replace('$flow.', ''))\n                    if (checkCondition(variableValue, item.operation, item.value)) {\n                        return item.output\n                    }\n                } else if (item.variable.startsWith('$vars')) {\n                    const variableValue = customGet(flow, item.variable.replace('$', ''))\n                    if (checkCondition(variableValue, item.operation, item.value)) {\n                        return item.output\n                    }\n                } else if (item.variable.startsWith('$')) {\n                    const nodeId = item.variable.replace('$', '')\n\n                    const messageOutputs = ((state.messages as unknown as BaseMessage[]) ?? []).filter(\n                        (message) => message.additional_kwargs && message.additional_kwargs?.nodeId === nodeId\n                    )\n                    const messageOutput = messageOutputs[messageOutputs.length - 1]\n\n                    if (messageOutput) {\n                        if (checkCondition(messageOutput.content as string, item.operation, item.value)) {\n                            return item.output\n                        }\n                    }\n                }\n            }\n            return 'End'\n        } catch (exception) {\n            throw new Error('Invalid Condition: ' + exception)\n        }\n    }\n}"
}

## ConditionAgent_SeqAgents

{
  "className": "ConditionAgent_SeqAgents",
  "init": "[Function: init]",
  "if": "if (messageOutput) {\n                        if (checkCondition(messageOutput.content as string, item.operation, item.value)) {\n                            return item.output\n                        }",
  "constructor": "constructor() {\n        this.label = 'Condition Agent'\n        this.name = 'seqConditionAgent'\n        this.version = 2.0\n        this.type = 'ConditionAgent'\n        this.icon = 'condition.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'Uses an agent to determine which route to take next'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-8.-conditional-agent-node'\n        this.inputs = [\n            {\n                label: 'Name',\n                name: 'conditionAgentName',\n                type: 'string',\n                placeholder: 'Condition Agent'\n            }",
  "catch": "catch (exception) {\n            throw new Error('Invalid Condition: ' + exception)\n        }",
  "for": "for (const toolCall of result.tool_calls) {\n            jsonResult = { ...jsonResult, ...toolCall.args }",
  "outsideClass_examplePrompt": "const examplePrompt = `You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally.`\n\nconst exampleHumanPrompt = `The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.`\n\nconst howToUseCode = `\n1. Must return a string value at the end of function. For example:\n    \\`\\`\\`js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    \\`\\`\\`\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: \\`$flow.state.messages\\`:\n    \\`\\`\\`json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    \\`\\`\\`\n\n    For example, to get the last message content:\n    \\`\\`\\`js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    \\`\\`\\`\n\n3. If you want to use the Condition Agent's output for conditional checks, it is available as \\`$flow.output\\` with the following structure:\n\n    \\`\\`\\`json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    \\`\\`\\`\n\n    For example, we can check if the agent's output contains specific keyword:\n    \\`\\`\\`js\n    const result = $flow.output.content;\n    \n    if (result.includes(\"some-keyword\")) {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    \\`\\`\\`\n\n    If Structured Output is enabled, \\`$flow.output\\` will be in the JSON format as defined in the Structured Output configuration:\n    \\`\\`\\`json\n    {\n        \"foo\": 'var'\n    }\n    \\`\\`\\`\n\n4. You can get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n5. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\n\nconst defaultFunc = `const result = $flow.output.content;\n\nif (result.includes(\"some-keyword\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n`\n\nconst TAB_IDENTIFIER = 'selectedConditionFunctionTab'",
  "outsideClass_conditionLabel": "const conditionLabel = nodeData.inputs?.conditionAgentName as string\n        const conditionName = conditionLabel.toLowerCase().replace(/\\s/g, '_').trim()\n        const output = nodeData.outputs?.output as string\n        const sequentialNodes = nodeData.inputs?.sequentialNode as ISeqAgentNode[]\n        let agentPrompt = nodeData.inputs?.systemMessagePrompt as string\n        let humanPrompt = nodeData.inputs?.humanMessagePrompt as string\n        const promptValuesStr = nodeData.inputs?.promptValues\n        const conditionAgentStructuredOutput = nodeData.inputs?.conditionAgentStructuredOutput\n        const model = nodeData.inputs?.model as BaseChatModel\n\n        if (!sequentialNodes || !sequentialNodes.length) throw new Error('Condition Agent must have a predecessor!')\n\n        const startLLM = sequentialNodes[0].startLLM\n        const llm = model || startLLM\n        if (nodeData.inputs) nodeData.inputs.model = llm\n\n        let conditionAgentInputVariablesValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                conditionAgentInputVariablesValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the Condition Agent's Prompt Input Values: \" + exception)\n            }\n        }\n        conditionAgentInputVariablesValues = handleEscapeCharacters(conditionAgentInputVariablesValues, true)\n\n        const conditionAgentInputVariables = uniq([...getInputVariables(agentPrompt), ...getInputVariables(humanPrompt)])\n\n        if (!conditionAgentInputVariables.every((element) => Object.keys(conditionAgentInputVariablesValues).includes(element))) {\n            throw new Error('Condition Agent input variables values are not provided!')\n        }\n\n        const abortControllerSignal = options.signal as AbortController\n\n        const conditionalEdge = async (state: ISeqAgentsState, config: RunnableConfig) =>\n            await runCondition(\n                conditionName,\n                nodeData,\n                input,\n                options,\n                state,\n                config,\n                llm,\n                agentPrompt,\n                humanPrompt,\n                conditionAgentInputVariablesValues,\n                conditionAgentStructuredOutput,\n                abortControllerSignal\n            )\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: conditionalEdge,\n            name: conditionName,\n            label: conditionLabel,\n            type: 'condition',\n            output,\n            llm,\n            startLLM,\n            multiModalMessageContent: sequentialNodes[0]?.multiModalMessageContent,\n            predecessorAgents: sequentialNodes\n        }\n\n        return returnOutput\n    }\n}\n\nconst runCondition = async (\n    conditionName: string,\n    nodeData: INodeData,\n    input: string,\n    options: ICommonObject,\n    state: ISeqAgentsState,\n    config: RunnableConfig,\n    llm: BaseChatModel,\n    agentPrompt: string,\n    humanPrompt: string,\n    conditionAgentInputVariablesValues: ICommonObject,\n    conditionAgentStructuredOutput: string,\n    abortControllerSignal: AbortController\n) => {\n    const appDataSource = options.appDataSource as DataSource\n    const databaseEntities = options.databaseEntities as IDatabaseEntity\n    const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n    const conditionUI = nodeData.inputs?.conditionUI as string\n    const conditionFunction = nodeData.inputs?.conditionFunction as string\n    const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'conditionUI'\n\n    const promptArrays = [new MessagesPlaceholder('messages')] as BaseMessagePromptTemplateLike[]\n    if (agentPrompt) promptArrays.unshift(['system', agentPrompt])\n    if (humanPrompt) promptArrays.push(['human', humanPrompt])\n    const prompt = ChatPromptTemplate.fromMessages(promptArrays)\n\n    let model\n    if (conditionAgentStructuredOutput && conditionAgentStructuredOutput !== '[]') {\n        try {\n            const structuredOutput = z.object(convertStructuredSchemaToZod(conditionAgentStructuredOutput))\n\n            if (llm instanceof ChatGoogleGenerativeAI) {\n                const tool = new ExtractTool({\n                    schema: structuredOutput\n                })\n                // @ts-ignore\n                const modelWithTool = llm.bind({\n                    tools: [tool],\n                    signal: abortControllerSignal ? abortControllerSignal.signal : undefined\n                })\n                model = modelWithTool\n            } else {\n                // @ts-ignore\n                model = llm.withStructuredOutput(structuredOutput)\n            }\n        } catch (exception) {\n            console.error('Invalid JSON in Condition Agent Structured Output: ' + exception)\n            model = llm\n        }\n    } else {\n        model = llm\n    }\n\n    let chain\n\n    if (!conditionAgentInputVariablesValues || !Object.keys(conditionAgentInputVariablesValues).length) {\n        chain = RunnableSequence.from([prompt, model]).withConfig({\n            metadata: { sequentialNodeName: conditionName }\n        })\n    } else {\n        chain = RunnableSequence.from([\n            RunnablePassthrough.assign(transformObjectPropertyToFunction(conditionAgentInputVariablesValues, state)),\n            prompt,\n            model\n        ]).withConfig({\n            metadata: { sequentialNodeName: conditionName }\n        })\n    }\n\n    // @ts-ignore\n    state.messages = restructureMessages(model, state)\n\n    let result = await chain.invoke({ ...state, signal: abortControllerSignal?.signal }, config)\n    result.additional_kwargs = { ...result.additional_kwargs, nodeId: nodeData.id }\n\n    if (conditionAgentStructuredOutput && conditionAgentStructuredOutput !== '[]' && result.tool_calls && result.tool_calls.length) {\n        let jsonResult = {}\n        for (const toolCall of result.tool_calls) {\n            jsonResult = { ...jsonResult, ...toolCall.args }\n        }\n        result = { ...jsonResult, additional_kwargs: { nodeId: nodeData.id } }\n    }\n\n    const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n    const flow = {\n        chatflowId: options.chatflowid,\n        sessionId: options.sessionId,\n        chatId: options.chatId,\n        input,\n        state,\n        output: result,\n        vars: prepareSandboxVars(variables)\n    }\n\n    if (selectedTab === 'conditionFunction' && conditionFunction) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${conditionFunction}}()`, __dirname)\n            if (typeof response !== 'string') throw new Error('Condition function must return a string')\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    } else if (selectedTab === 'conditionUI' && conditionUI) {\n        try {\n            const conditionItems: IConditionGridItem[] = typeof conditionUI === 'string' ? JSON.parse(conditionUI) : conditionUI\n\n            for (const item of conditionItems) {\n                if (!item.variable) throw new Error('Condition variable is required!')\n\n                if (item.variable.startsWith('$flow')) {\n                    const variableValue = customGet(flow, item.variable.replace('$flow.', ''))\n                    if (checkCondition(variableValue, item.operation, item.value)) {\n                        return item.output\n                    }\n                } else if (item.variable.startsWith('$vars')) {\n                    const variableValue = customGet(flow, item.variable.replace('$', ''))\n                    if (checkCondition(variableValue, item.operation, item.value)) {\n                        return item.output\n                    }\n                } else if (item.variable.startsWith('$')) {\n                    const nodeId = item.variable.replace('$', '')\n\n                    const messageOutputs = ((state.messages as unknown as BaseMessage[]) ?? []).filter(\n                        (message) => message.additional_kwargs && message.additional_kwargs?.nodeId === nodeId\n                    )\n                    const messageOutput = messageOutputs[messageOutputs.length - 1]\n\n                    if (messageOutput) {\n                        if (checkCondition(messageOutput.content as string, item.operation, item.value)) {\n                            return item.output\n                        }\n                    }\n                }\n            }\n            return 'End'\n        } catch (exception) {\n            throw new Error('Invalid Condition: ' + exception)\n        }\n    }\n}"
}

## End_SeqAgents

{
  "className": "End_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'End'\n        this.name = 'seqEnd'\n        this.version = 2.0\n        this.type = 'End'\n        this.icon = 'end.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'End conversation'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-10.-end-node'\n        this.inputs = [\n            {\n                label: 'Agent | Condition | LLM | Tool Node',\n                name: 'sequentialNode',\n                type: 'Agent | Condition | LLMNode | ToolNode'\n            }",
  "outsideClass_sequentialNode": "const sequentialNode = nodeData.inputs?.sequentialNode as ISeqAgentNode\n        if (!sequentialNode) throw new Error('End must have a predecessor!')\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: END,\n            name: END,\n            label: END,\n            type: 'end',\n            output: END,\n            predecessorAgents: [sequentialNode]\n        }\n\n        return returnOutput\n    }\n}"
}

## LLMNode_SeqAgents

{
  "className": "LLMNode_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'LLM Node'\n        this.name = 'seqLLMNode'\n        this.version = 3.0\n        this.type = 'LLMNode'\n        this.icon = 'llmNode.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'Run Chat Model and return the output'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-5.-llm-node'\n        this.inputs = [\n            {\n                label: 'Name',\n                name: 'llmNodeName',\n                type: 'string',\n                placeholder: 'LLM'\n            }",
  "if": "if (selectedTab === 'updateStateMemoryCode' && updateStateMemoryCode) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${updateStateMemoryCode}",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "agentNode": "agentNode(\n    {\n        state,\n        llm,\n        agent,\n        name,\n        abortControllerSignal,\n        nodeData,\n        input,\n        options\n    }: {\n        state: ISeqAgentsState\n        llm: BaseChatModel\n        agent: AgentExecutor | RunnableSequence\n        name: string\n        abortControllerSignal: AbortController\n        nodeData: INodeData\n        input: string\n        options: ICommonObject\n    },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }",
  "for": "for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                }",
  "outsideClass_TAB_IDENTIFIER": "const TAB_IDENTIFIER = 'selectedUpdateStateMemoryTab'\nconst customOutputFuncDesc = `This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values`\nconst howToUseCode = `\n1. Return the key value JSON object. For example: if you have the following State:\n    \\`\\`\\`json\n    {\n        \"user\": null\n    }\n    \\`\\`\\`\n\n    You can update the \"user\" value by returning the following:\n    \\`\\`\\`js\n    return {\n        \"user\": \"john doe\"\n    }\n    \\`\\`\\`\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as \\`$flow.output\\` with the following structure:\n    \\`\\`\\`json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    \\`\\`\\`\n\n    For example, if the output \\`content\\` is the value you want to update the state with, you can return the following:\n    \\`\\`\\`js\n    return {\n        \"user\": $flow.output.content\n    }\n    \\`\\`\\`\n\n3. You can also get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\nconst howToUse = `\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as \\`$flow.output\\` with the following structure:\n    \\`\\`\\`json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    \\`\\`\\`\n\n    For example, if the output \\`content\\` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | \\`$flow.output.content\\`  |\n\n3. You can get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\nconst defaultFunc = `const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};`\n\nconst messageHistoryExample = `const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]`",
  "outsideClass_llmNodeLabel": "const llmNodeLabel = nodeData.inputs?.llmNodeName as string\n        const sequentialNodes = nodeData.inputs?.sequentialNode as ISeqAgentNode[]\n        const model = nodeData.inputs?.model as BaseChatModel\n        const promptValuesStr = nodeData.inputs?.promptValues\n        const output = nodeData.outputs?.output as string\n        const llmStructuredOutput = nodeData.inputs?.llmStructuredOutput\n\n        if (!llmNodeLabel) throw new Error('LLM Node name is required!')\n        const llmNodeName = llmNodeLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        if (!sequentialNodes || !sequentialNodes.length) throw new Error('Agent must have a predecessor!')\n\n        let llmNodeInputVariablesValues: ICommonObject = {}\n        if (promptValuesStr) {\n            try {\n                llmNodeInputVariablesValues = typeof promptValuesStr === 'object' ? promptValuesStr : JSON.parse(promptValuesStr)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the LLM Node's Prompt Input Values: \" + exception)\n            }\n        }\n        llmNodeInputVariablesValues = handleEscapeCharacters(llmNodeInputVariablesValues, true)\n\n        const startLLM = sequentialNodes[0].startLLM\n        const llm = model || startLLM\n        if (nodeData.inputs) nodeData.inputs.model = llm\n\n        const multiModalMessageContent = sequentialNodes[0]?.multiModalMessageContent || (await processImageMessage(llm, nodeData, options))\n        const abortControllerSignal = options.signal as AbortController\n        const llmNodeInputVariables = uniq([...getInputVariables(systemPrompt), ...getInputVariables(humanPrompt)])\n\n        if (!llmNodeInputVariables.every((element) => Object.keys(llmNodeInputVariablesValues).includes(element))) {\n            throw new Error('LLM Node input variables values are not provided!')\n        }\n\n        const workerNode = async (state: ISeqAgentsState, config: RunnableConfig) => {\n            const bindModel = config.configurable?.bindModel?.[nodeData.id]\n            return await agentNode(\n                {\n                    state,\n                    llm,\n                    agent: await createAgent(\n                        nodeData,\n                        options,\n                        llmNodeName,\n                        state,\n                        bindModel || llm,\n                        [...tools],\n                        systemPrompt,\n                        humanPrompt,\n                        multiModalMessageContent,\n                        llmNodeInputVariablesValues,\n                        llmStructuredOutput\n                    ),\n                    name: llmNodeName,\n                    abortControllerSignal,\n                    nodeData,\n                    input,\n                    options\n                },\n                config\n            )\n        }\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: workerNode,\n            name: llmNodeName,\n            label: llmNodeLabel,\n            type: 'llm',\n            llm,\n            startLLM,\n            output,\n            predecessorAgents: sequentialNodes,\n            multiModalMessageContent,\n            moderations: sequentialNodes[0]?.moderations\n        }\n\n        return returnOutput\n    }\n}\n\nasync function createAgent(\n    nodeData: INodeData,\n    options: ICommonObject,\n    llmNodeName: string,\n    state: ISeqAgentsState,\n    llm: BaseChatModel,\n    tools: any[],\n    systemPrompt: string,\n    humanPrompt: string,\n    multiModalMessageContent: MessageContentImageUrl[],\n    llmNodeInputVariablesValues: ICommonObject,\n    llmStructuredOutput: string\n): Promise<AgentExecutor | RunnableSequence> {\n    if (tools.length) {\n        if (llm.bindTools === undefined) {\n            throw new Error(`LLM Node only compatible with function calling models.`)\n        }\n        // @ts-ignore\n        llm = llm.bindTools(tools)\n    }\n\n    if (llmStructuredOutput && llmStructuredOutput !== '[]') {\n        try {\n            const structuredOutput = z.object(convertStructuredSchemaToZod(llmStructuredOutput))\n\n            if (llm instanceof ChatGoogleGenerativeAI) {\n                const tool = new ExtractTool({\n                    schema: structuredOutput\n                })\n                // @ts-ignore\n                const modelWithTool = llm.bind({\n                    tools: [tool]\n                }) as any\n                llm = modelWithTool\n            } else {\n                // @ts-ignore\n                llm = llm.withStructuredOutput(structuredOutput)\n            }\n        } catch (exception) {\n            console.error(exception)\n        }\n    }\n\n    const promptArrays = [new MessagesPlaceholder('messages')] as BaseMessagePromptTemplateLike[]\n    if (systemPrompt) promptArrays.unshift(['system', systemPrompt])\n    if (humanPrompt) promptArrays.push(['human', humanPrompt])\n\n    let prompt = ChatPromptTemplate.fromMessages(promptArrays)\n    prompt = await checkMessageHistory(nodeData, options, prompt, promptArrays, systemPrompt)\n\n    if (multiModalMessageContent.length) {\n        const msg = HumanMessagePromptTemplate.fromTemplate([...multiModalMessageContent])\n        prompt.promptMessages.splice(1, 0, msg)\n    }\n\n    let chain\n\n    if (!llmNodeInputVariablesValues || !Object.keys(llmNodeInputVariablesValues).length) {\n        chain = RunnableSequence.from([prompt, llm]).withConfig({\n            metadata: { sequentialNodeName: llmNodeName }\n        })\n    } else {\n        chain = RunnableSequence.from([\n            RunnablePassthrough.assign(transformObjectPropertyToFunction(llmNodeInputVariablesValues, state)),\n            prompt,\n            llm\n        ]).withConfig({\n            metadata: { sequentialNodeName: llmNodeName }\n        })\n    }\n\n    // @ts-ignore\n    return chain\n}\n\nasync function agentNode(\n    {\n        state,\n        llm,\n        agent,\n        name,\n        abortControllerSignal,\n        nodeData,\n        input,\n        options\n    }: {\n        state: ISeqAgentsState\n        llm: BaseChatModel\n        agent: AgentExecutor | RunnableSequence\n        name: string\n        abortControllerSignal: AbortController\n        nodeData: INodeData\n        input: string\n        options: ICommonObject\n    },\n    config: RunnableConfig\n) {\n    try {\n        if (abortControllerSignal.signal.aborted) {\n            throw new Error('Aborted!')\n        }\n\n        // @ts-ignore\n        state.messages = restructureMessages(llm, state)\n\n        let result: AIMessageChunk | ICommonObject = await agent.invoke({ ...state, signal: abortControllerSignal.signal }, config)\n\n        const llmStructuredOutput = nodeData.inputs?.llmStructuredOutput\n        if (llmStructuredOutput && llmStructuredOutput !== '[]' && result.tool_calls && result.tool_calls.length) {\n            let jsonResult = {}\n            for (const toolCall of result.tool_calls) {\n                jsonResult = { ...jsonResult, ...toolCall.args }\n            }\n            result = { ...jsonResult, additional_kwargs: { nodeId: nodeData.id } }\n        }\n\n        if (nodeData.inputs?.updateStateMemoryUI || nodeData.inputs?.updateStateMemoryCode) {\n            const returnedOutput = await getReturnOutput(nodeData, input, options, result, state)\n\n            if (nodeData.inputs?.llmStructuredOutput && nodeData.inputs.llmStructuredOutput !== '[]') {\n                const messages = [\n                    new AIMessage({\n                        content: typeof result === 'object' ? JSON.stringify(result) : result,\n                        name,\n                        additional_kwargs: { nodeId: nodeData.id }\n                    })\n                ]\n                return {\n                    ...returnedOutput,\n                    messages\n                }\n            } else {\n                result.name = name\n                result.additional_kwargs = { ...result.additional_kwargs, nodeId: nodeData.id }\n                return {\n                    ...returnedOutput,\n                    messages: [result]\n                }\n            }\n        } else {\n            if (nodeData.inputs?.llmStructuredOutput && nodeData.inputs.llmStructuredOutput !== '[]') {\n                const messages = [\n                    new AIMessage({\n                        content: typeof result === 'object' ? JSON.stringify(result) : result,\n                        name,\n                        additional_kwargs: { nodeId: nodeData.id }\n                    })\n                ]\n                return {\n                    messages\n                }\n            } else {\n                result.name = name\n                result.additional_kwargs = { ...result.additional_kwargs, nodeId: nodeData.id }\n                return {\n                    messages: [result]\n                }\n            }\n        }\n    } catch (error) {\n        throw new Error(error)\n    }\n}\n\nconst getReturnOutput = async (nodeData: INodeData, input: string, options: ICommonObject, output: any, state: ISeqAgentsState) => {\n    const appDataSource = options.appDataSource as DataSource\n    const databaseEntities = options.databaseEntities as IDatabaseEntity\n    const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n    const updateStateMemoryUI = nodeData.inputs?.updateStateMemoryUI as string\n    const updateStateMemoryCode = nodeData.inputs?.updateStateMemoryCode as string\n    const updateStateMemory = nodeData.inputs?.updateStateMemory as string\n\n    const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'updateStateMemoryUI'\n    const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n    const flow = {\n        chatflowId: options.chatflowid,\n        sessionId: options.sessionId,\n        chatId: options.chatId,\n        input,\n        output,\n        state,\n        vars: prepareSandboxVars(variables)\n    }\n\n    if (updateStateMemory && updateStateMemory !== 'updateStateMemoryUI' && updateStateMemory !== 'updateStateMemoryCode') {\n        try {\n            const parsedSchema = typeof updateStateMemory === 'string' ? JSON.parse(updateStateMemory) : updateStateMemory\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.Key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.Value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.Value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.Value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n\n    if (selectedTab === 'updateStateMemoryUI' && updateStateMemoryUI) {\n        try {\n            const parsedSchema = typeof updateStateMemoryUI === 'string' ? JSON.parse(updateStateMemoryUI) : updateStateMemoryUI\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    } else if (selectedTab === 'updateStateMemoryCode' && updateStateMemoryCode) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${updateStateMemoryCode}}()`, __dirname)\n            if (typeof response !== 'object') throw new Error('Return output must be an object')\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## Loop_SeqAgents

{
  "className": "Loop_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Loop'\n        this.name = 'seqLoop'\n        this.version = 2.0\n        this.type = 'Loop'\n        this.icon = 'loop.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'Loop back to the specific sequential node'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-9.-loop-node'\n        this.inputs = [\n            {\n                label: 'Agent | Condition | LLM | Tool Node',\n                name: 'sequentialNode',\n                type: 'Agent | Condition | LLMNode | ToolNode',\n                list: true\n            }",
  "outsideClass_sequentialNodes": "const sequentialNodes = nodeData.inputs?.sequentialNode as ISeqAgentNode[]\n        const loopToNameLabel = nodeData.inputs?.loopToName as string\n\n        if (!sequentialNodes || !sequentialNodes.length) throw new Error('Loop must have a predecessor!')\n        if (!loopToNameLabel) throw new Error('Loop to name is required')\n\n        const loopToName = loopToNameLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: loopToName,\n            name: loopToName,\n            label: loopToNameLabel,\n            type: 'agent',\n            predecessorAgents: sequentialNodes,\n            output: loopToName\n        }\n\n        return returnOutput\n    }\n}"
}

## Start_SeqAgents

{
  "className": "Start_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Start'\n        this.name = 'seqStart'\n        this.version = 2.0\n        this.type = 'Start'\n        this.icon = 'start.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'Starting point of the conversation'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-1.-start-node'\n        this.inputs = [\n            {\n                label: 'Chat Model',\n                name: 'model',\n                type: 'BaseChatModel',\n                description: `Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat`\n            }",
  "outsideClass_moderations": "const moderations = (nodeData.inputs?.inputModeration as Moderation[]) ?? []\n        const model = nodeData.inputs?.model as BaseChatModel\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: START,\n            name: START,\n            label: START,\n            type: 'start',\n            output: START,\n            llm: model,\n            startLLM: model,\n            moderations,\n            checkpointMemory: nodeData.inputs?.agentMemory\n        }\n\n        return returnOutput\n    }\n}"
}

## State_SeqAgents

{
  "className": "State_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'State'\n        this.name = 'seqState'\n        this.version = 2.0\n        this.type = 'State'\n        this.icon = 'state.svg'\n        this.category = 'Sequential Agents'\n        this.description = 'A centralized state object, updated by nodes in the graph, passing from one node to another'\n        this.baseClasses = [this.type]\n        this.documentation = 'https://docs.flowiseai.com/using-flowise/agentflows/sequential-agents#id-3.-state-node'\n        this.inputs = [\n            {\n                label: 'Custom State',\n                name: 'stateMemory',\n                type: 'tabs',\n                tabIdentifier: TAB_IDENTIFIER,\n                additionalParams: true,\n                default: 'stateMemoryUI',\n                tabs: [\n                    {\n                        label: 'Custom State (Table)',\n                        name: 'stateMemoryUI',\n                        type: 'datagrid',\n                        description:\n                            'Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.',\n                        hint: {\n                            label: 'How to use',\n                            value: howToUse\n                        }",
  "if": "if (selectedTab === 'stateMemoryCode' && stateMemoryCode) {\n            const variables = await getVars(appDataSource, databaseEntities, nodeData)\n            const flow = {\n                chatflowId: options.chatflowid,\n                sessionId: options.sessionId,\n                chatId: options.chatId,\n                input\n            }",
  "for": "for (const sch of parsedSchema) {\n                    const key = sch.key\n                    if (!key) throw new Error(`Key is required`)\n                    const type = sch.type\n                    const defaultValue = sch.defaultValue\n\n                    if (type === 'Append') {\n                        obj[key] = {\n                            value: (x: any, y: any) => (Array.isArray(y) ? x.concat(y) : x.concat([y])),\n                            default: () => (defaultValue ? JSON.parse(defaultValue) : [])\n                        }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "run": "run(`module.exports = async function() {return ${stateMemoryCode}",
  "outsideClass_defaultFunc": "const defaultFunc = `{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}`\n\nconst howToUse = `\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n`\nconst TAB_IDENTIFIER = 'selectedStateTab'",
  "outsideClass_tabIdentifier": "const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n        const stateMemoryUI = nodeData.inputs?.stateMemoryUI as string\n        const stateMemoryCode = nodeData.inputs?.stateMemoryCode as string\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'stateMemoryUI'\n        const stateMemory = nodeData.inputs?.stateMemory as string\n\n        if (stateMemory && stateMemory !== 'stateMemoryUI' && stateMemory !== 'stateMemoryCode') {\n            try {\n                const parsedSchema = typeof stateMemory === 'string' ? JSON.parse(stateMemory) : stateMemory\n                const obj: ICommonObject = {}\n                for (const sch of parsedSchema) {\n                    const key = sch.Key\n                    if (!key) throw new Error(`Key is required`)\n                    const type = sch.Operation\n                    const defaultValue = sch['Default Value']\n\n                    if (type === 'Append') {\n                        obj[key] = {\n                            value: (x: any, y: any) => (Array.isArray(y) ? x.concat(y) : x.concat([y])),\n                            default: () => (defaultValue ? JSON.parse(defaultValue) : [])\n                        }\n                    } else {\n                        obj[key] = {\n                            value: (x: any, y: any) => y ?? x,\n                            default: () => defaultValue\n                        }\n                    }\n                }\n                const returnOutput: ISeqAgentNode = {\n                    id: nodeData.id,\n                    node: obj,\n                    name: 'state',\n                    label: 'state',\n                    type: 'state',\n                    output: START\n                }\n                return returnOutput\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n\n        if (!stateMemoryUI && !stateMemoryCode) {\n            const returnOutput: ISeqAgentNode = {\n                id: nodeData.id,\n                node: {},\n                name: 'state',\n                label: 'state',\n                type: 'state',\n                output: START\n            }\n            return returnOutput\n        }\n\n        if (selectedTab === 'stateMemoryUI' && stateMemoryUI) {\n            try {\n                const parsedSchema = typeof stateMemoryUI === 'string' ? JSON.parse(stateMemoryUI) : stateMemoryUI\n                const obj: ICommonObject = {}\n                for (const sch of parsedSchema) {\n                    const key = sch.key\n                    if (!key) throw new Error(`Key is required`)\n                    const type = sch.type\n                    const defaultValue = sch.defaultValue\n\n                    if (type === 'Append') {\n                        obj[key] = {\n                            value: (x: any, y: any) => (Array.isArray(y) ? x.concat(y) : x.concat([y])),\n                            default: () => (defaultValue ? JSON.parse(defaultValue) : [])\n                        }\n                    } else {\n                        obj[key] = {\n                            value: (x: any, y: any) => y ?? x,\n                            default: () => defaultValue\n                        }\n                    }\n                }\n                const returnOutput: ISeqAgentNode = {\n                    id: nodeData.id,\n                    node: obj,\n                    name: 'state',\n                    label: 'state',\n                    type: 'state',\n                    output: START\n                }\n                return returnOutput\n            } catch (e) {\n                throw new Error(e)\n            }\n        } else if (selectedTab === 'stateMemoryCode' && stateMemoryCode) {\n            const variables = await getVars(appDataSource, databaseEntities, nodeData)\n            const flow = {\n                chatflowId: options.chatflowid,\n                sessionId: options.sessionId,\n                chatId: options.chatId,\n                input\n            }\n\n            let sandbox: any = {}\n            sandbox['$vars'] = prepareSandboxVars(variables)\n            sandbox['$flow'] = flow\n\n            const builtinDeps = process.env.TOOL_FUNCTION_BUILTIN_DEP\n                ? defaultAllowBuiltInDep.concat(process.env.TOOL_FUNCTION_BUILTIN_DEP.split(','))\n                : defaultAllowBuiltInDep\n            const externalDeps = process.env.TOOL_FUNCTION_EXTERNAL_DEP ? process.env.TOOL_FUNCTION_EXTERNAL_DEP.split(',') : []\n            const deps = availableDependencies.concat(externalDeps)\n\n            const nodeVMOptions = {\n                console: 'inherit',\n                sandbox,\n                require: {\n                    external: { modules: deps },\n                    builtin: builtinDeps\n                }\n            } as any\n\n            const vm = new NodeVM(nodeVMOptions)\n            try {\n                const response = await vm.run(`module.exports = async function() {return ${stateMemoryCode}}()`, __dirname)\n                if (typeof response !== 'object') throw new Error('State must be an object')\n                const returnOutput: ISeqAgentNode = {\n                    id: nodeData.id,\n                    node: response,\n                    name: 'state',\n                    label: 'state',\n                    type: 'state',\n                    output: START\n                }\n                return returnOutput\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n}"
}

## ToolNode_SeqAgents

{
  "className": "ToolNode_SeqAgents",
  "init": "[Function: init]",
  "constructor": "constructor(\n        tools: StructuredTool[],\n        nodeData: INodeData,\n        inputQuery: string,\n        options: ICommonObject,\n        name: string = 'tools',\n        tags: string[] = [],\n        metadata: ICommonObject = {}\n    ) {\n        super({ name, metadata, tags, func: (input, config) => this.run(input, config) }",
  "if": "if (selectedTab === 'updateStateMemoryCode' && updateStateMemoryCode) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${updateStateMemoryCode}",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "for": "for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                }",
  "outsideClass_defaultApprovalPrompt": "const defaultApprovalPrompt = `You are about to execute tool: {tools}. Ask if user want to proceed`\n\nconst customOutputFuncDesc = `This is only applicable when you have a custom State at the START node. After tool execution, you might want to update the State values`\n\nconst howToUseCode = `\n1. Return the key value JSON object. For example: if you have the following State:\n    \\`\\`\\`json\n    {\n        \"user\": null\n    }\n    \\`\\`\\`\n\n    You can update the \"user\" value by returning the following:\n    \\`\\`\\`js\n    return {\n        \"user\": \"john doe\"\n    }\n    \\`\\`\\`\n\n2. If you want to use the tool's output as the value to update state, it is available as \\`$flow.output\\` with the following structure (array):\n    \\`\\`\\`json\n    [\n        {\n            \"tool\": \"tool's name\",\n            \"toolInput\": {},\n            \"toolOutput\": \"tool's output content\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\",\n                }\n            ],\n        }\n    ]\n    \\`\\`\\`\n\n    For example:\n    \\`\\`\\`js\n    /* Assuming you have the following state:\n    {\n        \"sources\": null\n    }\n    */\n    \n    return {\n        \"sources\": $flow.output[0].sourceDocuments\n    }\n    \\`\\`\\`\n\n3. You can also get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\nconst howToUse = `\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the agent's output as the value to update state, it is available as available as \\`$flow.output\\` with the following structure (array):\n    \\`\\`\\`json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\",\n                }\n            ],\n        }\n    ]\n    \\`\\`\\`\n\n    For example:\n    | Key          | Value                                     |\n    |--------------|-------------------------------------------|\n    | sources      | \\`$flow.output[0].sourceDocuments\\`       |\n\n3. You can get default flow config, including the current \"state\":\n    - \\`$flow.sessionId\\`\n    - \\`$flow.chatId\\`\n    - \\`$flow.chatflowId\\`\n    - \\`$flow.input\\`\n    - \\`$flow.state\\`\n\n4. You can get custom variables: \\`$vars.<variable-name>\\`\n\n`\n\nconst defaultFunc = `const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};`\nconst TAB_IDENTIFIER = 'selectedUpdateStateMemoryTab'",
  "outsideClass_toolNodeLabel": "const toolNodeLabel = nodeData.inputs?.toolNodeName as string\n        const llmNode = nodeData.inputs?.llmNode as ISeqAgentNode\n        if (!llmNode) throw new Error('Tool node must have a predecessor!')\n\n        const interrupt = nodeData.inputs?.interrupt as boolean\n        const approvalPrompt = nodeData.inputs?.approvalPrompt as string\n        const approveButtonText = nodeData.inputs?.approveButtonText as string\n        const rejectButtonText = nodeData.inputs?.rejectButtonText as string\n\n        let tools = nodeData.inputs?.tools\n        tools = flatten(tools)\n        if (!tools || !tools.length) throw new Error('Tools must not be empty')\n\n        const output = nodeData.outputs?.output as string\n\n        if (!toolNodeLabel) throw new Error('Tool node name is required!')\n        const toolNodeLabelName = toolNodeLabel.toLowerCase().replace(/\\s/g, '_').trim()\n\n        const toolNode = new ToolNode(tools, nodeData, input, options, toolNodeLabelName, [], { sequentialNodeName: toolNodeLabelName })\n        ;(toolNode as any).interrupt = interrupt\n\n        if (interrupt && approvalPrompt && approveButtonText && rejectButtonText) {\n            ;(toolNode as any).seekPermissionMessage = async (usedTools: IUsedTool[]) => {\n                const prompt = ChatPromptTemplate.fromMessages([['human', approvalPrompt || defaultApprovalPrompt]])\n                const chain = prompt.pipe(llmNode.startLLM)\n                const response = (await chain.invoke({\n                    input: 'Hello there!',\n                    tools: JSON.stringify(usedTools)\n                })) as AIMessageChunk\n                return response.content\n            }\n        }\n\n        const returnOutput: ISeqAgentNode = {\n            id: nodeData.id,\n            node: toolNode,\n            name: toolNodeLabelName,\n            label: toolNodeLabel,\n            type: 'tool',\n            output,\n            predecessorAgents: [llmNode],\n            llm: llmNode.llm,\n            startLLM: llmNode.startLLM,\n            moderations: llmNode.moderations,\n            multiModalMessageContent: llmNode.multiModalMessageContent\n        }\n\n        return returnOutput\n    }\n}",
  "outsideClass_message": "const message = messages[messages.length - 1]\n\n        if (message._getType() !== 'ai') {\n            throw new Error('ToolNode only accepts AIMessages as input.')\n        }\n\n        // Extract all properties except messages for IStateWithMessages\n        const { messages: _, ...inputWithoutMessages } = Array.isArray(input) ? { messages: input } : input\n        const ChannelsWithoutMessages = {\n            state: inputWithoutMessages\n        }\n\n        const outputs = await Promise.all(\n            (message as AIMessage).tool_calls?.map(async (call) => {\n                const tool = this.tools.find((tool) => tool.name === call.name)\n                if (tool === undefined) {\n                    throw new Error(`Tool ${call.name} not found.`)\n                }\n                if (tool && tool instanceof DynamicStructuredTool) {\n                    // @ts-ignore\n                    tool.setFlowObject(ChannelsWithoutMessages)\n                }\n                let output = await tool.invoke(call.args, config)\n                let sourceDocuments: Document[] = []\n                if (output?.includes(SOURCE_DOCUMENTS_PREFIX)) {\n                    const outputArray = output.split(SOURCE_DOCUMENTS_PREFIX)\n                    output = outputArray[0]\n                    const docs = outputArray[1]\n                    try {\n                        sourceDocuments = JSON.parse(docs)\n                    } catch (e) {\n                        console.error('Error parsing source documents from tool')\n                    }\n                }\n                return new ToolMessage({\n                    name: tool.name,\n                    content: typeof output === 'string' ? output : JSON.stringify(output),\n                    tool_call_id: call.id!,\n                    additional_kwargs: {\n                        sourceDocuments,\n                        args: call.args,\n                        usedTools: [\n                            {\n                                tool: tool.name ?? '',\n                                toolInput: call.args,\n                                toolOutput: output\n                            }\n                        ]\n                    }\n                })\n            }) ?? []\n        )\n\n        const additional_kwargs: ICommonObject = { nodeId: this.nodeData.id }\n        outputs.forEach((result) => (result.additional_kwargs = { ...result.additional_kwargs, ...additional_kwargs }))\n\n        if (this.nodeData.inputs?.updateStateMemoryUI || this.nodeData.inputs?.updateStateMemoryCode) {\n            const returnedOutput = await getReturnOutput(this.nodeData, this.inputQuery, this.options, outputs, input)\n            return {\n                ...returnedOutput,\n                messages: outputs\n            }\n        } else {\n            return Array.isArray(input) ? outputs : { messages: outputs }\n        }\n    }\n}\n\nconst getReturnOutput = async (\n    nodeData: INodeData,\n    input: string,\n    options: ICommonObject,\n    outputs: ToolMessage[],\n    state: ICommonObject\n) => {\n    const appDataSource = options.appDataSource as DataSource\n    const databaseEntities = options.databaseEntities as IDatabaseEntity\n    const tabIdentifier = nodeData.inputs?.[`${TAB_IDENTIFIER}_${nodeData.id}`] as string\n    const updateStateMemoryUI = nodeData.inputs?.updateStateMemoryUI as string\n    const updateStateMemoryCode = nodeData.inputs?.updateStateMemoryCode as string\n    const updateStateMemory = nodeData.inputs?.updateStateMemory as string\n\n    const selectedTab = tabIdentifier ? tabIdentifier.split(`_${nodeData.id}`)[0] : 'updateStateMemoryUI'\n    const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n    const reformattedOutput = outputs.map((output) => {\n        return {\n            tool: output.name,\n            toolInput: output.additional_kwargs.args,\n            toolOutput: output.content,\n            sourceDocuments: output.additional_kwargs.sourceDocuments\n        } as IUsedTool\n    })\n\n    const flow = {\n        chatflowId: options.chatflowid,\n        sessionId: options.sessionId,\n        chatId: options.chatId,\n        input,\n        output: reformattedOutput,\n        state,\n        vars: prepareSandboxVars(variables)\n    }\n\n    if (updateStateMemory && updateStateMemory !== 'updateStateMemoryUI' && updateStateMemory !== 'updateStateMemoryCode') {\n        try {\n            const parsedSchema = typeof updateStateMemory === 'string' ? JSON.parse(updateStateMemory) : updateStateMemory\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.Key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.Value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.Value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.Value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n\n    if (selectedTab === 'updateStateMemoryUI' && updateStateMemoryUI) {\n        try {\n            const parsedSchema = typeof updateStateMemoryUI === 'string' ? JSON.parse(updateStateMemoryUI) : updateStateMemoryUI\n            const obj: ICommonObject = {}\n            for (const sch of parsedSchema) {\n                const key = sch.key\n                if (!key) throw new Error(`Key is required`)\n                let value = sch.value as string\n                if (value.startsWith('$flow')) {\n                    value = customGet(flow, sch.value.replace('$flow.', ''))\n                } else if (value.startsWith('$vars')) {\n                    value = customGet(flow, sch.value.replace('$', ''))\n                }\n                obj[key] = value\n            }\n            return obj\n        } catch (e) {\n            throw new Error(e)\n        }\n    } else if (selectedTab === 'updateStateMemoryCode' && updateStateMemoryCode) {\n        const vm = await getVM(appDataSource, databaseEntities, nodeData, flow)\n        try {\n            const response = await vm.run(`module.exports = async function() {${updateStateMemoryCode}}()`, __dirname)\n            if (typeof response !== 'object') throw new Error('Return output must be an object')\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## AssemblyAI_SpeechToText

{
  "className": "AssemblyAI_SpeechToText",
  "constructor": "constructor() {\n        this.label = 'AssemblyAI'\n        this.name = 'assemblyAI'\n        this.version = 1.0\n        this.type = 'AssemblyAI'\n        this.icon = 'assemblyai.png'\n        this.category = 'SpeechToText'\n        this.baseClasses = [this.type]\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['assemblyAIApi']\n        }"
}

## CharacterTextSplitter_TextSplitters

{
  "className": "CharacterTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Character Text Splitter'\n        this.name = 'characterTextSplitter'\n        this.version = 1.0\n        this.type = 'CharacterTextSplitter'\n        this.icon = 'textsplitter.svg'\n        this.category = 'Text Splitters'\n        this.description = `splits only on one type of character (defaults to \"\\\\n\\\\n\").`\n        this.baseClasses = [this.type, ...getBaseClasses(CharacterTextSplitter)]\n        this.inputs = [\n            {\n                label: 'Chunk Size',\n                name: 'chunkSize',\n                type: 'number',\n                description: 'Number of characters in each chunk. Default is 1000.',\n                default: 1000,\n                optional: true\n            }",
  "outsideClass_separator": "const separator = nodeData.inputs?.separator as string\n        const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n\n        const obj = {} as CharacterTextSplitterParams\n\n        if (separator) obj.separator = separator\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n\n        const splitter = new CharacterTextSplitter(obj)\n\n        return splitter\n    }\n}"
}

## CodeTextSplitter_TextSplitters

{
  "className": "CodeTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Code Text Splitter'\n        this.name = 'codeTextSplitter'\n        this.version = 1.0\n        this.type = 'CodeTextSplitter'\n        this.icon = 'codeTextSplitter.svg'\n        this.category = 'Text Splitters'\n        this.description = `Split documents based on language-specific syntax`\n        this.baseClasses = [this.type, ...getBaseClasses(RecursiveCharacterTextSplitter)]\n        this.inputs = [\n            {\n                label: 'Language',\n                name: 'language',\n                type: 'options',\n                options: [\n                    {\n                        label: 'cpp',\n                        name: 'cpp'\n                    }",
  "outsideClass_chunkSize": "const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n        const language = nodeData.inputs?.language as SupportedTextSplitterLanguage\n\n        const obj = {} as RecursiveCharacterTextSplitterParams\n\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n\n        const splitter = RecursiveCharacterTextSplitter.fromLanguage(language, obj)\n\n        return splitter\n    }\n}"
}

## HtmlToMarkdownTextSplitter_TextSplitters

{
  "className": "HtmlToMarkdownTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor(fields?: Partial<MarkdownTextSplitterParams>) {\n        {\n            super(fields)\n        }",
  "outsideClass_chunkSize": "const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n\n        const obj = {} as MarkdownTextSplitterParams\n\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n\n        const splitter = new HtmlToMarkdownTextSplitter(obj)\n\n        return splitter\n    }\n}",
  "outsideClass_markdown": "const markdown = NodeHtmlMarkdown.translate(text)\n            super.splitText(markdown).then((result) => {\n                resolve(result)\n            })\n        })\n    }\n}"
}

## MarkdownTextSplitter_TextSplitters

{
  "className": "MarkdownTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Markdown Text Splitter'\n        this.name = 'markdownTextSplitter'\n        this.version = 1.0\n        this.type = 'MarkdownTextSplitter'\n        this.icon = 'markdownTextSplitter.svg'\n        this.category = 'Text Splitters'\n        this.description = `Split your content into documents based on the Markdown headers`\n        this.baseClasses = [this.type, ...getBaseClasses(MarkdownTextSplitter)]\n        this.inputs = [\n            {\n                label: 'Chunk Size',\n                name: 'chunkSize',\n                type: 'number',\n                description: 'Number of characters in each chunk. Default is 1000.',\n                default: 1000,\n                optional: true\n            }",
  "outsideClass_chunkSize": "const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n\n        const obj = {} as MarkdownTextSplitterParams\n\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n\n        const splitter = new MarkdownTextSplitter(obj)\n\n        return splitter\n    }\n}"
}

## RecursiveCharacterTextSplitter_TextSplitters

{
  "className": "RecursiveCharacterTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Recursive Character Text Splitter'\n        this.name = 'recursiveCharacterTextSplitter'\n        this.version = 2.0\n        this.type = 'RecursiveCharacterTextSplitter'\n        this.icon = 'textsplitter.svg'\n        this.category = 'Text Splitters'\n        this.description = `Split documents recursively by different characters - starting with \"\\\\n\\\\n\", then \"\\\\n\", then \" \"`\n        this.baseClasses = [this.type, ...getBaseClasses(RecursiveCharacterTextSplitter)]\n        this.inputs = [\n            {\n                label: 'Chunk Size',\n                name: 'chunkSize',\n                type: 'number',\n                description: 'Number of characters in each chunk. Default is 1000.',\n                default: 1000,\n                optional: true\n            }",
  "if": "if (separators) {\n            try {\n                obj.separators = typeof separators === 'object' ? separators : JSON.parse(separators)\n            }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_chunkSize": "const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n        const separators = nodeData.inputs?.separators\n\n        const obj = {} as RecursiveCharacterTextSplitterParams\n\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n        if (separators) {\n            try {\n                obj.separators = typeof separators === 'object' ? separators : JSON.parse(separators)\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n\n        const splitter = new RecursiveCharacterTextSplitter(obj)\n\n        return splitter\n    }\n}"
}

## TokenTextSplitter_TextSplitters

{
  "className": "TokenTextSplitter_TextSplitters",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Token Text Splitter'\n        this.name = 'tokenTextSplitter'\n        this.version = 1.0\n        this.type = 'TokenTextSplitter'\n        this.icon = 'tiktoken.svg'\n        this.category = 'Text Splitters'\n        this.description = `Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.`\n        this.baseClasses = [this.type, ...getBaseClasses(TokenTextSplitter)]\n        this.inputs = [\n            {\n                label: 'Encoding Name',\n                name: 'encodingName',\n                type: 'options',\n                options: [\n                    {\n                        label: 'gpt2',\n                        name: 'gpt2'\n                    }",
  "outsideClass_encodingName": "const encodingName = nodeData.inputs?.encodingName as string\n        const chunkSize = nodeData.inputs?.chunkSize as string\n        const chunkOverlap = nodeData.inputs?.chunkOverlap as string\n\n        const obj = {} as TokenTextSplitterParams\n\n        obj.encodingName = encodingName as TiktokenEncoding\n        if (chunkSize) obj.chunkSize = parseInt(chunkSize, 10)\n        if (chunkOverlap) obj.chunkOverlap = parseInt(chunkOverlap, 10)\n\n        const splitter = new TokenTextSplitter(obj)\n\n        return splitter\n    }\n}"
}

## BraveSearchAPI_Tools

{
  "className": "BraveSearchAPI_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'BraveSearch API'\n        this.name = 'braveSearchAPI'\n        this.version = 1.0\n        this.type = 'BraveSearchAPI'\n        this.icon = 'brave.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around BraveSearch API - a real-time API to access Brave search results'\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['braveSearchApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const braveApiKey = getCredentialParam('braveApiKey', credentialData, nodeData)\n        return new BraveSearch({ apiKey: braveApiKey })\n    }\n}"
}

## Calculator_Tools

{
  "className": "Calculator_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Calculator'\n        this.name = 'calculator'\n        this.version = 1.0\n        this.type = 'Calculator'\n        this.icon = 'calculator.svg'\n        this.category = 'Tools'\n        this.description = 'Perform calculations on response'\n        this.baseClasses = [this.type, ...getBaseClasses(Calculator)]\n    }"
}

## ChainTool_Tools

{
  "className": "ChainTool_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Chain Tool'\n        this.name = 'chainTool'\n        this.version = 1.0\n        this.type = 'ChainTool'\n        this.icon = 'chaintool.svg'\n        this.category = 'Tools'\n        this.description = 'Use a chain as allowed tool for agent'\n        this.baseClasses = [this.type, ...getBaseClasses(ChainTool)]\n        this.inputs = [\n            {\n                label: 'Chain Name',\n                name: 'name',\n                type: 'string',\n                placeholder: 'state-of-union-qa'\n            }",
  "outsideClass_name": "const name = nodeData.inputs?.name as string\n        const description = nodeData.inputs?.description as string\n        const baseChain = nodeData.inputs?.baseChain as BaseChain\n        const returnDirect = nodeData.inputs?.returnDirect as boolean\n\n        const obj = {\n            name,\n            description,\n            chain: baseChain\n        } as any\n\n        if (returnDirect) obj.returnDirect = returnDirect\n\n        const tool = new ChainTool(obj)\n\n        return tool\n    }\n}"
}

## ChatflowTool_Tools

{
  "className": "ChatflowTool_Tools",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor({\n        name,\n        description,\n        input,\n        chatflowid,\n        startNewSession,\n        baseURL,\n        headers\n    }: {\n        name: string\n        description: string\n        input: string\n        chatflowid: string\n        startNewSession: boolean\n        baseURL: string\n        headers: ICommonObject\n    }) {\n        super()\n        this.name = name\n        this.description = description\n        this.input = input\n        this.baseURL = baseURL\n        this.startNewSession = startNewSession\n        this.headers = headers\n        this.chatflowid = chatflowid\n    }",
  "if": "if (config.runName === undefined) {\n            config.runName = this.name\n        }",
  "for": "for (let i = 0; i < chatflows.length; i += 1) {\n                const data = {\n                    label: chatflows[i].name,\n                    name: chatflows[i].id\n                }",
  "lc_name": "lc_name() {\n        return 'ChatflowTool'\n    }",
  "catch": "catch (error) {\n\tconsole.error(error);\n\treturn '';\n}",
  "run": "run(`module.exports = async function() {${code}",
  "outsideClass_appDataSource": "const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n            if (appDataSource === undefined || !appDataSource) {\n                return returnData\n            }\n\n            const chatflows = await appDataSource.getRepository(databaseEntities['ChatFlow']).find()\n\n            for (let i = 0; i < chatflows.length; i += 1) {\n                const data = {\n                    label: chatflows[i].name,\n                    name: chatflows[i].id\n                } as INodeOptionsValue\n                returnData.push(data)\n            }\n            return returnData\n        }\n    }\n\n    async init(nodeData: INodeData, input: string, options: ICommonObject): Promise<any> {\n        const selectedChatflowId = nodeData.inputs?.selectedChatflow as string\n        const _name = nodeData.inputs?.name as string\n        const description = nodeData.inputs?.description as string\n        const useQuestionFromChat = nodeData.inputs?.useQuestionFromChat as boolean\n        const customInput = nodeData.inputs?.customInput as string\n\n        const startNewSession = nodeData.inputs?.startNewSession as boolean\n\n        const baseURL = (nodeData.inputs?.baseURL as string) || (options.baseURL as string)\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const chatflowApiKey = getCredentialParam('chatflowApiKey', credentialData, nodeData)\n\n        if (selectedChatflowId === options.chatflowid) throw new Error('Cannot call the same chatflow!')\n\n        let headers = {}\n        if (chatflowApiKey) headers = { Authorization: `Bearer ${chatflowApiKey}` }\n\n        let toolInput = ''\n        if (useQuestionFromChat) {\n            toolInput = input\n        } else if (!customInput) {\n            toolInput = customInput\n        }\n\n        let name = _name || 'chatflow_tool'\n\n        return new ChatflowTool({ name, baseURL, description, chatflowid: selectedChatflowId, startNewSession, headers, input: toolInput })\n    }\n}",
  "outsideClass_config": "const config = parseCallbackConfigArg(configArg)\n        if (config.runName === undefined) {\n            config.runName = this.name\n        }\n        let parsed\n        try {\n            parsed = await this.schema.parseAsync(arg)\n        } catch (e) {\n            throw new Error(`Received tool input did not match expected schema: ${JSON.stringify(arg)}`)\n        }\n        const callbackManager_ = await CallbackManager.configure(\n            config.callbacks,\n            this.callbacks,\n            config.tags || tags,\n            this.tags,\n            config.metadata,\n            this.metadata,\n            { verbose: this.verbose }\n        )\n        const runManager = await callbackManager_?.handleToolStart(\n            this.toJSON(),\n            typeof parsed === 'string' ? parsed : JSON.stringify(parsed),\n            undefined,\n            undefined,\n            undefined,\n            undefined,\n            config.runName\n        )\n        let result\n        try {\n            result = await this._call(parsed, runManager, flowConfig)\n        } catch (e) {\n            await runManager?.handleToolError(e)\n            throw e\n        }\n        await runManager?.handleToolEnd(result)\n        return result\n    }\n\n    // @ts-ignore\n    protected async _call(\n        arg: z.infer<typeof this.schema>,\n        _?: CallbackManagerForToolRun,\n        flowConfig?: { sessionId?: string; chatId?: string; input?: string }\n    ): Promise<string> {\n        const inputQuestion = this.input || arg.input\n\n        const body = {\n            question: inputQuestion,\n            chatId: this.startNewSession ? uuidv4() : flowConfig?.chatId,\n            overrideConfig: {\n                sessionId: this.startNewSession ? uuidv4() : flowConfig?.sessionId\n            }\n        }\n\n        const options = {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                ...this.headers\n            },\n            body: JSON.stringify(body)\n        }\n\n        let sandbox = { $callOptions: options, $callBody: body }\n\n        const code = `\nconst fetch = require('node-fetch');\nconst url = \"${this.baseURL}/api/v1/prediction/${this.chatflowid}\";\n\nconst body = $callBody;\n\nconst options = $callOptions;\n\ntry {\n\tconst response = await fetch(url, options);\n\tconst resp = await response.json();\n\treturn resp.text;\n} catch (error) {\n\tconsole.error(error);\n\treturn '';\n}\n`\n        const builtinDeps = process.env.TOOL_FUNCTION_BUILTIN_DEP\n            ? defaultAllowBuiltInDep.concat(process.env.TOOL_FUNCTION_BUILTIN_DEP.split(','))\n            : defaultAllowBuiltInDep\n        const externalDeps = process.env.TOOL_FUNCTION_EXTERNAL_DEP ? process.env.TOOL_FUNCTION_EXTERNAL_DEP.split(',') : []\n        const deps = availableDependencies.concat(externalDeps)\n\n        const vmOptions = {\n            console: 'inherit',\n            sandbox,\n            require: {\n                external: { modules: deps },\n                builtin: builtinDeps\n            }\n        } as any\n\n        const vm = new NodeVM(vmOptions)\n        const response = await vm.run(`module.exports = async function() {${code}}()`, __dirname)\n\n        return response\n    }\n}"
}

## CustomTool_Tools

{
  "className": "CustomTool_Tools",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Custom Tool'\n        this.name = 'customTool'\n        this.version = 2.0\n        this.type = 'CustomTool'\n        this.icon = 'customtool.svg'\n        this.category = 'Tools'\n        this.description = `Use custom tool you've created in Flowise within chatflow`\n        this.inputs = [\n            {\n                label: 'Select Tool',\n                name: 'selectedTool',\n                type: 'asyncOptions',\n                loadMethod: 'listTools'\n            }",
  "if": "if (customToolSchema) {\n                const zodSchemaFunction = new Function('z', `return ${customToolSchema}",
  "for": "for (let i = 0; i < tools.length; i += 1) {\n                const data = {\n                    label: tools[i].name,\n                    name: tools[i].id,\n                    description: tools[i].description\n                }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "outsideClass_appDataSource": "const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n            if (appDataSource === undefined || !appDataSource) {\n                return returnData\n            }\n\n            const tools = await appDataSource.getRepository(databaseEntities['Tool']).find()\n\n            for (let i = 0; i < tools.length; i += 1) {\n                const data = {\n                    label: tools[i].name,\n                    name: tools[i].id,\n                    description: tools[i].description\n                } as INodeOptionsValue\n                returnData.push(data)\n            }\n            return returnData\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const selectedToolId = nodeData.inputs?.selectedTool as string\n        const customToolFunc = nodeData.inputs?.customToolFunc as string\n        const customToolName = nodeData.inputs?.customToolName as string\n        const customToolDesc = nodeData.inputs?.customToolDesc as string\n        const customToolSchema = nodeData.inputs?.customToolSchema as string\n        const customToolReturnDirect = nodeData.inputs?.returnDirect as boolean\n\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n        try {\n            const tool = await appDataSource.getRepository(databaseEntities['Tool']).findOneBy({\n                id: selectedToolId\n            })\n\n            if (!tool) throw new Error(`Tool ${selectedToolId} not found`)\n            const obj = {\n                name: tool.name,\n                description: tool.description,\n                schema: z.object(convertSchemaToZod(tool.schema)),\n                code: tool.func\n            }\n            if (customToolFunc) obj.code = customToolFunc\n            if (customToolName) obj.name = customToolName\n            if (customToolDesc) obj.description = customToolDesc\n            if (customToolSchema) {\n                const zodSchemaFunction = new Function('z', `return ${customToolSchema}`)\n                obj.schema = zodSchemaFunction(z)\n            }\n\n            const variables = await getVars(appDataSource, databaseEntities, nodeData)\n\n            const flow = { chatflowId: options.chatflowid }\n\n            let dynamicStructuredTool = new DynamicStructuredTool(obj)\n            dynamicStructuredTool.setVariables(variables)\n            dynamicStructuredTool.setFlowObject(flow)\n            dynamicStructuredTool.returnDirect = customToolReturnDirect\n\n            return dynamicStructuredTool\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## ExaSearch_Tools

{
  "className": "ExaSearch_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Exa Search'\n        this.name = 'exaSearch'\n        this.version = 1.0\n        this.type = 'ExaSearch'\n        this.icon = 'exa.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around Exa Search API - search engine fully designed for use by LLMs'\n        this.inputs = [\n            {\n                label: 'Tool Description',\n                name: 'description',\n                type: 'string',\n                description: 'Description of what the tool does. This is for LLM to determine when to use this tool.',\n                rows: 4,\n                additionalParams: true,\n                default: DESC\n            }",
  "outsideClass_DESC": "const DESC = `A wrapper around Exa Search. Input should be an Exa-optimized query. Output is a JSON array of the query results`",
  "outsideClass_description": "const description = nodeData.inputs?.description as string\n        const numResults = nodeData.inputs?.numResults as string\n        const type = nodeData.inputs?.type as string\n        const useAutoprompt = nodeData.inputs?.useAutoprompt as boolean\n        const category = nodeData.inputs?.category as string\n        const includeDomains = nodeData.inputs?.includeDomains as string\n        const excludeDomains = nodeData.inputs?.excludeDomains as string\n        const startCrawlDate = nodeData.inputs?.startCrawlDate as string\n        const endCrawlDate = nodeData.inputs?.endCrawlDate as string\n        const startPublishedDate = nodeData.inputs?.startPublishedDate as string\n        const endPublishedDate = nodeData.inputs?.endPublishedDate as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const exaSearchApiKey = getCredentialParam('exaSearchApiKey', credentialData, nodeData)\n\n        const tool = new ExaSearchResults({\n            client: new Exa(exaSearchApiKey),\n            searchArgs: {\n                numResults: numResults ? parseFloat(numResults) : undefined,\n                type: type || undefined,\n                useAutoprompt: useAutoprompt || undefined,\n                category: category || undefined,\n                includeDomains: includeDomains ? includeDomains.split(',') : undefined,\n                excludeDomains: excludeDomains ? excludeDomains.split(',') : undefined,\n                startCrawlDate: startCrawlDate || undefined,\n                endCrawlDate: endCrawlDate || undefined,\n                startPublishedDate: startPublishedDate || undefined,\n                endPublishedDate: endPublishedDate || undefined\n            }\n        })\n\n        if (description) tool.description = description\n\n        return tool\n    }\n}"
}

## GoogleCustomSearchAPI_Tools

{
  "className": "GoogleCustomSearchAPI_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Google Custom Search'\n        this.name = 'googleCustomSearch'\n        this.version = 1.0\n        this.type = 'GoogleCustomSearchAPI'\n        this.icon = 'google.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around Google Custom Search API - a real-time API to access Google search results'\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['googleCustomSearchApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const googleApiKey = getCredentialParam('googleCustomSearchApiKey', credentialData, nodeData)\n        const googleCseId = getCredentialParam('googleCustomSearchApiId', credentialData, nodeData)\n        return new GoogleCustomSearch({ apiKey: googleApiKey, googleCSEId: googleCseId })\n    }\n}"
}

## OpenAPIToolkit_Tools

{
  "className": "OpenAPIToolkit_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenAPI Toolkit'\n        this.name = 'openAPIToolkit'\n        this.version = 1.0\n        this.type = 'OpenAPIToolkit'\n        this.icon = 'openapi.svg'\n        this.category = 'Tools'\n        this.description = 'Load OpenAPI specification'\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Only needed if the YAML OpenAPI Spec requires authentication',\n            optional: true,\n            credentialNames: ['openAPIAuth']\n        }",
  "if": "if (!data) {\n            throw new Error('Failed to load OpenAPI spec')\n        }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const yamlFileBase64 = nodeData.inputs?.yamlFile as string\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const openAPIToken = getCredentialParam('openAPIToken', credentialData, nodeData)\n\n        let data: JsonObject\n        if (yamlFileBase64.startsWith('FILE-STORAGE::')) {\n            const file = yamlFileBase64.replace('FILE-STORAGE::', '')\n            const chatflowid = options.chatflowid\n            const fileData = await getFileFromStorage(file, chatflowid)\n            const utf8String = fileData.toString('utf-8')\n\n            data = load(utf8String) as JsonObject\n        } else {\n            const splitDataURI = yamlFileBase64.split(',')\n            splitDataURI.pop()\n            const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n            const utf8String = bf.toString('utf-8')\n            data = load(utf8String) as JsonObject\n        }\n        if (!data) {\n            throw new Error('Failed to load OpenAPI spec')\n        }\n\n        const headers: ICommonObject = {\n            'Content-Type': 'application/json'\n        }\n        if (openAPIToken) headers.Authorization = `Bearer ${openAPIToken}`\n        const toolkit = new OpenApiToolkit(new JsonSpec(data), model, headers)\n\n        return toolkit.tools\n    }\n}"
}

## PythonInterpreter_Tools

{
  "className": "PythonInterpreter_Tools",
  "init": "[Function: init]",
  "if": "if (pyodideInstance === undefined) {\n        const obj = { packageCacheDir: path.join(getUserHome(), '.flowise', 'pyodideCacheDir') }",
  "constructor": "constructor(options: PythonInterpreterToolParams & { name: string; description: string }) {\n        super(options)\n        this.description = options.description\n        this.name = options.name\n        this.pyodideInstance = options.instance\n        this.pyodideInstance.setStderr({\n            batched: (text: string) => {\n                this.stderr += text\n            }",
  "lc_name": "lc_name() {\n        return 'PythonInterpreterTool'\n    }",
  "initialize": "initialize(options: Partial<PythonInterpreterToolParams> & { name: string; description: string }) {\n        const instance = await LoadPyodide()\n        return new this({ instance, name: options.name, description: options.description }",
  "_call": "_call(script: string) {\n        this.stdout = ''\n        this.stderr = ''\n\n        try {\n            await this.pyodideInstance.loadPackagesFromImports(script)\n            await this.pyodideInstance.runPythonAsync(script)\n            return JSON.stringify({ stdout: this.stdout, stderr: this.stderr }",
  "catch": "catch (e) {\n            return typeof e === 'string' ? e : JSON.stringify(e, null, 2)\n        }",
  "outsideClass_DESC": "const DESC = `Evaluates python code in a sandbox environment. The environment resets on every execution. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. Use only packages available in Pyodide.`\nconst NAME = 'python_interpreter'\n\nasync function LoadPyodide(): Promise<PyodideInterface> {\n    if (pyodideInstance === undefined) {\n        const obj = { packageCacheDir: path.join(getUserHome(), '.flowise', 'pyodideCacheDir') }\n        pyodideInstance = await loadPyodide(obj)\n    }\n    return pyodideInstance\n}",
  "outsideClass_toolDesc": "const toolDesc = nodeData.inputs?.toolDesc as string\n        const toolName = nodeData.inputs?.toolName as string\n\n        return await PythonInterpreterTool.initialize({\n            description: toolDesc ?? DESC,\n            name: toolName ?? NAME\n        })\n    }\n}\n\ntype PythonInterpreterToolParams = Parameters<typeof loadPyodide>[0] &\n    ToolParams & {\n        instance: PyodideInterface\n    }\n\nexport class PythonInterpreterTool extends Tool {\n    static lc_name() {\n        return 'PythonInterpreterTool'\n    }\n\n    name = NAME\n\n    description = DESC\n\n    pyodideInstance: PyodideInterface\n\n    stdout = ''\n\n    stderr = ''\n\n    constructor(options: PythonInterpreterToolParams & { name: string; description: string }) {\n        super(options)\n        this.description = options.description\n        this.name = options.name\n        this.pyodideInstance = options.instance\n        this.pyodideInstance.setStderr({\n            batched: (text: string) => {\n                this.stderr += text\n            }\n        })\n        this.pyodideInstance.setStdout({\n            batched: (text: string) => {\n                this.stdout += text\n            }\n        })\n    }\n\n    static async initialize(options: Partial<PythonInterpreterToolParams> & { name: string; description: string }) {\n        const instance = await LoadPyodide()\n        return new this({ instance, name: options.name, description: options.description })\n    }\n\n    async _call(script: string) {\n        this.stdout = ''\n        this.stderr = ''\n\n        try {\n            await this.pyodideInstance.loadPackagesFromImports(script)\n            await this.pyodideInstance.runPythonAsync(script)\n            return JSON.stringify({ stdout: this.stdout, stderr: this.stderr }, null, 2)\n        } catch (e) {\n            return typeof e === 'string' ? e : JSON.stringify(e, null, 2)\n        }\n    }\n}"
}

## QueryEngine_Tools

{
  "className": "QueryEngine_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'QueryEngine Tool'\n        this.name = 'queryEngineToolLlamaIndex'\n        this.version = 2.0\n        this.type = 'QueryEngineTool'\n        this.icon = 'queryEngineTool.svg'\n        this.category = 'Tools'\n        this.tags = ['LlamaIndex']\n        this.description = 'Tool used to invoke query engine'\n        this.baseClasses = [this.type, 'Tool_LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Base QueryEngine',\n                name: 'baseQueryEngine',\n                type: 'BaseQueryEngine'\n            }",
  "outsideClass_baseQueryEngine": "const baseQueryEngine = nodeData.inputs?.baseQueryEngine\n        const toolName = nodeData.inputs?.toolName as string\n        const toolDesc = nodeData.inputs?.toolDesc as string\n        const queryEngineTool = new QueryEngineTool({\n            queryEngine: baseQueryEngine,\n            metadata: {\n                name: toolName,\n                description: toolDesc\n            }\n        })\n\n        return queryEngineTool\n    }\n}"
}

## ReadFile_Tools

{
  "className": "ReadFile_Tools",
  "init": "[Function: init]",
  "constructor": "constructor({ store }: ReadFileParams) {\n        super(...arguments)\n\n        this.store = store\n    }",
  "lc_name": "lc_name() {\n        return 'ReadFileTool'\n    }",
  "_call": "_call({ file_path }: z.infer<typeof this.schema>) {\n        return await this.store.readFile(file_path)\n    }",
  "outsideClass_basePath": "const basePath = nodeData.inputs?.basePath as string\n        const store = basePath ? new NodeFileStore(basePath) : new NodeFileStore()\n        return new ReadFileTool({ store })\n    }\n}\n\ninterface ReadFileParams extends ToolParams {\n    store: BaseFileStore\n}\n\n/**\n * Class for reading files from the disk. Extends the StructuredTool\n * class.\n */\nexport class ReadFileTool extends StructuredTool {\n    static lc_name() {\n        return 'ReadFileTool'\n    }\n\n    schema = z.object({\n        file_path: z.string().describe('name of file')\n    }) as any\n\n    name = 'read_file'\n\n    description = 'Read file from disk'\n\n    store: BaseFileStore\n\n    constructor({ store }: ReadFileParams) {\n        super(...arguments)\n\n        this.store = store\n    }\n\n    async _call({ file_path }: z.infer<typeof this.schema>) {\n        return await this.store.readFile(file_path)\n    }\n}"
}

## RequestsGet_Tools

{
  "className": "RequestsGet_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Requests Get'\n        this.name = 'requestsGet'\n        this.version = 1.0\n        this.type = 'RequestsGet'\n        this.icon = 'requestsget.svg'\n        this.category = 'Tools'\n        this.description = 'Execute HTTP GET requests'\n        this.baseClasses = [this.type, ...getBaseClasses(RequestsGetTool)]\n        this.inputs = [\n            {\n                label: 'URL',\n                name: 'url',\n                type: 'string',\n                description:\n                    'Agent will make call to this exact URL. If not specified, agent will try to figure out itself from AIPlugin if provided',\n                additionalParams: true,\n                optional: true\n            }",
  "if": "if (headers) {\n            const parsedHeaders = typeof headers === 'object' ? headers : JSON.parse(headers)\n            obj.headers = parsedHeaders\n        }",
  "outsideClass_headers": "const headers = nodeData.inputs?.headers as string\n        const url = nodeData.inputs?.url as string\n        const description = nodeData.inputs?.description as string\n\n        const obj: RequestParameters = {}\n        if (url) obj.url = url\n        if (description) obj.description = description\n        if (headers) {\n            const parsedHeaders = typeof headers === 'object' ? headers : JSON.parse(headers)\n            obj.headers = parsedHeaders\n        }\n\n        return new RequestsGetTool(obj)\n    }\n}"
}

## RequestsPost_Tools

{
  "className": "RequestsPost_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Requests Post'\n        this.name = 'requestsPost'\n        this.version = 1.0\n        this.type = 'RequestsPost'\n        this.icon = 'requestspost.svg'\n        this.category = 'Tools'\n        this.description = 'Execute HTTP POST requests'\n        this.baseClasses = [this.type, ...getBaseClasses(RequestsPostTool)]\n        this.inputs = [\n            {\n                label: 'URL',\n                name: 'url',\n                type: 'string',\n                description:\n                    'Agent will make call to this exact URL. If not specified, agent will try to figure out itself from AIPlugin if provided',\n                additionalParams: true,\n                optional: true\n            }",
  "if": "if (body) {\n            const parsedBody = typeof body === 'object' ? body : JSON.parse(body)\n            obj.body = parsedBody\n        }",
  "outsideClass_headers": "const headers = nodeData.inputs?.headers as string\n        const url = nodeData.inputs?.url as string\n        const description = nodeData.inputs?.description as string\n        const body = nodeData.inputs?.body as string\n\n        const obj: RequestParameters = {}\n        if (url) obj.url = url\n        if (description) obj.description = description\n        if (headers) {\n            const parsedHeaders = typeof headers === 'object' ? headers : JSON.parse(headers)\n            obj.headers = parsedHeaders\n        }\n        if (body) {\n            const parsedBody = typeof body === 'object' ? body : JSON.parse(body)\n            obj.body = parsedBody\n        }\n\n        return new RequestsPostTool(obj)\n    }\n}"
}

## Retriever_Tools

{
  "className": "Retriever_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Retriever Tool'\n        this.name = 'retrieverTool'\n        this.version = 2.0\n        this.type = 'RetrieverTool'\n        this.icon = 'retrievertool.svg'\n        this.category = 'Tools'\n        this.description = 'Use a retriever as allowed tool for agent'\n        this.baseClasses = [this.type, 'DynamicTool', ...getBaseClasses(DynamicTool)]\n        this.inputs = [\n            {\n                label: 'Retriever Name',\n                name: 'name',\n                type: 'string',\n                placeholder: 'search_state_of_union'\n            }",
  "outsideClass_name": "const name = nodeData.inputs?.name as string\n        const description = nodeData.inputs?.description as string\n        const retriever = nodeData.inputs?.retriever as BaseRetriever\n        const returnSourceDocuments = nodeData.inputs?.returnSourceDocuments as boolean\n\n        const input = {\n            name,\n            description\n        }\n\n        const func = async ({ input }: { input: string }, runManager?: CallbackManagerForToolRun) => {\n            const docs = await retriever.getRelevantDocuments(input, runManager?.getChild('retriever'))\n            const content = docs.map((doc) => doc.pageContent).join('\\n\\n')\n            const sourceDocuments = JSON.stringify(docs)\n            return returnSourceDocuments ? content + SOURCE_DOCUMENTS_PREFIX + sourceDocuments : content\n        }\n\n        const schema = z.object({\n            input: z.string().describe('input to look up in retriever')\n        }) as any\n\n        const tool = new DynamicStructuredTool({ ...input, func, schema })\n        return tool\n    }\n}"
}

## SearchAPI_Tools

{
  "className": "SearchAPI_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SearchApi'\n        this.name = 'searchAPI'\n        this.version = 1.0\n        this.type = 'SearchAPI'\n        this.icon = 'searchapi.svg'\n        this.category = 'Tools'\n        this.description = 'Real-time API for accessing Google Search data'\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['searchApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const searchApiKey = getCredentialParam('searchApiKey', credentialData, nodeData)\n        return new SearchApi(searchApiKey)\n    }\n}"
}

## Searxng_Tools

{
  "className": "Searxng_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SearXNG'\n        this.name = 'searXNG'\n        this.version = 1.0\n        this.type = 'SearXNG'\n        this.icon = 'SearXNG.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around SearXNG - a free internet metasearch engine'\n        this.inputs = [\n            {\n                label: 'Base URL',\n                name: 'apiBase',\n                type: 'string',\n                default: 'http://searxng:8080'\n            }",
  "outsideClass_apiBase": "const apiBase = nodeData.inputs?.apiBase as string\n        const categories = nodeData.inputs?.categories as string\n        const engines = nodeData.inputs?.engines as string\n        const language = nodeData.inputs?.language as string\n        const pageno = nodeData.inputs?.pageno as number\n        const time_range = nodeData.inputs?.time_range as string\n        const safesearch = nodeData.inputs?.safesearch as 0 | 1 | 2 | undefined\n        const format = 'json' as 'json'\n\n        const params = {\n            format,\n            categories,\n            engines,\n            language,\n            pageno,\n            time_range,\n            safesearch\n        }\n\n        const headers = {}\n\n        const tool = new SearxngSearch({\n            apiBase,\n            params,\n            headers\n        })\n\n        return tool\n    }\n}"
}

## SerpAPI_Tools

{
  "className": "SerpAPI_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Serp API'\n        this.name = 'serpAPI'\n        this.version = 1.0\n        this.type = 'SerpAPI'\n        this.icon = 'serp.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around SerpAPI - a real-time API to access Google search results'\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['serpApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const serpApiKey = getCredentialParam('serpApiKey', credentialData, nodeData)\n        return new SerpAPI(serpApiKey)\n    }\n}"
}

## Serper_Tools

{
  "className": "Serper_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Serper'\n        this.name = 'serper'\n        this.version = 1.0\n        this.type = 'Serper'\n        this.icon = 'serper.svg'\n        this.category = 'Tools'\n        this.description = 'Wrapper around Serper.dev - Google Search API'\n        this.inputs = []\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['serperApi']\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const serperApiKey = getCredentialParam('serperApiKey', credentialData, nodeData)\n        return new Serper(serperApiKey)\n    }\n}"
}

## WebBrowser_Tools

{
  "className": "WebBrowser_Tools",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Web Browser'\n        this.name = 'webBrowser'\n        this.version = 1.0\n        this.type = 'WebBrowser'\n        this.icon = 'webBrowser.svg'\n        this.category = 'Tools'\n        this.description = 'Gives agent the ability to visit a website and extract information'\n        this.inputs = [\n            {\n                label: 'Language Model',\n                name: 'model',\n                type: 'BaseLanguageModel'\n            }",
  "outsideClass_model": "const model = nodeData.inputs?.model as BaseLanguageModel\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n        return new WebBrowser({ model, embeddings })\n    }\n}"
}

## WriteFile_Tools

{
  "className": "WriteFile_Tools",
  "init": "[Function: init]",
  "constructor": "constructor({ store, ...rest }: WriteFileParams) {\n        super(rest)\n\n        this.store = store\n    }",
  "lc_name": "lc_name() {\n        return 'WriteFileTool'\n    }",
  "_call": "_call({ file_path, text }: z.infer<typeof this.schema>) {\n        await this.store.writeFile(file_path, text)\n        return 'File written to successfully.'\n    }",
  "outsideClass_basePath": "const basePath = nodeData.inputs?.basePath as string\n        const store = basePath ? new NodeFileStore(basePath) : new NodeFileStore()\n        return new WriteFileTool({ store })\n    }\n}\n\ninterface WriteFileParams extends ToolParams {\n    store: BaseFileStore\n}\n\n/**\n * Class for writing data to files on the disk. Extends the StructuredTool\n * class.\n */\nexport class WriteFileTool extends StructuredTool {\n    static lc_name() {\n        return 'WriteFileTool'\n    }\n\n    schema = z.object({\n        file_path: z.string().describe('name of file'),\n        text: z.string().describe('text to write to file')\n    }) as any\n\n    name = 'write_file'\n\n    description = 'Write file from disk'\n\n    store: BaseFileStore\n\n    constructor({ store, ...rest }: WriteFileParams) {\n        super(rest)\n\n        this.store = store\n    }\n\n    async _call({ file_path, text }: z.infer<typeof this.schema>) {\n        await this.store.writeFile(file_path, text)\n        return 'File written to successfully.'\n    }\n}"
}

## CustomFunction_Utilities

{
  "className": "CustomFunction_Utilities",
  "init": "[Function: init]",
  "run": "run(`module.exports = async function() {${javascriptFunction}",
  "constructor": "constructor() {\n        this.label = 'Custom JS Function'\n        this.name = 'customFunction'\n        this.version = 2.0\n        this.type = 'CustomFunction'\n        this.icon = 'customfunction.svg'\n        this.category = 'Utilities'\n        this.description = `Execute custom javascript function`\n        this.baseClasses = [this.type, 'Utilities']\n        this.tags = ['Utilities']\n        this.inputs = [\n            {\n                label: 'Input Variables',\n                name: 'functionInputVariables',\n                description: 'Input variables can be used in the function with prefix $. For example: $var',\n                type: 'json',\n                optional: true,\n                acceptVariable: true,\n                list: true\n            }",
  "if": "if (typeof response === 'string' && !isEndingNode) {\n                return handleEscapeCharacters(response, false)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "for": "for (const item in inputVars) {\n                sandbox[`$${item}",
  "outsideClass_isEndingNode": "const isEndingNode = nodeData?.outputs?.output === 'EndingNode'\n        if (isEndingNode && !options.isRun) return // prevent running both init and run twice\n\n        const javascriptFunction = nodeData.inputs?.javascriptFunction as string\n        const functionInputVariablesRaw = nodeData.inputs?.functionInputVariables\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n        const variables = await getVars(appDataSource, databaseEntities, nodeData)\n        const flow = {\n            chatflowId: options.chatflowid,\n            sessionId: options.sessionId,\n            chatId: options.chatId,\n            input\n        }\n\n        let inputVars: ICommonObject = {}\n        if (functionInputVariablesRaw) {\n            try {\n                inputVars =\n                    typeof functionInputVariablesRaw === 'object' ? functionInputVariablesRaw : JSON.parse(functionInputVariablesRaw)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Custom Function Input Variables: ' + exception)\n            }\n        }\n\n        // Some values might be a stringified JSON, parse it\n        for (const key in inputVars) {\n            let value = inputVars[key]\n            if (typeof value === 'string') {\n                value = handleEscapeCharacters(value, true)\n                if (value.startsWith('{') && value.endsWith('}')) {\n                    try {\n                        value = JSON.parse(value)\n                    } catch (e) {\n                        // ignore\n                    }\n                }\n                inputVars[key] = value\n            }\n        }\n\n        let sandbox: any = { $input: input }\n        sandbox['$vars'] = prepareSandboxVars(variables)\n        sandbox['$flow'] = flow\n\n        if (Object.keys(inputVars).length) {\n            for (const item in inputVars) {\n                sandbox[`$${item}`] = inputVars[item]\n            }\n        }\n\n        const builtinDeps = process.env.TOOL_FUNCTION_BUILTIN_DEP\n            ? defaultAllowBuiltInDep.concat(process.env.TOOL_FUNCTION_BUILTIN_DEP.split(','))\n            : defaultAllowBuiltInDep\n        const externalDeps = process.env.TOOL_FUNCTION_EXTERNAL_DEP ? process.env.TOOL_FUNCTION_EXTERNAL_DEP.split(',') : []\n        const deps = availableDependencies.concat(externalDeps)\n\n        const nodeVMOptions = {\n            console: 'inherit',\n            sandbox,\n            require: {\n                external: { modules: deps },\n                builtin: builtinDeps\n            }\n        } as any\n\n        const vm = new NodeVM(nodeVMOptions)\n        try {\n            const response = await vm.run(`module.exports = async function() {${javascriptFunction}}()`, __dirname)\n\n            if (typeof response === 'string' && !isEndingNode) {\n                return handleEscapeCharacters(response, false)\n            }\n            return response\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n\n    async run(nodeData: INodeData, input: string, options: ICommonObject): Promise<string> {\n        return await this.init(nodeData, input, { ...options, isRun: true })\n    }\n}"
}

## GetVariable_Utilities

{
  "className": "GetVariable_Utilities",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Get Variable'\n        this.name = 'getVariable'\n        this.version = 2.0\n        this.type = 'GetVariable'\n        this.icon = 'getvar.svg'\n        this.category = 'Utilities'\n        this.description = `Get variable that was saved using Set Variable node`\n        this.baseClasses = [this.type, 'Utilities']\n        this.tags = ['Utilities']\n        this.inputs = [\n            {\n                label: 'Variable Name',\n                name: 'variableName',\n                type: 'string',\n                placeholder: 'var1'\n            }",
  "outsideClass_variableName": "const variableName = nodeData.inputs?.variableName as string\n        const dynamicVars = options.dynamicVariables as Record<string, unknown>\n\n        if (Object.prototype.hasOwnProperty.call(dynamicVars, variableName)) {\n            return dynamicVars[variableName]\n        }\n        return undefined\n    }\n}"
}

## IfElseFunction_Utilities

{
  "className": "IfElseFunction_Utilities",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'IfElse Function'\n        this.name = 'ifElseFunction'\n        this.version = 2.0\n        this.type = 'IfElseFunction'\n        this.icon = 'ifelsefunction.svg'\n        this.category = 'Utilities'\n        this.description = `Split flows based on If Else javascript functions`\n        this.baseClasses = [this.type, 'Utilities']\n        this.tags = ['Utilities']\n        this.inputs = [\n            {\n                label: 'Input Variables',\n                name: 'functionInputVariables',\n                description: 'Input variables can be used in the function with prefix $. For example: $var',\n                type: 'json',\n                optional: true,\n                acceptVariable: true,\n                list: true\n            }",
  "if": "if (functionInputVariablesRaw) {\n            try {\n                inputVars =\n                    typeof functionInputVariablesRaw === 'object' ? functionInputVariablesRaw : JSON.parse(functionInputVariablesRaw)\n            }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "for": "for (const item in inputVars) {\n                sandbox[`$${item}",
  "run": "run(`module.exports = async function() {${elseFunction}",
  "outsideClass_ifFunction": "const ifFunction = nodeData.inputs?.ifFunction as string\n        const elseFunction = nodeData.inputs?.elseFunction as string\n        const functionInputVariablesRaw = nodeData.inputs?.functionInputVariables\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n        const variables = await getVars(appDataSource, databaseEntities, nodeData)\n        const flow = {\n            chatflowId: options.chatflowid,\n            sessionId: options.sessionId,\n            chatId: options.chatId,\n            input\n        }\n\n        let inputVars: ICommonObject = {}\n        if (functionInputVariablesRaw) {\n            try {\n                inputVars =\n                    typeof functionInputVariablesRaw === 'object' ? functionInputVariablesRaw : JSON.parse(functionInputVariablesRaw)\n            } catch (exception) {\n                throw new Error(\"Invalid JSON in the IfElse's Input Variables: \" + exception)\n            }\n        }\n\n        // Some values might be a stringified JSON, parse it\n        for (const key in inputVars) {\n            let value = inputVars[key]\n            if (typeof value === 'string') {\n                value = handleEscapeCharacters(value, true)\n                if (value.startsWith('{') && value.endsWith('}')) {\n                    try {\n                        value = JSON.parse(value)\n                    } catch (e) {\n                        // ignore\n                    }\n                }\n                inputVars[key] = value\n            }\n        }\n\n        let sandbox: any = { $input: input }\n        sandbox['$vars'] = prepareSandboxVars(variables)\n        sandbox['$flow'] = flow\n\n        if (Object.keys(inputVars).length) {\n            for (const item in inputVars) {\n                sandbox[`$${item}`] = inputVars[item]\n            }\n        }\n\n        const builtinDeps = process.env.TOOL_FUNCTION_BUILTIN_DEP\n            ? defaultAllowBuiltInDep.concat(process.env.TOOL_FUNCTION_BUILTIN_DEP.split(','))\n            : defaultAllowBuiltInDep\n        const externalDeps = process.env.TOOL_FUNCTION_EXTERNAL_DEP ? process.env.TOOL_FUNCTION_EXTERNAL_DEP.split(',') : []\n        const deps = availableDependencies.concat(externalDeps)\n\n        const nodeVMOptions = {\n            console: 'inherit',\n            sandbox,\n            require: {\n                external: { modules: deps },\n                builtin: builtinDeps\n            }\n        } as any\n\n        const vm = new NodeVM(nodeVMOptions)\n        try {\n            const responseTrue = await vm.run(`module.exports = async function() {${ifFunction}}()`, __dirname)\n            if (responseTrue)\n                return { output: typeof responseTrue === 'string' ? handleEscapeCharacters(responseTrue, false) : responseTrue, type: true }\n\n            const responseFalse = await vm.run(`module.exports = async function() {${elseFunction}}()`, __dirname)\n            return { output: typeof responseFalse === 'string' ? handleEscapeCharacters(responseFalse, false) : responseFalse, type: false }\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}"
}

## SetVariable_Utilities

{
  "className": "SetVariable_Utilities",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Set Variable'\n        this.name = 'setVariable'\n        this.version = 2.0\n        this.type = 'SetVariable'\n        this.icon = 'setvar.svg'\n        this.category = 'Utilities'\n        this.description = `Set variable which can be retrieved at a later stage. Variable is only available during runtime.`\n        this.tags = ['Utilities']\n        this.baseClasses = [this.type, 'Utilities']\n        this.inputs = [\n            {\n                label: 'Input',\n                name: 'input',\n                type: 'string | number | boolean | json | array',\n                optional: true,\n                list: true\n            }",
  "outsideClass_variableName": "const variableName = nodeData.inputs?.variableName as string\n\n        if (Array.isArray(inputRaw) && inputRaw.length === 1) {\n            inputRaw = inputRaw[0]\n        }\n\n        return { output: inputRaw, dynamicVariables: { [variableName]: inputRaw } }\n    }\n}"
}

## StickyNote

{
  "className": "StickyNote",
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Sticky Note'\n        this.name = 'stickyNote'\n        this.version = 2.0\n        this.type = 'StickyNote'\n        this.icon = 'stickyNote.svg'\n        this.category = 'Utilities'\n        this.tags = ['Utilities']\n        this.description = 'Add a sticky note'\n        this.inputs = [\n            {\n                label: '',\n                name: 'note',\n                type: 'string',\n                rows: 1,\n                placeholder: 'Type something here',\n                optional: true\n            }"
}

## Astra_VectorStores

{
  "className": "Astra_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Astra'\n        this.name = 'Astra'\n        this.version = 2.0\n        this.type = 'Astra'\n        this.icon = 'astra.svg'\n        this.category = 'Vector Stores'\n        this.description = `Upsert embedded data and perform similarity or mmr search upon query using DataStax Astra DB, a serverless vector database that’s perfect for managing mission-critical AI workloads`\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['AstraDBApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_docs": "const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const vectorDimension = nodeData.inputs?.vectorDimension as number\n            const astraNamespace = nodeData.inputs?.astraNamespace as string\n            const astraCollection = nodeData.inputs?.astraCollection as string\n            const similarityMetric = nodeData.inputs?.similarityMetric as 'cosine' | 'euclidean' | 'dot_product' | undefined\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n\n            const expectedSimilarityMetric = ['cosine', 'euclidean', 'dot_product']\n            if (similarityMetric && !expectedSimilarityMetric.includes(similarityMetric)) {\n                throw new Error(`Invalid Similarity Metric should be one of 'cosine' | 'euclidean' | 'dot_product'`)\n            }\n\n            const clientConfig = {\n                token: credentialData?.applicationToken,\n                endpoint: credentialData?.dbEndPoint\n            }\n\n            const astraConfig: AstraLibArgs = {\n                ...clientConfig,\n                namespace: astraNamespace ?? 'default_keyspace',\n                collection: astraCollection ?? credentialData.collectionName ?? 'flowise_test',\n                collectionOptions: {\n                    vector: {\n                        dimension: vectorDimension ?? 1536,\n                        metric: similarityMetric ?? 'cosine'\n                    }\n                }\n            }\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                await AstraDBVectorStore.fromDocuments(finalDocs, embeddings, astraConfig)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const vectorDimension = nodeData.inputs?.vectorDimension as number\n        const similarityMetric = nodeData.inputs?.similarityMetric as 'cosine' | 'euclidean' | 'dot_product' | undefined\n        const astraNamespace = nodeData.inputs?.astraNamespace as string\n        const astraCollection = nodeData.inputs?.astraCollection as string\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n\n        const expectedSimilarityMetric = ['cosine', 'euclidean', 'dot_product']\n        if (similarityMetric && !expectedSimilarityMetric.includes(similarityMetric)) {\n            throw new Error(`Invalid Similarity Metric should be one of 'cosine' | 'euclidean' | 'dot_product'`)\n        }\n\n        const clientConfig = {\n            token: credentialData?.applicationToken,\n            endpoint: credentialData?.dbEndPoint\n        }\n\n        const astraConfig: AstraLibArgs = {\n            ...clientConfig,\n            namespace: astraNamespace ?? 'default_keyspace',\n            collection: astraCollection ?? credentialData.collectionName ?? 'flowise_test',\n            collectionOptions: {\n                vector: {\n                    dimension: vectorDimension ?? 1536,\n                    metric: similarityMetric ?? 'cosine'\n                }\n            }\n        }\n\n        const vectorStore = await AstraDBVectorStore.fromExistingIndex(embeddings, astraConfig)\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore)\n    }\n}"
}

## Chroma_VectorStores

{
  "className": "Chroma_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Chroma'\n        this.name = 'chroma'\n        this.version = 2.0\n        this.type = 'Chroma'\n        this.icon = 'chroma.svg'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data and perform similarity search upon query using Chroma, an open-source embedding database'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Only needed if you have chroma on cloud services with X-Api-key',\n            optional: true,\n            credentialNames: ['chromaApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "if": "if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (chromaMetadataFilter) {\n                ;(vectorStore as any).filter = obj.filter\n            }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_collectionName": "const collectionName = nodeData.inputs?.collectionName as string\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const chromaURL = nodeData.inputs?.chromaURL as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const chromaApiKey = getCredentialParam('chromaApiKey', credentialData, nodeData)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const obj: {\n                collectionName: string\n                url?: string\n                chromaApiKey?: string\n            } = { collectionName }\n            if (chromaURL) obj.url = chromaURL\n            if (chromaApiKey) obj.chromaApiKey = chromaApiKey\n\n            try {\n                if (recordManager) {\n                    const vectorStore = await ChromaExtended.fromExistingCollection(embeddings, obj)\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: collectionName\n                        }\n                    })\n                    return res\n                } else {\n                    await ChromaExtended.fromDocuments(finalDocs, embeddings, obj)\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const collectionName = nodeData.inputs?.collectionName as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const chromaURL = nodeData.inputs?.chromaURL as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const chromaApiKey = getCredentialParam('chromaApiKey', credentialData, nodeData)\n\n            const obj: {\n                collectionName: string\n                url?: string\n                chromaApiKey?: string\n            } = { collectionName }\n            if (chromaURL) obj.url = chromaURL\n            if (chromaApiKey) obj.chromaApiKey = chromaApiKey\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = collectionName\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    const chromaStore = new ChromaExtended(embeddings, obj)\n\n                    await chromaStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    const chromaStore = new ChromaExtended(embeddings, obj)\n                    await chromaStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const collectionName = nodeData.inputs?.collectionName as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const chromaURL = nodeData.inputs?.chromaURL as string\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const chromaApiKey = getCredentialParam('chromaApiKey', credentialData, nodeData)\n\n        const chromaMetadataFilter = nodeData.inputs?.chromaMetadataFilter\n\n        const obj: {\n            collectionName: string\n            url?: string\n            chromaApiKey?: string\n            filter?: object | undefined\n        } = { collectionName }\n        if (chromaURL) obj.url = chromaURL\n        if (chromaApiKey) obj.chromaApiKey = chromaApiKey\n        if (chromaMetadataFilter) {\n            const metadatafilter = typeof chromaMetadataFilter === 'object' ? chromaMetadataFilter : JSON.parse(chromaMetadataFilter)\n            obj.filter = metadatafilter\n        }\n\n        const vectorStore = await ChromaExtended.fromExistingCollection(embeddings, obj)\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (chromaMetadataFilter) {\n                ;(vectorStore as any).filter = obj.filter\n            }\n            return vectorStore\n        }\n        return vectorStore\n    }\n}"
}

## DocStore_VectorStores

{
  "className": "DocStore_VectorStores",
  "loadMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Document Store (Vector)'\n        this.name = 'documentStoreVS'\n        this.version = 1.0\n        this.type = 'DocumentStoreVS'\n        this.icon = 'dstore.svg'\n        this.badge = 'New'\n        this.category = 'Vector Stores'\n        this.description = `Search and retrieve documents from Document Store`\n        this.baseClasses = [this.type]\n        this.inputs = [\n            {\n                label: 'Select Store',\n                name: 'selectedStore',\n                type: 'asyncOptions',\n                loadMethod: 'listStores'\n            }",
  "if": "if (embeddingObj) {\n        vStoreNodeData.inputs.embeddings = embeddingObj\n    }",
  "for": "for (const store of stores) {\n                if (store.status === 'UPSERTED') {\n                    const obj = {\n                        name: store.id,\n                        label: store.name,\n                        description: store.description\n                    }",
  "outsideClass_appDataSource": "const appDataSource = options.appDataSource as DataSource\n            const databaseEntities = options.databaseEntities as IDatabaseEntity\n\n            if (appDataSource === undefined || !appDataSource) {\n                return returnData\n            }\n\n            const stores = await appDataSource.getRepository(databaseEntities['DocumentStore']).find()\n            for (const store of stores) {\n                if (store.status === 'UPSERTED') {\n                    const obj = {\n                        name: store.id,\n                        label: store.name,\n                        description: store.description\n                    }\n                    returnData.push(obj)\n                }\n            }\n            return returnData\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const selectedStore = nodeData.inputs?.selectedStore as string\n        const appDataSource = options.appDataSource as DataSource\n        const databaseEntities = options.databaseEntities as IDatabaseEntity\n        const output = nodeData.outputs?.output as string\n\n        const entity = await appDataSource.getRepository(databaseEntities['DocumentStore']).findOneBy({ id: selectedStore })\n        if (!entity) {\n            return { error: 'Store not found' }\n        }\n        const data: ICommonObject = {}\n        data.output = output\n\n        // Prepare Embeddings Instance\n        const embeddingConfig = JSON.parse(entity.embeddingConfig)\n        data.embeddingName = embeddingConfig.name\n        data.embeddingConfig = embeddingConfig.config\n        let embeddingObj = await _createEmbeddingsObject(options.componentNodes, data, options)\n        if (!embeddingObj) {\n            return { error: 'Failed to create EmbeddingObj' }\n        }\n\n        // Prepare Vector Store Instance\n        const vsConfig = JSON.parse(entity.vectorStoreConfig)\n        data.vectorStoreName = vsConfig.name\n        data.vectorStoreConfig = vsConfig.config\n        if (data.inputs) {\n            data.vectorStoreConfig = { ...vsConfig.config, ...data.inputs }\n        }\n\n        // Prepare Vector Store Node Data\n        const vStoreNodeData = _createVectorStoreNodeData(options.componentNodes, data, embeddingObj)\n\n        // Finally create the Vector Store or Retriever object (data.output)\n        const vectorStoreObj = await _createVectorStoreObject(options.componentNodes, data)\n        const retrieverOrVectorStore = await vectorStoreObj.init(vStoreNodeData, '', options)\n        if (!retrieverOrVectorStore) {\n            return { error: 'Failed to create vectorStore' }\n        }\n        return retrieverOrVectorStore\n    }\n}\n\nconst _createEmbeddingsObject = async (componentNodes: ICommonObject, data: ICommonObject, options: ICommonObject): Promise<any> => {\n    // prepare embedding node data\n    const embeddingComponent = componentNodes[data.embeddingName]\n    const embeddingNodeData: any = {\n        inputs: { ...data.embeddingConfig },\n        outputs: { output: 'document' },\n        id: `${embeddingComponent.name}_0`,\n        label: embeddingComponent.label,\n        name: embeddingComponent.name,\n        category: embeddingComponent.category,\n        inputParams: embeddingComponent.inputs || []\n    }\n    if (data.embeddingConfig.credential) {\n        embeddingNodeData.credential = data.embeddingConfig.credential\n    }\n\n    // init embedding object\n    const embeddingNodeInstanceFilePath = embeddingComponent.filePath as string\n    const embeddingNodeModule = await import(embeddingNodeInstanceFilePath)\n    const embeddingNodeInstance = new embeddingNodeModule.nodeClass()\n    return await embeddingNodeInstance.init(embeddingNodeData, '', options)\n}\n\nconst _createVectorStoreNodeData = (componentNodes: ICommonObject, data: ICommonObject, embeddingObj: any) => {\n    const vectorStoreComponent = componentNodes[data.vectorStoreName]\n    const vStoreNodeData: any = {\n        id: `${vectorStoreComponent.name}_0`,\n        inputs: { ...data.vectorStoreConfig },\n        outputs: { output: data.output },\n        label: vectorStoreComponent.label,\n        name: vectorStoreComponent.name,\n        category: vectorStoreComponent.category\n    }\n    if (data.vectorStoreConfig.credential) {\n        vStoreNodeData.credential = data.vectorStoreConfig.credential\n    }\n\n    if (embeddingObj) {\n        vStoreNodeData.inputs.embeddings = embeddingObj\n    }\n\n    // Get all input params except the ones that are anchor points to avoid JSON stringify circular error\n    const filterInputParams = ['document', 'embeddings', 'recordManager']\n    const inputParams = vectorStoreComponent.inputs?.filter((input: any) => !filterInputParams.includes(input.name))\n    vStoreNodeData.inputParams = inputParams\n    return vStoreNodeData\n}\n\nconst _createVectorStoreObject = async (componentNodes: ICommonObject, data: ICommonObject) => {\n    const vStoreNodeInstanceFilePath = componentNodes[data.vectorStoreName].filePath as string\n    const vStoreNodeModule = await import(vStoreNodeInstanceFilePath)\n    const vStoreNodeInstance = new vStoreNodeModule.nodeClass()\n    return vStoreNodeInstance\n}"
}

## Elasticsearch_VectorStores

{
  "className": "Elasticsearch_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Elasticsearch'\n        this.name = 'elasticsearch'\n        this.version = 2.0\n        this.description =\n            'Upsert embedded data and perform similarity search upon query using Elasticsearch, a distributed search and analytics engine'\n        this.type = 'Elasticsearch'\n        this.icon = 'elasticsearch.png'\n        this.category = 'Vector Stores'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['elasticsearchApi', 'elasticSearchUserPassword']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "if": "if (cloudId) {\n        let username = getCredentialParam('username', credentialData, nodeData)\n        let password = getCredentialParam('password', credentialData, nodeData)\n        if (cloudId.startsWith('http')) {\n            elasticSearchClientOptions = {\n                node: cloudId,\n                auth: {\n                    username: username,\n                    password: password\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "switch": "switch (similarityMeasure) {\n        case 'dot_product':\n            vectorSearchOptions = {\n                similarity: 'dot_product'\n            }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const endPoint = getCredentialParam('endpoint', credentialData, nodeData)\n            const cloudId = getCredentialParam('cloudId', credentialData, nodeData)\n            const indexName = nodeData.inputs?.indexName as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const similarityMeasure = nodeData.inputs?.similarityMeasure as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            const docs = nodeData.inputs?.document as Document[]\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            // The following code is a workaround for a bug (Langchain Issue #1589) in the underlying library.\n            // Store does not support object in metadata and fail silently\n            finalDocs.forEach((d) => {\n                delete d.metadata.pdf\n                delete d.metadata.loc\n            })\n            // end of workaround\n\n            const elasticSearchClientArgs = prepareClientArgs(endPoint, cloudId, credentialData, nodeData, similarityMeasure, indexName)\n            const vectorStore = new ElasticVectorSearch(embeddings, elasticSearchClientArgs)\n\n            try {\n                if (recordManager) {\n                    const vectorStore = await ElasticVectorSearch.fromExistingIndex(embeddings, elasticSearchClientArgs)\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: indexName\n                        }\n                    })\n                    return res\n                } else {\n                    await vectorStore.addDocuments(finalDocs)\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const indexName = nodeData.inputs?.indexName as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const similarityMeasure = nodeData.inputs?.similarityMeasure as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const endPoint = getCredentialParam('endpoint', credentialData, nodeData)\n            const cloudId = getCredentialParam('cloudId', credentialData, nodeData)\n\n            const elasticSearchClientArgs = prepareClientArgs(endPoint, cloudId, credentialData, nodeData, similarityMeasure, indexName)\n            const vectorStore = new ElasticVectorSearch(embeddings, elasticSearchClientArgs)\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = indexName\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await vectorStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await vectorStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const endPoint = getCredentialParam('endpoint', credentialData, nodeData)\n        const cloudId = getCredentialParam('cloudId', credentialData, nodeData)\n        const indexName = nodeData.inputs?.indexName as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const topK = nodeData.inputs?.topK as string\n        const similarityMeasure = nodeData.inputs?.similarityMeasure as string\n        const k = topK ? parseFloat(topK) : 4\n        const output = nodeData.outputs?.output as string\n\n        const elasticSearchClientArgs = prepareClientArgs(endPoint, cloudId, credentialData, nodeData, similarityMeasure, indexName)\n        const vectorStore = await ElasticVectorSearch.fromExistingIndex(embeddings, elasticSearchClientArgs)\n\n        if (output === 'retriever') {\n            return vectorStore.asRetriever(k)\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst prepareConnectionOptions = (\n    endPoint: string | undefined,\n    cloudId: string | undefined,\n    credentialData: ICommonObject,\n    nodeData: INodeData\n) => {\n    let elasticSearchClientOptions: ClientOptions = {}\n    if (endPoint) {\n        let apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n        elasticSearchClientOptions = {\n            node: endPoint,\n            auth: {\n                apiKey: apiKey\n            }\n        }\n    } else if (cloudId) {\n        let username = getCredentialParam('username', credentialData, nodeData)\n        let password = getCredentialParam('password', credentialData, nodeData)\n        if (cloudId.startsWith('http')) {\n            elasticSearchClientOptions = {\n                node: cloudId,\n                auth: {\n                    username: username,\n                    password: password\n                },\n                tls: {\n                    rejectUnauthorized: false\n                }\n            }\n        } else {\n            elasticSearchClientOptions = {\n                cloud: {\n                    id: cloudId\n                },\n                auth: {\n                    username: username,\n                    password: password\n                }\n            }\n        }\n    }\n    return elasticSearchClientOptions\n}\n\nconst prepareClientArgs = (\n    endPoint: string | undefined,\n    cloudId: string | undefined,\n    credentialData: ICommonObject,\n    nodeData: INodeData,\n    similarityMeasure: string,\n    indexName: string\n) => {\n    let elasticSearchClientOptions = prepareConnectionOptions(endPoint, cloudId, credentialData, nodeData)\n    let vectorSearchOptions = {}\n    switch (similarityMeasure) {\n        case 'dot_product':\n            vectorSearchOptions = {\n                similarity: 'dot_product'\n            }\n            break\n        case 'cosine':\n            vectorSearchOptions = {\n                similarity: 'cosine'\n            }\n            break\n        default:\n            vectorSearchOptions = {\n                similarity: 'l2_norm'\n            }\n    }\n    const elasticSearchClientArgs: ElasticClientArgs = {\n        client: new Client(elasticSearchClientOptions),\n        indexName: indexName,\n        vectorSearchOptions: vectorSearchOptions\n    }\n    return elasticSearchClientArgs\n}"
}

## Faiss_VectorStores

{
  "className": "Faiss_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Faiss'\n        this.name = 'faiss'\n        this.version = 1.0\n        this.type = 'Faiss'\n        this.icon = 'faiss.svg'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data and perform similarity search upon query using Faiss library from Meta'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Document',\n                name: 'document',\n                type: 'Document',\n                list: true,\n                optional: true\n            }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }",
  "outsideClass_docs": "const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const basePath = nodeData.inputs?.basePath as string\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                const vectorStore = await FaissStore.fromDocuments(finalDocs, embeddings)\n                await vectorStore.save(basePath)\n\n                // Avoid illegal invocation error\n                vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number) => {\n                    return await similaritySearchVectorWithScore(query, k, vectorStore)\n                }\n\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData): Promise<any> {\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const basePath = nodeData.inputs?.basePath as string\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const vectorStore = await FaissStore.load(basePath, embeddings)\n\n        // Avoid illegal invocation error\n        vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number) => {\n            return await similaritySearchVectorWithScore(query, k, vectorStore)\n        }\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst similaritySearchVectorWithScore = async (query: number[], k: number, vectorStore: FaissStore) => {\n    const index = vectorStore.index\n\n    if (k > index.ntotal()) {\n        const total = index.ntotal()\n        console.warn(`k (${k}) is greater than the number of elements in the index (${total}), setting k to ${total}`)\n        k = total\n    }\n\n    const result = index.search(query, k)\n    return result.labels.map((id, index) => {\n        const uuid = vectorStore._mapping[id]\n        return [vectorStore.docstore.search(uuid), result.distances[index]] as [Document, number]\n    })\n}"
}

## InMemoryVectorStore_VectorStores

{
  "className": "InMemoryVectorStore_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'In-Memory Vector Store'\n        this.name = 'memoryVectorStore'\n        this.version = 1.0\n        this.type = 'Memory'\n        this.icon = 'memory.svg'\n        this.category = 'Vector Stores'\n        this.description = 'In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.inputs = [\n            {\n                label: 'Document',\n                name: 'document',\n                type: 'Document',\n                list: true,\n                optional: true\n            }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n            if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                finalDocs.push(new Document(flattenDocs[i]))\n            }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }",
  "outsideClass_docs": "const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                await MemoryVectorStore.fromDocuments(finalDocs, embeddings)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData): Promise<any> {\n        const docs = nodeData.inputs?.document as Document[]\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const flattenDocs = docs && docs.length ? flatten(docs) : []\n        const finalDocs = []\n        for (let i = 0; i < flattenDocs.length; i += 1) {\n            if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                finalDocs.push(new Document(flattenDocs[i]))\n            }\n        }\n\n        const vectorStore = await MemoryVectorStore.fromDocuments(finalDocs, embeddings)\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}"
}

## MeilisearchRetriever_node

{
  "className": "MeilisearchRetriever_node",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Meilisearch'\n        this.name = 'meilisearch'\n        this.version = 1.0\n        this.type = 'Meilisearch'\n        this.icon = 'Meilisearch.png'\n        this.category = 'Vector Stores'\n        this.badge = 'NEW'\n        this.description = `Upsert embedded data and perform similarity search upon query using Meilisearch hybrid search functionality`\n        this.baseClasses = ['BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['meilisearchApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const uniqueId = uuidv4()\n                    const { pageContent, metadata }",
  "if": "if (vectorStoreEnabled !== true) {\n                throw new Error('Failed to enable vectorStore, vectorStrore property returned is not true')\n            }",
  "catch": "catch (error) {\n            console.error('Error enabling vectorStore feature:', error)\n        }",
  "while": "while (AddTaskStatus.status !== 'succeeded') {\n                    AddTaskStatus = await client.getTask(taskUid_created)\n                    if (AddTaskStatus.error !== null || AddTaskStatus.status === 'failed') {\n                        throw new Error('Error during documents adding task: ' + AddTaskStatus.error)\n                    }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const meilisearchAdminApiKey = getCredentialParam('meilisearchAdminApiKey', credentialData, nodeData)\n            const docs = nodeData.inputs?.document as Document[]\n            const host = nodeData.inputs?.host as string\n            const indexUid = nodeData.inputs?.indexUid as string\n            const deleteIndex = nodeData.inputs?.deleteIndex as boolean\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            let embeddingDimension: number = 384\n            const client = new Meilisearch({\n                host: host,\n                apiKey: meilisearchAdminApiKey\n            })\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const uniqueId = uuidv4()\n                    const { pageContent, metadata } = flattenDocs[i]\n                    const docEmbedding = await embeddings.embedQuery(pageContent)\n                    embeddingDimension = docEmbedding.length\n                    const documentForIndexing = {\n                        pageContent,\n                        metadata,\n                        objectID: uniqueId,\n                        _vectors: {\n                            ollama: {\n                                embeddings: docEmbedding,\n                                regenerate: false\n                            }\n                        }\n                    }\n                    finalDocs.push(documentForIndexing)\n                }\n            }\n            let taskUid_created: number = 0\n\n            if (deleteIndex) {\n                try {\n                    const deleteResponse = await client.deleteIndex(indexUid)\n                    taskUid_created = deleteResponse.taskUid\n                    let deleteTaskStatus = await client.getTask(taskUid_created)\n\n                    while (deleteTaskStatus.status !== 'succeeded') {\n                        deleteTaskStatus = await client.getTask(taskUid_created)\n                        if (deleteTaskStatus.error !== null || deleteTaskStatus.status === 'failed') {\n                            throw new Error('Error during index deletion task: ' + deleteTaskStatus.error)\n                        }\n                    }\n                } catch (error) {\n                    console.error(error)\n                    console.warn('Error occured when deleting your index, if it did not exist, we will create one for you... ')\n                }\n            }\n\n            let index: any\n\n            try {\n                index = await client.getIndex(indexUid)\n            } catch (error) {\n                console.warn('Index not found, creating a new index...')\n\n                try {\n                    const createResponse = await client.createIndex(indexUid, { primaryKey: 'objectID' })\n                    taskUid_created = createResponse.taskUid\n                    let createTaskStatus = await client.getTask(taskUid_created)\n\n                    while (createTaskStatus.status !== 'succeeded') {\n                        createTaskStatus = await client.getTask(taskUid_created)\n                        if (createTaskStatus.error !== null || createTaskStatus.status === 'failed') {\n                            throw new Error('Error during index creation task: ' + createTaskStatus.error)\n                        }\n                    }\n                    index = await client.getIndex(indexUid)\n                } catch (taskError) {\n                    console.error('Error during index creation process:', taskError)\n                }\n            }\n\n            try {\n                await index.updateFilterableAttributes(['metadata'])\n                await index.updateSettings({\n                    embedders: {\n                        ollama: {\n                            source: 'userProvided',\n                            dimensions: embeddingDimension\n                        }\n                    }\n                })\n                const addResponse = await index.addDocuments(finalDocs)\n                taskUid_created = addResponse.taskUid\n                let AddTaskStatus = await client.getTask(taskUid_created)\n                while (AddTaskStatus.status !== 'succeeded') {\n                    AddTaskStatus = await client.getTask(taskUid_created)\n                    if (AddTaskStatus.error !== null || AddTaskStatus.status === 'failed') {\n                        throw new Error('Error during documents adding task: ' + AddTaskStatus.error)\n                    }\n                }\n                index = await client.getIndex(indexUid)\n            } catch (error) {\n                console.error('Error occurred while adding documents:', error)\n            }\n            return { numAdded: finalDocs.length, addedDocs: finalDocs }\n        }\n    }\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const meilisearchSearchApiKey = getCredentialParam('meilisearchSearchApiKey', credentialData, nodeData)\n        const meilisearchAdminApiKey = getCredentialParam('meilisearchAdminApiKey', credentialData, nodeData)\n        const host = nodeData.inputs?.host as string\n        const indexUid = nodeData.inputs?.indexUid as string\n        const K = nodeData.inputs?.K as string\n        const semanticRatio = nodeData.inputs?.semanticRatio as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const searchFilter = nodeData.inputs?.searchFilter as string\n\n        const experimentalEndpoint = host + '/experimental-features/'\n        const token = meilisearchAdminApiKey\n\n        const experimentalOptions = {\n            method: 'PATCH',\n            headers: {\n                'Content-Type': 'application/json',\n                Authorization: `Bearer ${token}`\n            },\n            body: JSON.stringify({\n                vectorStore: true\n            })\n        }\n\n        try {\n            const response = await fetch(experimentalEndpoint, experimentalOptions)\n            if (!response.ok) {\n                throw new Error(`Failed to enable vectorStore: ${response.statusText}`)\n            }\n\n            const data = await response.json()\n\n            const vectorStoreEnabled = data.vectorStore\n            if (vectorStoreEnabled !== true) {\n                throw new Error('Failed to enable vectorStore, vectorStrore property returned is not true')\n            }\n        } catch (error) {\n            console.error('Error enabling vectorStore feature:', error)\n        }\n\n        const hybridsearchretriever = new MeilisearchRetriever(\n            host,\n            meilisearchSearchApiKey,\n            indexUid,\n            K,\n            semanticRatio,\n            embeddings,\n            searchFilter\n        )\n        return hybridsearchretriever\n    }\n}"
}

## Milvus_VectorStores

{
  "className": "Milvus_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Milvus'\n        this.name = 'milvus'\n        this.version = 2.1\n        this.type = 'Milvus'\n        this.icon = 'milvus.svg'\n        this.category = 'Vector Stores'\n        this.description = `Upsert embedded data and perform similarity search upon query using Milvus, world's most advanced open-source vector database`\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            optional: true,\n            credentialNames: ['milvusAuth']\n        }",
  "if": "if (insertResp.status.error_code !== ErrorCode.SUCCESS) {\n            throw new Error(`Error inserting data: ${JSON.stringify(insertResp)}",
  "for": "for (let index = 0; index < vectors.length; index++) {\n            const vec = vectors[index]\n            const doc = documents[index]\n            const data: InsertRow = {\n                [this.textField]: doc.pageContent,\n                [this.vectorField]: vec\n            }",
  "catch": "catch (e) {\n        return { isJson: false, obj: null }",
  "switch": "switch (field) {\n                    case this.primaryField:\n                        if (!this.autoId) {\n                            if (doc.metadata[this.primaryField] === undefined) {\n                                throw new Error(\n                                    `The Collection's primaryField is configured with autoId=false, thus its value must be provided through metadata.`\n                                )\n                            }",
  "outsideClass_address": "const address = nodeData.inputs?.milvusServerUrl as string\n            const collectionName = nodeData.inputs?.milvusCollection as string\n\n            // embeddings\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n            // credential\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const milvusUser = getCredentialParam('milvusUser', credentialData, nodeData)\n            const milvusPassword = getCredentialParam('milvusPassword', credentialData, nodeData)\n\n            // tls\n            const secure = nodeData.inputs?.secure as boolean\n            const clientPemPath = nodeData.inputs?.clientPemPath as string\n            const clientKeyPath = nodeData.inputs?.clientKeyPath as string\n            const caPemPath = nodeData.inputs?.caPemPath as string\n            const serverName = nodeData.inputs?.serverName as string\n\n            // partition\n            const partitionName = nodeData.inputs?.milvusPartition ?? '_default'\n\n            // init MilvusLibArgs\n            const milVusArgs: MilvusLibArgs = {\n                url: address,\n                collectionName: collectionName,\n                partitionName: partitionName\n            }\n\n            if (secure) {\n                milVusArgs.clientConfig = {\n                    address: address,\n                    ssl: secure,\n                    tls: {\n                        rootCertPath: caPemPath,\n                        certChainPath: clientPemPath,\n                        privateKeyPath: clientKeyPath,\n                        serverName: serverName\n                    }\n                }\n            }\n\n            if (milvusUser) milVusArgs.username = milvusUser\n            if (milvusPassword) milVusArgs.password = milvusPassword\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }\n                    }\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                const vectorStore = await MilvusUpsert.fromDocuments(finalDocs, embeddings, milVusArgs)\n\n                // Avoid Illegal Invocation\n                vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: string) => {\n                    return await similaritySearchVectorWithScore(query, k, vectorStore, undefined, filter)\n                }\n\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        // server setup\n        const address = nodeData.inputs?.milvusServerUrl as string\n        const collectionName = nodeData.inputs?.milvusCollection as string\n        const _milvusFilter = nodeData.inputs?.milvusFilter as string\n        const textField = nodeData.inputs?.milvusTextField as string\n        const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n        // embeddings\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const topK = nodeData.inputs?.topK as string\n\n        // output\n        const output = nodeData.outputs?.output as string\n\n        // format data\n        const k = topK ? parseFloat(topK) : 4\n\n        // credential\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const milvusUser = getCredentialParam('milvusUser', credentialData, nodeData)\n        const milvusPassword = getCredentialParam('milvusPassword', credentialData, nodeData)\n\n        // tls\n        const secure = nodeData.inputs?.secure as boolean\n        const clientPemPath = nodeData.inputs?.clientPemPath as string\n        const clientKeyPath = nodeData.inputs?.clientKeyPath as string\n        const caPemPath = nodeData.inputs?.caPemPath as string\n        const serverName = nodeData.inputs?.serverName as string\n\n        // partition\n        const partitionName = nodeData.inputs?.milvusPartition ?? '_default'\n\n        // init MilvusLibArgs\n        const milVusArgs: MilvusLibArgs = {\n            url: address,\n            collectionName: collectionName,\n            partitionName: partitionName,\n            textField: textField\n        }\n\n        if (secure) {\n            milVusArgs.clientConfig = {\n                address: address,\n                ssl: secure,\n                tls: {\n                    rootCertPath: caPemPath,\n                    certChainPath: clientPemPath,\n                    privateKeyPath: clientKeyPath,\n                    serverName: serverName\n                }\n            }\n        }\n\n        if (milvusUser) milVusArgs.username = milvusUser\n        if (milvusPassword) milVusArgs.password = milvusPassword\n\n        let milvusFilter = _milvusFilter\n        if (isFileUploadEnabled && options.chatId) {\n            if (milvusFilter) milvusFilter += ` OR ${FLOWISE_CHATID} == \"${options.chatId}\" OR NOT EXISTS(${FLOWISE_CHATID})`\n            else milvusFilter = `${FLOWISE_CHATID} == \"${options.chatId}\" OR NOT EXISTS(${FLOWISE_CHATID})`\n        }\n\n        const vectorStore = await Milvus.fromExistingCollection(embeddings, milVusArgs)\n\n        // Avoid Illegal Invocation\n        vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: string) => {\n            return await similaritySearchVectorWithScore(query, k, vectorStore, milvusFilter, filter)\n        }\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (milvusFilter) {\n                ;(vectorStore as any).filter = milvusFilter\n            }\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst checkJsonString = (value: string): { isJson: boolean; obj: any } => {\n    try {\n        const result = JSON.parse(value)\n        return { isJson: true, obj: result }\n    } catch (e) {\n        return { isJson: false, obj: null }\n    }\n}\n\nconst similaritySearchVectorWithScore = async (query: number[], k: number, vectorStore: Milvus, milvusFilter?: string, filter?: string) => {\n    const hasColResp = await vectorStore.client.hasCollection({\n        collection_name: vectorStore.collectionName\n    })\n    if (hasColResp.status.error_code !== ErrorCode.SUCCESS) {\n        throw new Error(`Error checking collection: ${hasColResp}`)\n    }\n    if (hasColResp.value === false) {\n        throw new Error(`Collection not found: ${vectorStore.collectionName}, please create collection before search.`)\n    }\n\n    const filterStr = milvusFilter ?? filter ?? ''\n\n    await vectorStore.grabCollectionFields()\n\n    const loadResp = await vectorStore.client.loadCollectionSync({\n        collection_name: vectorStore.collectionName\n    })\n\n    if (loadResp.error_code !== ErrorCode.SUCCESS) {\n        throw new Error(`Error loading collection: ${loadResp}`)\n    }\n\n    const outputFields = vectorStore.fields.filter((field) => field !== vectorStore.vectorField)\n\n    const search_params: any = {\n        anns_field: vectorStore.vectorField,\n        topk: k.toString(),\n        metric_type: vectorStore.indexCreateParams.metric_type,\n        params: vectorStore.indexSearchParams\n    }\n    const searchResp = await vectorStore.client.search({\n        collection_name: vectorStore.collectionName,\n        search_params,\n        output_fields: outputFields,\n        vector_type: DataType.FloatVector,\n        vectors: [query],\n        filter: filterStr\n    })\n    if (searchResp.status.error_code !== ErrorCode.SUCCESS) {\n        throw new Error(`Error searching data: ${JSON.stringify(searchResp)}`)\n    }\n    const results: [Document, number][] = []\n    searchResp.results.forEach((result) => {\n        const fields = {\n            pageContent: '',\n            metadata: {} as Record<string, any>\n        }\n        Object.keys(result).forEach((key) => {\n            if (key === vectorStore.textField) {\n                fields.pageContent = result[key]\n            } else if (vectorStore.fields.includes(key) || key === vectorStore.primaryField) {\n                if (typeof result[key] === 'string') {\n                    const { isJson, obj } = checkJsonString(result[key])\n                    fields.metadata[key] = isJson ? obj : result[key]\n                } else {\n                    fields.metadata[key] = result[key]\n                }\n            }\n        })\n        results.push([new Document(fields), result.score])\n    })\n    return results\n}",
  "outsideClass_vec": "const vec = vectors[index]\n            const doc = documents[index]\n            const data: InsertRow = {\n                [this.textField]: doc.pageContent,\n                [this.vectorField]: vec\n            }\n            this.fields.forEach((field) => {\n                switch (field) {\n                    case this.primaryField:\n                        if (!this.autoId) {\n                            if (doc.metadata[this.primaryField] === undefined) {\n                                throw new Error(\n                                    `The Collection's primaryField is configured with autoId=false, thus its value must be provided through metadata.`\n                                )\n                            }\n                            data[field] = doc.metadata[this.primaryField]\n                        }\n                        break\n                    case this.textField:\n                        data[field] = doc.pageContent\n                        break\n                    case this.vectorField:\n                        data[field] = vec\n                        break\n                    default: // metadata fields\n                        if (doc.metadata[field] === undefined) {\n                            throw new Error(`The field \"${field}\" is not provided in documents[${index}].metadata.`)\n                        } else if (typeof doc.metadata[field] === 'object') {\n                            data[field] = JSON.stringify(doc.metadata[field])\n                        } else {\n                            data[field] = doc.metadata[field]\n                        }\n                        break\n                }\n            })\n\n            insertDatas.push(data)\n        }\n\n        const descIndexResp = await this.client.describeIndex({\n            collection_name: this.collectionName\n        })\n\n        if (descIndexResp.status.error_code === ErrorCode.IndexNotExist) {\n            const resp = await this.client.createIndex({\n                collection_name: this.collectionName,\n                field_name: this.vectorField,\n                index_name: `myindex_${Date.now().toString()}`,\n                index_type: IndexType.AUTOINDEX,\n                metric_type: MetricType.L2\n            })\n            if (resp.error_code !== ErrorCode.SUCCESS) {\n                throw new Error(`Error creating index`)\n            }\n        }\n\n        const insertResp = await this.client.insert({\n            collection_name: this.collectionName,\n            fields_data: insertDatas\n        })\n\n        if (insertResp.status.error_code !== ErrorCode.SUCCESS) {\n            throw new Error(`Error inserting data: ${JSON.stringify(insertResp)}`)\n        }\n\n        await this.client.flushSync({ collection_names: [this.collectionName] })\n    }\n}"
}

## MongoDBAtlas_VectorStores

{
  "className": "MongoDBAtlas_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'MongoDB Atlas'\n        this.name = 'mongoDBAtlas'\n        this.version = 1.0\n        this.description = `Upsert embedded data and perform similarity or mmr search upon query using MongoDB Atlas, a managed cloud mongodb database`\n        this.type = 'MongoDB Atlas'\n        this.icon = 'mongodb.svg'\n        this.category = 'Vector Stores'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['mongoDBUrlApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const document = new Document(flattenDocs[i])\n                    finalDocs.push(document)\n                }",
  "catch": "catch (e) {\n            throw new Error(e)\n        }",
  "if": "if (mongoClientSingleton && newMongoUrl !== mongoUrl) {\n        // if client exists but url changed\n        mongoClientSingleton.close()\n        mongoClientSingleton = new MongoClient(newMongoUrl, { driverInfo }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const databaseName = nodeData.inputs?.databaseName as string\n            const collectionName = nodeData.inputs?.collectionName as string\n            const indexName = nodeData.inputs?.indexName as string\n            let textKey = nodeData.inputs?.textKey as string\n            let embeddingKey = nodeData.inputs?.embeddingKey as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n            let mongoDBConnectUrl = getCredentialParam('mongoDBConnectUrl', credentialData, nodeData)\n\n            const docs = nodeData.inputs?.document as Document[]\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const document = new Document(flattenDocs[i])\n                    finalDocs.push(document)\n                }\n            }\n\n            const mongoClient = await getMongoClient(mongoDBConnectUrl)\n            try {\n                const collection = mongoClient.db(databaseName).collection(collectionName)\n\n                if (!textKey || textKey === '') textKey = 'text'\n                if (!embeddingKey || embeddingKey === '') embeddingKey = 'embedding'\n\n                const mongoDBAtlasVectorSearch = new MongoDBAtlasVectorSearch(embeddings, {\n                    collection,\n                    indexName,\n                    textKey,\n                    embeddingKey\n                })\n                await mongoDBAtlasVectorSearch.addDocuments(finalDocs)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const databaseName = nodeData.inputs?.databaseName as string\n        const collectionName = nodeData.inputs?.collectionName as string\n        const indexName = nodeData.inputs?.indexName as string\n        let textKey = nodeData.inputs?.textKey as string\n        let embeddingKey = nodeData.inputs?.embeddingKey as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n        let mongoDBConnectUrl = getCredentialParam('mongoDBConnectUrl', credentialData, nodeData)\n\n        const mongoClient = await getMongoClient(mongoDBConnectUrl)\n        try {\n            const collection = mongoClient.db(databaseName).collection(collectionName)\n\n            if (!textKey || textKey === '') textKey = 'text'\n            if (!embeddingKey || embeddingKey === '') embeddingKey = 'embedding'\n\n            const vectorStore = new MongoDBAtlasVectorSearch(embeddings, {\n                collection,\n                indexName,\n                textKey,\n                embeddingKey\n            }) as unknown as VectorStore\n\n            return resolveVectorStoreOrRetriever(nodeData, vectorStore)\n        } catch (e) {\n            throw new Error(e)\n        }\n    }\n}\n\nlet mongoClientSingleton: MongoClient\nlet mongoUrl: string\n\nconst getMongoClient = async (newMongoUrl: string) => {\n    const driverInfo = { name: 'Flowise', version: (await getVersion()).version }\n\n    if (!mongoClientSingleton) {\n        // if client does not exist\n        mongoClientSingleton = new MongoClient(newMongoUrl, { driverInfo })\n        mongoUrl = newMongoUrl\n        return mongoClientSingleton\n    } else if (mongoClientSingleton && newMongoUrl !== mongoUrl) {\n        // if client exists but url changed\n        mongoClientSingleton.close()\n        mongoClientSingleton = new MongoClient(newMongoUrl, { driverInfo })\n        mongoUrl = newMongoUrl\n        return mongoClientSingleton\n    }\n    return mongoClientSingleton\n}"
}

## OpenSearch_VectorStores

{
  "className": "OpenSearch_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'OpenSearch'\n        this.name = 'openSearch'\n        this.version = 3.0\n        this.type = 'OpenSearch'\n        this.icon = 'opensearch.svg'\n        this.category = 'Vector Stores'\n        this.description = `Upsert embedded data and perform similarity search upon query using OpenSearch, an open-source, all-in-one vector database`\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['openSearchUrl']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (user && password) {\n        const urlObj = new URL(url)\n        urlObj.username = user\n        urlObj.password = password\n        url = urlObj.toString()\n    }",
  "outsideClass_docs": "const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const indexName = nodeData.inputs?.indexName as string\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const opensearchURL = getCredentialParam('openSearchUrl', credentialData, nodeData)\n            const user = getCredentialParam('user', credentialData, nodeData)\n            const password = getCredentialParam('password', credentialData, nodeData)\n\n            const client = getOpenSearchClient(opensearchURL, user, password)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                await OpenSearchVectorStore.fromDocuments(finalDocs, embeddings, {\n                    client,\n                    indexName: indexName\n                })\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const indexName = nodeData.inputs?.indexName as string\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const opensearchURL = getCredentialParam('openSearchUrl', credentialData, nodeData)\n        const user = getCredentialParam('user', credentialData, nodeData)\n        const password = getCredentialParam('password', credentialData, nodeData)\n\n        const client = getOpenSearchClient(opensearchURL, user, password)\n\n        const vectorStore = new OpenSearchVectorStore(embeddings, {\n            client,\n            indexName\n        })\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst getOpenSearchClient = (url: string, user?: string, password?: string): Client => {\n    if (user && password) {\n        const urlObj = new URL(url)\n        urlObj.username = user\n        urlObj.password = password\n        url = urlObj.toString()\n    }\n\n    return new Client({\n        nodes: [url]\n    })\n}"
}

## Pinecone_VectorStores

{
  "className": "Pinecone_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "if": "if (isFileUploadEnabled && options.chatId) {\n            obj.filter = obj.filter || {}",
  "constructor": "constructor() {\n        this.label = 'Pinecone'\n        this.name = 'pinecone'\n        this.version = 5.0\n        this.type = 'Pinecone'\n        this.icon = 'pinecone.svg'\n        this.category = 'Vector Stores'\n        this.description = `Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database`\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['pineconeApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_getPineconeClient": "const getPineconeClient = (option: PineconeConfiguration) => {\n    if (!pineconeClientSingleton) {\n        // if client doesn't exists\n        pineconeClientSingleton = new Pinecone(option)\n        pineconeClientOption = option\n        return pineconeClientSingleton\n    } else if (pineconeClientSingleton && !isEqual(option, pineconeClientOption)) {\n        // if client exists but option changed\n        pineconeClientSingleton = new Pinecone(option)\n        return pineconeClientSingleton\n    }\n    return pineconeClientSingleton\n}",
  "outsideClass__index": "const _index = nodeData.inputs?.pineconeIndex as string\n            const pineconeNamespace = nodeData.inputs?.pineconeNamespace as string\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n            const pineconeTextKey = nodeData.inputs?.pineconeTextKey as string\n            const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const pineconeApiKey = getCredentialParam('pineconeApiKey', credentialData, nodeData)\n\n            const client = getPineconeClient({ apiKey: pineconeApiKey })\n\n            const pineconeIndex = client.Index(_index)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }\n                    }\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const obj: PineconeStoreParams = {\n                pineconeIndex,\n                textKey: pineconeTextKey || 'text'\n            }\n\n            if (pineconeNamespace) obj.namespace = pineconeNamespace\n\n            try {\n                if (recordManager) {\n                    const vectorStore = (await PineconeStore.fromExistingIndex(embeddings, obj)) as unknown as VectorStore\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: pineconeNamespace\n                        }\n                    })\n\n                    return res\n                } else {\n                    await PineconeStore.fromDocuments(finalDocs, embeddings, obj)\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const _index = nodeData.inputs?.pineconeIndex as string\n            const pineconeNamespace = nodeData.inputs?.pineconeNamespace as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const pineconeTextKey = nodeData.inputs?.pineconeTextKey as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const pineconeApiKey = getCredentialParam('pineconeApiKey', credentialData, nodeData)\n\n            const client = getPineconeClient({ apiKey: pineconeApiKey })\n\n            const pineconeIndex = client.Index(_index)\n\n            const obj: PineconeStoreParams = {\n                pineconeIndex,\n                textKey: pineconeTextKey || 'text'\n            }\n\n            if (pineconeNamespace) obj.namespace = pineconeNamespace\n            const pineconeStore = new PineconeStore(embeddings, obj)\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = pineconeNamespace\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await pineconeStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    const pineconeStore = new PineconeStore(embeddings, obj)\n                    await pineconeStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const index = nodeData.inputs?.pineconeIndex as string\n        const pineconeNamespace = nodeData.inputs?.pineconeNamespace as string\n        const pineconeMetadataFilter = nodeData.inputs?.pineconeMetadataFilter\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const pineconeTextKey = nodeData.inputs?.pineconeTextKey as string\n        const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const pineconeApiKey = getCredentialParam('pineconeApiKey', credentialData, nodeData)\n\n        const client = getPineconeClient({ apiKey: pineconeApiKey })\n\n        const pineconeIndex = client.Index(index)\n\n        const obj: PineconeStoreParams = {\n            pineconeIndex,\n            textKey: pineconeTextKey || 'text'\n        }\n\n        if (pineconeNamespace) obj.namespace = pineconeNamespace\n        if (pineconeMetadataFilter) {\n            const metadatafilter = typeof pineconeMetadataFilter === 'object' ? pineconeMetadataFilter : JSON.parse(pineconeMetadataFilter)\n            obj.filter = metadatafilter\n        }\n        if (isFileUploadEnabled && options.chatId) {\n            obj.filter = obj.filter || {}\n            obj.filter.$or = [\n                ...(obj.filter.$or || []),\n                { [FLOWISE_CHATID]: { $eq: options.chatId } },\n                { [FLOWISE_CHATID]: { $exists: false } }\n            ]\n        }\n\n        const vectorStore = (await PineconeStore.fromExistingIndex(embeddings, obj)) as unknown as VectorStore\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, obj.filter)\n    }\n}"
}

## PineconeLlamaIndex_VectorStores

{
  "className": "PineconeLlamaIndex_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor(params: PineconeParams) {\n        super(params?.embedModel)\n        this.indexName = params?.indexName\n        this.apiKey = params?.apiKey\n        this.namespace = params?.namespace ?? ''\n        this.chunkSize = params?.chunkSize ?? Number.parseInt(process.env.PINECONE_CHUNK_SIZE ?? '100')\n        this.queryFilter = params?.queryFilter ?? {}",
  "for": "for (let i = 0; i < nodes.length; i += this.chunkSize) {\n            const chunk = nodes.slice(i, i + this.chunkSize)\n            const result = await this.saveChunk(idx, chunk)\n            if (!result) {\n                return Promise.reject()\n            }",
  "catch": "catch (err) {\n            return false\n        }",
  "if": "if (metadata[key] == null) {\n            delete metadata[key]\n        }",
  "client": "client() {\n        return this.getDb()\n    }",
  "index": "index() {\n        const db: Pinecone = await this.getDb()\n        return db.Index(this.indexName)\n    }",
  "clearIndex": "clearIndex() {\n        const db: Pinecone = await this.getDb()\n        return await db.index(this.indexName).deleteAll()\n    }",
  "saveChunk": "saveChunk(idx: Index, chunk: any) {\n        try {\n            const namespace = idx.namespace(this.namespace ?? '')\n            await namespace.upsert(chunk)\n            return true\n        }",
  "nodeToRecord": "nodeToRecord(node: BaseNode<Metadata>) {\n        let id: any = node.id_.length ? node.id_ : null\n        return {\n            id: id,\n            values: node.getEmbedding(),\n            metadata: {\n                ...cleanupMetadata(node.metadata),\n                text: (node as any).text\n            }",
  "outsideClass_indexName": "const indexName = nodeData.inputs?.pineconeIndex as string\n            const pineconeNamespace = nodeData.inputs?.pineconeNamespace as string\n            const docs = nodeData.inputs?.document as LCDocument[]\n            const embeddings = nodeData.inputs?.embeddings as BaseEmbedding\n            const model = nodeData.inputs?.model\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const pineconeApiKey = getCredentialParam('pineconeApiKey', credentialData, nodeData)\n\n            const pcvs = new PineconeVectorStore({\n                indexName,\n                apiKey: pineconeApiKey,\n                namespace: pineconeNamespace,\n                embedModel: embeddings\n            })\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new LCDocument(flattenDocs[i]))\n                }\n            }\n\n            const llamadocs: Document[] = []\n            for (const doc of finalDocs) {\n                llamadocs.push(new Document({ text: doc.pageContent, metadata: doc.metadata }))\n            }\n\n            const serviceContext = serviceContextFromDefaults({ llm: model, embedModel: embeddings })\n            const storageContext = await storageContextFromDefaults({ vectorStore: pcvs })\n\n            try {\n                await VectorStoreIndex.fromDocuments(llamadocs, { serviceContext, storageContext })\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const indexName = nodeData.inputs?.pineconeIndex as string\n        const pineconeNamespace = nodeData.inputs?.pineconeNamespace as string\n        const pineconeMetadataFilter = nodeData.inputs?.pineconeMetadataFilter\n        const embeddings = nodeData.inputs?.embeddings as BaseEmbedding\n        const model = nodeData.inputs?.model\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const pineconeApiKey = getCredentialParam('pineconeApiKey', credentialData, nodeData)\n\n        const obj: PineconeParams = {\n            indexName,\n            apiKey: pineconeApiKey,\n            embedModel: embeddings\n        }\n\n        if (pineconeNamespace) obj.namespace = pineconeNamespace\n\n        let metadatafilter = {}\n        if (pineconeMetadataFilter) {\n            metadatafilter = typeof pineconeMetadataFilter === 'object' ? pineconeMetadataFilter : JSON.parse(pineconeMetadataFilter)\n            obj.queryFilter = metadatafilter\n        }\n\n        const pcvs = new PineconeVectorStore(obj)\n\n        const serviceContext = serviceContextFromDefaults({ llm: model, embedModel: embeddings })\n        const storageContext = await storageContextFromDefaults({ vectorStore: pcvs })\n\n        const index = await VectorStoreIndex.init({\n            nodes: [],\n            storageContext,\n            serviceContext\n        })\n\n        const output = nodeData.outputs?.output as string\n\n        if (output === 'retriever') {\n            const retriever = index.asRetriever()\n            retriever.similarityTopK = k\n            ;(retriever as any).serviceContext = serviceContext\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(index as any).k = k\n            if (metadatafilter) {\n                ;(index as any).metadatafilter = metadatafilter\n            }\n            return index\n        }\n        return index\n    }\n}\n\ntype PineconeParams = {\n    indexName: string\n    apiKey: string\n    namespace?: string\n    chunkSize?: number\n    queryFilter?: object\n} & IEmbedModel",
  "outsideClass_nodes": "const nodes = embeddingResults.map(this.nodeToRecord)\n\n        for (let i = 0; i < nodes.length; i += this.chunkSize) {\n            const chunk = nodes.slice(i, i + this.chunkSize)\n            const result = await this.saveChunk(idx, chunk)\n            if (!result) {\n                return Promise.reject()\n            }\n        }\n        return Promise.resolve([])\n    }\n\n    protected async saveChunk(idx: Index, chunk: any) {\n        try {\n            const namespace = idx.namespace(this.namespace ?? '')\n            await namespace.upsert(chunk)\n            return true\n        } catch (err) {\n            return false\n        }\n    }\n\n    async delete(refDocId: string): Promise<void> {\n        const idx = await this.index()\n        const namespace = idx.namespace(this.namespace ?? '')\n        return namespace.deleteOne(refDocId)\n    }\n\n    async query(query: VectorStoreQuery): Promise<VectorStoreQueryResult> {\n        const queryOptions: any = {\n            vector: query.queryEmbedding,\n            topK: query.similarityTopK,\n            filter: this.queryFilter\n        }\n\n        const idx = await this.index()\n        const namespace = idx.namespace(this.namespace ?? '')\n        const results = await namespace.query(queryOptions)\n\n        const idList = results.matches.map((row) => row.id)\n        const records: FetchResponse<any> = await namespace.fetch(idList)\n        const rows = Object.values(records.records)\n\n        const nodes = rows.map((row) => {\n            return new Document({\n                id_: row.id,\n                text: this.textFromResultRow(row),\n                metadata: this.metaWithoutText(row.metadata),\n                embedding: row.values\n            })\n        })\n\n        const result = {\n            nodes: nodes,\n            similarities: results.matches.map((row) => row.score || 999),\n            ids: results.matches.map((row) => row.id)\n        }\n\n        return Promise.resolve(result)\n    }\n\n    /**\n     * Required by VectorStore interface. Currently ignored.\n     */\n    persist(): Promise<void> {\n        return Promise.resolve()\n    }\n\n    textFromResultRow(row: ScoredPineconeRecord<Metadata>): string {\n        return row.metadata?.text ?? ''\n    }\n\n    metaWithoutText(meta: Metadata): any {\n        return Object.keys(meta)\n            .filter((key) => key != 'text')\n            .reduce((acc: any, key: string) => {\n                acc[key] = meta[key]\n                return acc\n            }, {})\n    }\n\n    nodeToRecord(node: BaseNode<Metadata>) {\n        let id: any = node.id_.length ? node.id_ : null\n        return {\n            id: id,\n            values: node.getEmbedding(),\n            metadata: {\n                ...cleanupMetadata(node.metadata),\n                text: (node as any).text\n            }\n        }\n    }\n}\n\nconst cleanupMetadata = (nodeMetadata: ICommonObject) => {\n    // Pinecone doesn't support nested objects, so we flatten them\n    const documentMetadata: any = { ...nodeMetadata }\n    // preserve string arrays which are allowed\n    const stringArrays: Record<string, string[]> = {}\n    for (const key of Object.keys(documentMetadata)) {\n        if (Array.isArray(documentMetadata[key]) && documentMetadata[key].every((el: any) => typeof el === 'string')) {\n            stringArrays[key] = documentMetadata[key]\n            delete documentMetadata[key]\n        }\n    }\n    const metadata: {\n        [key: string]: string | number | boolean | string[] | null\n    } = {\n        ...flattenObject(documentMetadata),\n        ...stringArrays\n    }\n    // Pinecone doesn't support null values, so we remove them\n    for (const key of Object.keys(metadata)) {\n        if (metadata[key] == null) {\n            delete metadata[key]\n        } else if (typeof metadata[key] === 'object' && Object.keys(metadata[key] as unknown as object).length === 0) {\n            delete metadata[key]\n        }\n    }\n    return metadata\n}"
}

## Postgres_VectorStores

{
  "className": "Postgres_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Postgres'\n        this.name = 'postgres'\n        this.version = 6.0\n        this.type = 'Postgres'\n        this.icon = 'postgres.svg'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data and perform similarity search upon query using pgvector on Postgres'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['PostgresApi']\n        }",
  "if": "if (filter && typeof filter === 'object') {\n        if (filter.$notexists) {\n            notExists = `OR NOT (metadata ? '${filter.$notexists}",
  "catch": "catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }",
  "for": "for (const doc of documents.rows) {\n        if (doc._distance != null && doc.pageContent != null) {\n            const document = new Document(doc) as TypeORMVectorStoreDocument\n            document.id = doc.id\n            results.push([document, doc._distance])\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const user = getCredentialParam('user', credentialData, nodeData)\n            const password = getCredentialParam('password', credentialData, nodeData)\n            const _tableName = nodeData.inputs?.tableName as string\n            const tableName = _tableName ? _tableName : 'documents'\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const additionalConfig = nodeData.inputs?.additionalConfig as string\n            const recordManager = nodeData.inputs?.recordManager\n            const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n            let additionalConfiguration = {}\n            if (additionalConfig) {\n                try {\n                    additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n                } catch (exception) {\n                    throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n                }\n            }\n\n            const postgresConnectionOptions = {\n                ...additionalConfiguration,\n                type: 'postgres',\n                host: nodeData.inputs?.host as string,\n                port: nodeData.inputs?.port as number,\n                username: user,\n                password: password,\n                database: nodeData.inputs?.database as string\n            }\n\n            const args = {\n                postgresConnectionOptions: postgresConnectionOptions as DataSourceOptions,\n                tableName: tableName\n            }\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }\n                    }\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                if (recordManager) {\n                    const vectorStore = await TypeORMVectorStore.fromDataSource(embeddings, args)\n\n                    // Avoid Illegal invocation error\n                    vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: any) => {\n                        return await similaritySearchVectorWithScore(query, k, tableName, postgresConnectionOptions, filter)\n                    }\n\n                    await recordManager.createSchema()\n\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: tableName\n                        }\n                    })\n\n                    return res\n                } else {\n                    const vectorStore = await TypeORMVectorStore.fromDocuments(finalDocs, embeddings, args)\n\n                    // Avoid Illegal invocation error\n                    vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: any) => {\n                        return await similaritySearchVectorWithScore(query, k, tableName, postgresConnectionOptions, filter)\n                    }\n\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const user = getCredentialParam('user', credentialData, nodeData)\n            const password = getCredentialParam('password', credentialData, nodeData)\n            const _tableName = nodeData.inputs?.tableName as string\n            const tableName = _tableName ? _tableName : 'documents'\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const additionalConfig = nodeData.inputs?.additionalConfig as string\n            const recordManager = nodeData.inputs?.recordManager\n\n            let additionalConfiguration = {}\n            if (additionalConfig) {\n                try {\n                    additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n                } catch (exception) {\n                    throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n                }\n            }\n\n            const postgresConnectionOptions = {\n                ...additionalConfiguration,\n                type: 'postgres',\n                host: nodeData.inputs?.host as string,\n                port: nodeData.inputs?.port as number,\n                username: user,\n                password: password,\n                database: nodeData.inputs?.database as string\n            }\n\n            const args = {\n                postgresConnectionOptions: postgresConnectionOptions as DataSourceOptions,\n                tableName: tableName\n            }\n\n            const vectorStore = await TypeORMVectorStore.fromDataSource(embeddings, args)\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = tableName\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await vectorStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await vectorStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const user = getCredentialParam('user', credentialData, nodeData)\n        const password = getCredentialParam('password', credentialData, nodeData)\n        const _tableName = nodeData.inputs?.tableName as string\n        const tableName = _tableName ? _tableName : 'documents'\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const additionalConfig = nodeData.inputs?.additionalConfig as string\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n        const _pgMetadataFilter = nodeData.inputs?.pgMetadataFilter\n        const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n        let pgMetadataFilter: any\n        if (_pgMetadataFilter) {\n            pgMetadataFilter = typeof _pgMetadataFilter === 'object' ? _pgMetadataFilter : JSON.parse(_pgMetadataFilter)\n        }\n        if (isFileUploadEnabled && options.chatId) {\n            pgMetadataFilter = pgMetadataFilter || {}\n            pgMetadataFilter = {\n                ...pgMetadataFilter,\n                [FLOWISE_CHATID]: options.chatId,\n                $notexists: FLOWISE_CHATID // special filter to check if the field does not exist\n            }\n        }\n\n        let additionalConfiguration = {}\n        if (additionalConfig) {\n            try {\n                additionalConfiguration = typeof additionalConfig === 'object' ? additionalConfig : JSON.parse(additionalConfig)\n            } catch (exception) {\n                throw new Error('Invalid JSON in the Additional Configuration: ' + exception)\n            }\n        }\n\n        const postgresConnectionOptions = {\n            ...additionalConfiguration,\n            type: 'postgres',\n            host: nodeData.inputs?.host as string,\n            port: nodeData.inputs?.port as number,\n            username: user, // Required by TypeORMVectorStore\n            user: user, // Required by Pool in similaritySearchVectorWithScore\n            password: password,\n            database: nodeData.inputs?.database as string\n        }\n\n        const args = {\n            postgresConnectionOptions: postgresConnectionOptions as DataSourceOptions,\n            tableName: tableName\n        }\n\n        const vectorStore = await TypeORMVectorStore.fromDataSource(embeddings, args)\n\n        // Rewrite the method to use pg pool connection instead of the default connection\n        /* Otherwise a connection error is displayed when the chain tries to execute the function\n            [chain/start] [1:chain:ConversationalRetrievalQAChain] Entering Chain run with input: { \"question\": \"what the document is about\", \"chat_history\": [] }\n            [retriever/start] [1:chain:ConversationalRetrievalQAChain > 2:retriever:VectorStoreRetriever] Entering Retriever run with input: { \"query\": \"what the document is about\" }\n            [ERROR]: uncaughtException:  Illegal invocation TypeError: Illegal invocation at Socket.ref (node:net:1524:18) at Connection.ref (.../node_modules/pg/lib/connection.js:183:17) at Client.ref (.../node_modules/pg/lib/client.js:591:21) at BoundPool._pulseQueue (/node_modules/pg-pool/index.js:148:28) at .../node_modules/pg-pool/index.js:184:37 at process.processTicksAndRejections (node:internal/process/task_queues:77:11)\n        */\n        vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: any) => {\n            return await similaritySearchVectorWithScore(query, k, tableName, postgresConnectionOptions, filter ?? pgMetadataFilter)\n        }\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (pgMetadataFilter) {\n                ;(vectorStore as any).filter = pgMetadataFilter\n            }\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst similaritySearchVectorWithScore = async (\n    query: number[],\n    k: number,\n    tableName: string,\n    postgresConnectionOptions: ICommonObject,\n    filter?: any\n) => {\n    const embeddingString = `[${query.join(',')}]`\n    let _filter = '{}'\n    let notExists = ''\n    if (filter && typeof filter === 'object') {\n        if (filter.$notexists) {\n            notExists = `OR NOT (metadata ? '${filter.$notexists}')`\n            delete filter.$notexists\n        }\n        _filter = JSON.stringify(filter)\n    }\n\n    const queryString = `\n        SELECT *, embedding <=> $1 as \"_distance\"\n        FROM ${tableName}\n        WHERE metadata @> $2\n        ${notExists}\n        ORDER BY \"_distance\" ASC\n        LIMIT $3;`\n\n    const pool = new Pool(postgresConnectionOptions)\n    const conn = await pool.connect()\n\n    const documents = await conn.query(queryString, [embeddingString, _filter, k])\n\n    conn.release()\n\n    const results = [] as [TypeORMVectorStoreDocument, number][]\n    for (const doc of documents.rows) {\n        if (doc._distance != null && doc.pageContent != null) {\n            const document = new Document(doc) as TypeORMVectorStoreDocument\n            document.id = doc.id\n            results.push([document, doc._distance])\n        }\n    }\n\n    return results\n}"
}

## Qdrant_VectorStores

{
  "className": "Qdrant_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "determinePortByUrl": "[Function: determinePortByUrl]",
  "constructor": "constructor() {\n        this.label = 'Qdrant'\n        this.name = 'qdrant'\n        this.version = 5.0\n        this.type = 'Qdrant'\n        this.icon = 'qdrant.png'\n        this.category = 'Vector Stores'\n        this.description =\n            'Upsert embedded data and perform similarity search upon query using Qdrant, a scalable open source vector database written in Rust'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Only needed when using Qdrant cloud hosted',\n            optional: true,\n            credentialNames: ['qdrantApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }",
  "if": "if (parsedUrl.protocol === 'http:' && parsedUrl.port === '') {\n            port = 80\n        }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_qdrantServerUrl": "const qdrantServerUrl = nodeData.inputs?.qdrantServerUrl as string\n            const collectionName = nodeData.inputs?.qdrantCollection as string\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const qdrantSimilarity = nodeData.inputs?.qdrantSimilarity\n            const qdrantVectorDimension = nodeData.inputs?.qdrantVectorDimension\n            const recordManager = nodeData.inputs?.recordManager\n            const _batchSize = nodeData.inputs?.batchSize\n            const contentPayloadKey = nodeData.inputs?.contentPayloadKey || 'content'\n            const metadataPayloadKey = nodeData.inputs?.metadataPayloadKey || 'metadata'\n            const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const qdrantApiKey = getCredentialParam('qdrantApiKey', credentialData, nodeData)\n\n            const port = Qdrant_VectorStores.determinePortByUrl(qdrantServerUrl)\n\n            const client = new QdrantClient({\n                url: qdrantServerUrl,\n                apiKey: qdrantApiKey,\n                port: port\n            })\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }\n                    }\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const dbConfig: QdrantLibArgs = {\n                client,\n                url: qdrantServerUrl,\n                collectionName,\n                collectionConfig: {\n                    vectors: {\n                        size: qdrantVectorDimension ? parseInt(qdrantVectorDimension, 10) : 1536,\n                        distance: qdrantSimilarity ?? 'Cosine'\n                    }\n                },\n                contentPayloadKey,\n                metadataPayloadKey\n            }\n\n            try {\n                if (recordManager) {\n                    const vectorStore = new QdrantVectorStore(embeddings, dbConfig)\n                    await vectorStore.ensureCollection()\n\n                    vectorStore.addVectors = async (\n                        vectors: number[][],\n                        documents: Document[],\n                        documentOptions?: QdrantAddDocumentOptions\n                    ): Promise<void> => {\n                        if (vectors.length === 0) {\n                            return\n                        }\n\n                        await vectorStore.ensureCollection()\n\n                        const points = vectors.map((embedding, idx) => ({\n                            id: documentOptions?.ids?.length ? documentOptions?.ids[idx] : uuid(),\n                            vector: embedding,\n                            payload: {\n                                [contentPayloadKey]: documents[idx].pageContent,\n                                [metadataPayloadKey]: documents[idx].metadata,\n                                customPayload: documentOptions?.customPayload?.length ? documentOptions?.customPayload[idx] : undefined\n                            }\n                        }))\n\n                        try {\n                            if (_batchSize) {\n                                const batchSize = parseInt(_batchSize, 10)\n                                for (let i = 0; i < points.length; i += batchSize) {\n                                    const batchPoints = points.slice(i, i + batchSize)\n                                    await client.upsert(collectionName, {\n                                        wait: true,\n                                        points: batchPoints\n                                    })\n                                }\n                            } else {\n                                await client.upsert(collectionName, {\n                                    wait: true,\n                                    points\n                                })\n                            }\n                        } catch (e: any) {\n                            const error = new Error(`${e?.status ?? 'Undefined error code'} ${e?.message}: ${e?.data?.status?.error}`)\n                            throw error\n                        }\n                    }\n\n                    vectorStore.delete = async (params: { ids: string[] }): Promise<void> => {\n                        const { ids } = params\n\n                        if (ids?.length) {\n                            try {\n                                client.delete(collectionName, {\n                                    points: ids\n                                })\n                            } catch (e) {\n                                console.error('Failed to delete')\n                            }\n                        }\n                    }\n\n                    await recordManager.createSchema()\n\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: collectionName\n                        }\n                    })\n\n                    return res\n                } else {\n                    if (_batchSize) {\n                        const batchSize = parseInt(_batchSize, 10)\n                        for (let i = 0; i < finalDocs.length; i += batchSize) {\n                            const batch = finalDocs.slice(i, i + batchSize)\n                            await QdrantVectorStore.fromDocuments(batch, embeddings, dbConfig)\n                        }\n                    } else {\n                        await QdrantVectorStore.fromDocuments(finalDocs, embeddings, dbConfig)\n                    }\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const qdrantServerUrl = nodeData.inputs?.qdrantServerUrl as string\n            const collectionName = nodeData.inputs?.qdrantCollection as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const qdrantSimilarity = nodeData.inputs?.qdrantSimilarity\n            const qdrantVectorDimension = nodeData.inputs?.qdrantVectorDimension\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const qdrantApiKey = getCredentialParam('qdrantApiKey', credentialData, nodeData)\n\n            const port = Qdrant_VectorStores.determinePortByUrl(qdrantServerUrl)\n\n            const client = new QdrantClient({\n                url: qdrantServerUrl,\n                apiKey: qdrantApiKey,\n                port: port\n            })\n\n            const dbConfig: QdrantLibArgs = {\n                client,\n                url: qdrantServerUrl,\n                collectionName,\n                collectionConfig: {\n                    vectors: {\n                        size: qdrantVectorDimension ? parseInt(qdrantVectorDimension, 10) : 1536,\n                        distance: qdrantSimilarity ?? 'Cosine'\n                    }\n                }\n            }\n\n            const vectorStore = new QdrantVectorStore(embeddings, dbConfig)\n\n            vectorStore.delete = async (params: { ids: string[] }): Promise<void> => {\n                const { ids } = params\n\n                if (ids?.length) {\n                    try {\n                        client.delete(collectionName, {\n                            points: ids\n                        })\n                    } catch (e) {\n                        console.error('Failed to delete')\n                    }\n                }\n            }\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = collectionName\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await vectorStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await vectorStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const qdrantServerUrl = nodeData.inputs?.qdrantServerUrl as string\n        const collectionName = nodeData.inputs?.qdrantCollection as string\n        let qdrantCollectionConfiguration = nodeData.inputs?.qdrantCollectionConfiguration\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const qdrantSimilarity = nodeData.inputs?.qdrantSimilarity\n        const qdrantVectorDimension = nodeData.inputs?.qdrantVectorDimension\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        let queryFilter = nodeData.inputs?.qdrantFilter\n        const contentPayloadKey = nodeData.inputs?.contentPayloadKey || 'content'\n        const metadataPayloadKey = nodeData.inputs?.metadataPayloadKey || 'metadata'\n        const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n        const k = topK ? parseFloat(topK) : 4\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const qdrantApiKey = getCredentialParam('qdrantApiKey', credentialData, nodeData)\n\n        const port = Qdrant_VectorStores.determinePortByUrl(qdrantServerUrl)\n\n        const client = new QdrantClient({\n            url: qdrantServerUrl,\n            apiKey: qdrantApiKey,\n            port: port\n        })\n\n        const dbConfig: QdrantLibArgs = {\n            client,\n            collectionName,\n            contentPayloadKey,\n            metadataPayloadKey\n        }\n\n        const retrieverConfig: RetrieverConfig = {\n            k\n        }\n\n        if (qdrantCollectionConfiguration) {\n            qdrantCollectionConfiguration =\n                typeof qdrantCollectionConfiguration === 'object'\n                    ? qdrantCollectionConfiguration\n                    : JSON.parse(qdrantCollectionConfiguration)\n            dbConfig.collectionConfig = {\n                ...qdrantCollectionConfiguration,\n                vectors: {\n                    ...qdrantCollectionConfiguration.vectors,\n                    size: qdrantVectorDimension ? parseInt(qdrantVectorDimension, 10) : 1536,\n                    distance: qdrantSimilarity ?? 'Cosine'\n                }\n            }\n        }\n\n        if (queryFilter) {\n            retrieverConfig.filter = typeof queryFilter === 'object' ? queryFilter : JSON.parse(queryFilter)\n        }\n        if (isFileUploadEnabled && options.chatId) {\n            retrieverConfig.filter = retrieverConfig.filter || {}\n\n            retrieverConfig.filter.should = Array.isArray(retrieverConfig.filter.should) ? retrieverConfig.filter.should : []\n\n            retrieverConfig.filter.should.push(\n                {\n                    key: `metadata.${FLOWISE_CHATID}`,\n                    match: {\n                        value: options.chatId\n                    }\n                },\n                {\n                    is_empty: {\n                        key: `metadata.${FLOWISE_CHATID}`\n                    }\n                }\n            )\n        }\n\n        const vectorStore = await QdrantVectorStore.fromExistingCollection(embeddings, dbConfig)\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(retrieverConfig)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (queryFilter) {\n                ;(vectorStore as any).filter = retrieverConfig.filter\n            }\n            return vectorStore\n        }\n        return vectorStore\n    }\n\n    /**\n     * Determine the port number from the given URL.\n     *\n     * The problem is when not doing this the qdrant-client.js will fall back on 6663 when you enter a port 443 and 80.\n     * See: https://stackoverflow.com/questions/59104197/nodejs-new-url-urlhttps-myurl-com80-lists-the-port-as-empty\n     * @param qdrantServerUrl the url to get the port from\n     */\n    static determinePortByUrl(qdrantServerUrl: string): number {\n        const parsedUrl = new URL(qdrantServerUrl)\n\n        let port = parsedUrl.port ? parseInt(parsedUrl.port) : 6663\n\n        if (parsedUrl.protocol === 'https:' && parsedUrl.port === '') {\n            port = 443\n        }\n        if (parsedUrl.protocol === 'http:' && parsedUrl.port === '') {\n            port = 80\n        }\n\n        return port\n    }\n}"
}

## Redis_VectorStores

{
  "className": "Redis_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "if": "if (results.total) {\n        for (const res of results.documents) {\n            if (res.value) {\n                const document = res.value\n                if (document.vector_score) {\n                    const metadataString = unEscapeSpecialChars(document[metadataKey] as string)\n                    result.push([\n                        new Document({\n                            pageContent: document[contentKey] as string,\n                            metadata: JSON.parse(metadataString)\n                        }",
  "constructor": "constructor() {\n        this.label = 'Redis'\n        this.name = 'redis'\n        this.version = 1.0\n        this.description =\n            'Upsert embedded data and perform similarity search upon query using Redis, an open source, in-memory data structure store'\n        this.type = 'Redis'\n        this.icon = 'redis.svg'\n        this.category = 'Vector Stores'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['redisCacheUrlApi', 'redisCacheApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const document = new Document(flattenDocs[i])\n                    escapeAllStrings(document.metadata)\n                    finalDocs.push(document)\n                }",
  "catch": "catch (err: any) {\n        if (err?.message.includes('unknown command')) {\n            throw new Error(\n                'Failed to run FT.INFO command. Please ensure that you are running a RediSearch-capable Redis instance: https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/redis#setup'\n            )\n        }",
  "outsideClass_getRedisClient": "const getRedisClient = async (option: RedisClientOptions) => {\n    if (!redisClientSingleton) {\n        // if client doesn't exists\n        redisClientSingleton = createClient(option)\n        await redisClientSingleton.connect()\n        redisClientOption = option\n        return redisClientSingleton\n    } else if (redisClientSingleton && !isEqual(option, redisClientOption)) {\n        // if client exists but option changed\n        redisClientSingleton.quit()\n        redisClientSingleton = createClient(option)\n        await redisClientSingleton.connect()\n        redisClientOption = option\n        return redisClientSingleton\n    }\n    return redisClientSingleton\n}",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const indexName = nodeData.inputs?.indexName as string\n            let contentKey = nodeData.inputs?.contentKey as string\n            let metadataKey = nodeData.inputs?.metadataKey as string\n            let vectorKey = nodeData.inputs?.vectorKey as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const replaceIndex = nodeData.inputs?.replaceIndex as boolean\n\n            let redisUrl = getCredentialParam('redisUrl', credentialData, nodeData)\n            if (!redisUrl || redisUrl === '') {\n                const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n                const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n                const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n                const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n\n                redisUrl = 'redis://' + username + ':' + password + '@' + host + ':' + portStr\n            }\n\n            const docs = nodeData.inputs?.document as Document[]\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    const document = new Document(flattenDocs[i])\n                    escapeAllStrings(document.metadata)\n                    finalDocs.push(document)\n                }\n            }\n\n            try {\n                const redisClient = await getRedisClient({ url: redisUrl })\n\n                const storeConfig: RedisVectorStoreConfig = {\n                    redisClient: redisClient,\n                    indexName: indexName\n                }\n                const isIndexExists = await checkIndexExists(redisClient, indexName)\n                if (replaceIndex && isIndexExists) {\n                    let response = await redisClient.ft.dropIndex(indexName)\n                    if (process.env.DEBUG === 'true') {\n                        // eslint-disable-next-line no-console\n                        console.log(`Redis Vector Store :: Dropping index [${indexName}], Received Response [${response}]`)\n                    }\n                }\n                const vectorStore = await RedisVectorStore.fromDocuments(finalDocs, embeddings, storeConfig)\n\n                if (!contentKey || contentKey === '') contentKey = 'content'\n                if (!metadataKey || metadataKey === '') metadataKey = 'metadata'\n                if (!vectorKey || vectorKey === '') vectorKey = 'content_vector'\n\n                // Avoid Illegal invocation error\n                vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: any) => {\n                    return await similaritySearchVectorWithScore(\n                        query,\n                        k,\n                        indexName,\n                        metadataKey,\n                        vectorKey,\n                        contentKey,\n                        redisClient,\n                        filter\n                    )\n                }\n\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const indexName = nodeData.inputs?.indexName as string\n        let contentKey = nodeData.inputs?.contentKey as string\n        let metadataKey = nodeData.inputs?.metadataKey as string\n        let vectorKey = nodeData.inputs?.vectorKey as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n        const output = nodeData.outputs?.output as string\n\n        let redisUrl = getCredentialParam('redisUrl', credentialData, nodeData)\n        if (!redisUrl || redisUrl === '') {\n            const username = getCredentialParam('redisCacheUser', credentialData, nodeData)\n            const password = getCredentialParam('redisCachePwd', credentialData, nodeData)\n            const portStr = getCredentialParam('redisCachePort', credentialData, nodeData)\n            const host = getCredentialParam('redisCacheHost', credentialData, nodeData)\n\n            redisUrl = 'redis://' + username + ':' + password + '@' + host + ':' + portStr\n        }\n\n        const redisClient = await getRedisClient({ url: redisUrl })\n\n        const storeConfig: RedisVectorStoreConfig = {\n            redisClient: redisClient,\n            indexName: indexName\n        }\n\n        const vectorStore = new RedisVectorStore(embeddings, storeConfig)\n\n        if (!contentKey || contentKey === '') contentKey = 'content'\n        if (!metadataKey || metadataKey === '') metadataKey = 'metadata'\n        if (!vectorKey || vectorKey === '') vectorKey = 'content_vector'\n\n        // Avoid Illegal invocation error\n        vectorStore.similaritySearchVectorWithScore = async (query: number[], k: number, filter?: any) => {\n            return await similaritySearchVectorWithScore(query, k, indexName, metadataKey, vectorKey, contentKey, redisClient, filter)\n        }\n\n        if (output === 'retriever') {\n            return vectorStore.asRetriever(k)\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst checkIndexExists = async (redisClient: ReturnType<typeof createClient>, indexName: string) => {\n    try {\n        await redisClient.ft.info(indexName)\n    } catch (err: any) {\n        if (err?.message.includes('unknown command')) {\n            throw new Error(\n                'Failed to run FT.INFO command. Please ensure that you are running a RediSearch-capable Redis instance: https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/redis#setup'\n            )\n        }\n        // index doesn't exist\n        return false\n    }\n\n    return true\n}\n\nconst buildQuery = (\n    query: number[],\n    k: number,\n    metadataKey: string,\n    vectorKey: string,\n    contentKey: string,\n    filter?: string[]\n): [string, SearchOptions] => {\n    const vectorScoreField = 'vector_score'\n\n    let hybridFields = '*'\n    // if a filter is set, modify the hybrid query\n    if (filter && filter.length) {\n        // `filter` is a list of strings, then it's applied using the OR operator in the metadata key\n        hybridFields = `@${metadataKey}:(${filter.map(escapeSpecialChars).join('|')})`\n    }\n\n    const baseQuery = `${hybridFields} => [KNN ${k} @${vectorKey} $vector AS ${vectorScoreField}]`\n    const returnFields = [metadataKey, contentKey, vectorScoreField]\n\n    const options: SearchOptions = {\n        PARAMS: {\n            vector: Buffer.from(new Float32Array(query).buffer)\n        },\n        RETURN: returnFields,\n        SORTBY: vectorScoreField,\n        DIALECT: 2,\n        LIMIT: {\n            from: 0,\n            size: k\n        }\n    }\n\n    return [baseQuery, options]\n}\n\nconst similaritySearchVectorWithScore = async (\n    query: number[],\n    k: number,\n    indexName: string,\n    metadataKey: string,\n    vectorKey: string,\n    contentKey: string,\n    redisClient: ReturnType<typeof createClient>,\n    filter?: string[]\n): Promise<[Document, number][]> => {\n    const results = await redisClient.ft.search(indexName, ...buildQuery(query, k, metadataKey, vectorKey, contentKey, filter))\n    const result: [Document, number][] = []\n\n    if (results.total) {\n        for (const res of results.documents) {\n            if (res.value) {\n                const document = res.value\n                if (document.vector_score) {\n                    const metadataString = unEscapeSpecialChars(document[metadataKey] as string)\n                    result.push([\n                        new Document({\n                            pageContent: document[contentKey] as string,\n                            metadata: JSON.parse(metadataString)\n                        }),\n                        Number(document.vector_score)\n                    ])\n                }\n            }\n        }\n    }\n    return result\n}"
}

## SimpleStoreUpsert_LlamaIndex_VectorStores

{
  "className": "SimpleStoreUpsert_LlamaIndex_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SimpleStore'\n        this.name = 'simpleStoreLlamaIndex'\n        this.version = 1.0\n        this.type = 'SimpleVectorStore'\n        this.icon = 'simplevs.svg'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data to local path and perform similarity search'\n        this.baseClasses = [this.type, 'VectorIndexRetriever']\n        this.tags = ['LlamaIndex']\n        this.inputs = [\n            {\n                label: 'Document',\n                name: 'document',\n                type: 'Document',\n                list: true,\n                optional: true\n            }",
  "for": "for (const doc of finalDocs) {\n                llamadocs.push(new Document({ text: doc.pageContent, metadata: doc.metadata }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (output === 'vectorStore') {\n            ;(index as any).k = k\n            return index\n        }",
  "outsideClass_basePath": "const basePath = nodeData.inputs?.basePath as string\n            const docs = nodeData.inputs?.document as LCDocument[]\n            const embeddings = nodeData.inputs?.embeddings\n            const model = nodeData.inputs?.model\n\n            let filePath = ''\n            if (!basePath) filePath = path.join(getUserHome(), '.flowise', 'llamaindex')\n            else filePath = basePath\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                finalDocs.push(new LCDocument(flattenDocs[i]))\n            }\n\n            const llamadocs: Document[] = []\n            for (const doc of finalDocs) {\n                llamadocs.push(new Document({ text: doc.pageContent, metadata: doc.metadata }))\n            }\n\n            const serviceContext = serviceContextFromDefaults({ llm: model, embedModel: embeddings })\n            const storageContext = await storageContextFromDefaults({ persistDir: filePath })\n\n            try {\n                await VectorStoreIndex.fromDocuments(llamadocs, { serviceContext, storageContext })\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData): Promise<any> {\n        const basePath = nodeData.inputs?.basePath as string\n        const embeddings = nodeData.inputs?.embeddings\n        const model = nodeData.inputs?.model\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        let filePath = ''\n        if (!basePath) filePath = path.join(getUserHome(), '.flowise', 'llamaindex')\n        else filePath = basePath\n\n        const serviceContext = serviceContextFromDefaults({ llm: model, embedModel: embeddings })\n        const storageContext = await storageContextFromDefaults({ persistDir: filePath })\n\n        const index = await VectorStoreIndex.init({ storageContext, serviceContext })\n\n        const output = nodeData.outputs?.output as string\n\n        if (output === 'retriever') {\n            const retriever = index.asRetriever()\n            retriever.similarityTopK = k\n            ;(retriever as any).serviceContext = serviceContext\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(index as any).k = k\n            return index\n        }\n        return index\n    }\n}"
}

## SingleStore_VectorStores

{
  "className": "SingleStore_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'SingleStore'\n        this.name = 'singlestore'\n        this.version = 1.0\n        this.type = 'SingleStore'\n        this.icon = 'singlestore.svg'\n        this.category = 'Vector Stores'\n        this.description =\n            'Upsert embedded data and perform similarity search upon query using SingleStore, a fast and distributed cloud relational database'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Needed when using SingleStore cloud hosted',\n            optional: true,\n            credentialNames: ['singleStoreApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const user = getCredentialParam('user', credentialData, nodeData)\n            const password = getCredentialParam('password', credentialData, nodeData)\n\n            const singleStoreConnectionConfig = {\n                connectionOptions: {\n                    host: nodeData.inputs?.host as string,\n                    port: 3306,\n                    user,\n                    password,\n                    database: nodeData.inputs?.database as string\n                },\n                ...(nodeData.inputs?.tableName ? { tableName: nodeData.inputs.tableName as string } : {}),\n                ...(nodeData.inputs?.contentColumnName ? { contentColumnName: nodeData.inputs.contentColumnName as string } : {}),\n                ...(nodeData.inputs?.vectorColumnName ? { vectorColumnName: nodeData.inputs.vectorColumnName as string } : {}),\n                ...(nodeData.inputs?.metadataColumnName ? { metadataColumnName: nodeData.inputs.metadataColumnName as string } : {})\n            } as SingleStoreVectorStoreConfig\n\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                const vectorStore = new SingleStoreVectorStore(embeddings, singleStoreConnectionConfig)\n                vectorStore.addDocuments.bind(vectorStore)(finalDocs)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const user = getCredentialParam('user', credentialData, nodeData)\n        const password = getCredentialParam('password', credentialData, nodeData)\n\n        const singleStoreConnectionConfig = {\n            connectionOptions: {\n                host: nodeData.inputs?.host as string,\n                port: 3306,\n                user,\n                password,\n                database: nodeData.inputs?.database as string\n            },\n            ...(nodeData.inputs?.tableName ? { tableName: nodeData.inputs.tableName as string } : {}),\n            ...(nodeData.inputs?.contentColumnName ? { contentColumnName: nodeData.inputs.contentColumnName as string } : {}),\n            ...(nodeData.inputs?.vectorColumnName ? { vectorColumnName: nodeData.inputs.vectorColumnName as string } : {}),\n            ...(nodeData.inputs?.metadataColumnName ? { metadataColumnName: nodeData.inputs.metadataColumnName as string } : {})\n        } as SingleStoreVectorStoreConfig\n\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 4\n\n        const vectorStore = new SingleStoreVectorStore(embeddings, singleStoreConnectionConfig)\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            return vectorStore\n        }\n        return vectorStore\n    }\n}"
}

## Supabase_VectorStores

{
  "className": "Supabase_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Supabase'\n        this.name = 'supabase'\n        this.version = 4.0\n        this.type = 'Supabase'\n        this.icon = 'supabase.svg'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data and perform similarity or mmr search upon query using Supabase via pgvector extension'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['supabaseApi']\n        }",
  "for": "for (let i = 0; i < rows.length; i += this.upsertBatchSize) {\n            const chunk = rows.slice(i, i + this.upsertBatchSize).map((row, j) => {\n                if (options?.ids) {\n                    return { id: options.ids[i + j], ...row }",
  "if": "if (res.data) {\n                returnedIds = returnedIds.concat(res.data.map((row) => row.id))\n            }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_supabaseProjUrl": "const supabaseProjUrl = nodeData.inputs?.supabaseProjUrl as string\n            const tableName = nodeData.inputs?.tableName as string\n            const queryName = nodeData.inputs?.queryName as string\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const supabaseApiKey = getCredentialParam('supabaseApiKey', credentialData, nodeData)\n\n            const client = createClient(supabaseProjUrl, supabaseApiKey)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            try {\n                if (recordManager) {\n                    const vectorStore = await SupabaseUpsertVectorStore.fromExistingIndex(embeddings, {\n                        client,\n                        tableName: tableName,\n                        queryName: queryName\n                    })\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: tableName + '_' + queryName\n                        }\n                    })\n                    return res\n                } else {\n                    await SupabaseUpsertVectorStore.fromDocuments(finalDocs, embeddings, {\n                        client,\n                        tableName: tableName,\n                        queryName: queryName\n                    })\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const supabaseProjUrl = nodeData.inputs?.supabaseProjUrl as string\n            const tableName = nodeData.inputs?.tableName as string\n            const queryName = nodeData.inputs?.queryName as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const supabaseApiKey = getCredentialParam('supabaseApiKey', credentialData, nodeData)\n\n            const client = createClient(supabaseProjUrl, supabaseApiKey)\n\n            const supabaseStore = new SupabaseVectorStore(embeddings, {\n                client,\n                tableName: tableName,\n                queryName: queryName\n            })\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = tableName + '_' + queryName\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await supabaseStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await supabaseStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const supabaseProjUrl = nodeData.inputs?.supabaseProjUrl as string\n        const tableName = nodeData.inputs?.tableName as string\n        const queryName = nodeData.inputs?.queryName as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const supabaseMetadataFilter = nodeData.inputs?.supabaseMetadataFilter\n        const supabaseRPCFilter = nodeData.inputs?.supabaseRPCFilter\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const supabaseApiKey = getCredentialParam('supabaseApiKey', credentialData, nodeData)\n\n        const client = createClient(supabaseProjUrl, supabaseApiKey)\n\n        const obj: SupabaseLibArgs = {\n            client,\n            tableName,\n            queryName\n        }\n\n        if (supabaseMetadataFilter) {\n            const metadatafilter = typeof supabaseMetadataFilter === 'object' ? supabaseMetadataFilter : JSON.parse(supabaseMetadataFilter)\n            obj.filter = metadatafilter\n        }\n\n        if (supabaseRPCFilter) {\n            const funcString = `return rpc.${supabaseRPCFilter};`\n            const funcFilter = new Function('rpc', funcString)\n            obj.filter = (rpc: SupabaseFilterRPCCall) => {\n                return funcFilter(rpc)\n            }\n        }\n\n        const vectorStore = await SupabaseVectorStore.fromExistingIndex(embeddings, obj)\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, obj.filter)\n    }\n}",
  "outsideClass_rows": "const rows = vectors.map((embedding, idx) => ({\n            content: documents[idx].pageContent,\n            embedding,\n            metadata: documents[idx].metadata\n        }))\n\n        let returnedIds: string[] = []\n        for (let i = 0; i < rows.length; i += this.upsertBatchSize) {\n            const chunk = rows.slice(i, i + this.upsertBatchSize).map((row, j) => {\n                if (options?.ids) {\n                    return { id: options.ids[i + j], ...row }\n                }\n                return row\n            })\n\n            let res = await this.client.from(this.tableName).upsert(chunk).select()\n\n            if (res.error) {\n                // If the error is due to null value in column \"id\", we will generate a new id for the row\n                if (res.error.message.includes(`null value in column \"id\"`)) {\n                    const chunk = rows.slice(i, i + this.upsertBatchSize).map((row, y) => {\n                        if (options?.ids) {\n                            return { id: options.ids[i + y], ...row }\n                        }\n                        return { id: uuidv4(), ...row }\n                    })\n                    res = await this.client.from(this.tableName).upsert(chunk).select()\n\n                    if (res.error) {\n                        throw new Error(`Error inserting: ${res.error.message} ${res.status} ${res.statusText}`)\n                    }\n                } else {\n                    throw new Error(`Error inserting: ${res.error.message} ${res.status} ${res.statusText}`)\n                }\n            }\n\n            if (res.data) {\n                returnedIds = returnedIds.concat(res.data.map((row) => row.id))\n            }\n        }\n\n        return returnedIds\n    }\n}"
}

## Upstash_VectorStores

{
  "className": "Upstash_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Upstash Vector'\n        this.name = 'upstash'\n        this.version = 2.0\n        this.type = 'Upstash'\n        this.icon = 'upstash.svg'\n        this.category = 'Vector Stores'\n        this.description =\n            'Upsert data as embedding or string and perform similarity search with Upstash, the leading serverless data platform'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Necessary credentials for the HTTP connection',\n            credentialNames: ['upstashVectorApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }",
  "if": "if (isFileUploadEnabled && options.chatId) {\n            if (upstashMetadataFilter) obj.filter += ` OR ${FLOWISE_CHATID}",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_docs": "const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n            const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const UPSTASH_VECTOR_REST_URL = getCredentialParam('UPSTASH_VECTOR_REST_URL', credentialData, nodeData)\n            const UPSTASH_VECTOR_REST_TOKEN = getCredentialParam('UPSTASH_VECTOR_REST_TOKEN', credentialData, nodeData)\n\n            const upstashIndex = new UpstashIndex({\n                url: UPSTASH_VECTOR_REST_URL,\n                token: UPSTASH_VECTOR_REST_TOKEN\n            })\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    if (isFileUploadEnabled && options.chatId) {\n                        flattenDocs[i].metadata = { ...flattenDocs[i].metadata, [FLOWISE_CHATID]: options.chatId }\n                    }\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const obj = {\n                index: upstashIndex\n            }\n\n            try {\n                if (recordManager) {\n                    const vectorStore = await UpstashVectorStore.fromExistingIndex(embeddings, obj)\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: UPSTASH_VECTOR_REST_URL\n                        }\n                    })\n\n                    return res\n                } else {\n                    await UpstashVectorStore.fromDocuments(finalDocs, embeddings, obj)\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const UPSTASH_VECTOR_REST_URL = getCredentialParam('UPSTASH_VECTOR_REST_URL', credentialData, nodeData)\n            const UPSTASH_VECTOR_REST_TOKEN = getCredentialParam('UPSTASH_VECTOR_REST_TOKEN', credentialData, nodeData)\n\n            const upstashIndex = new UpstashIndex({\n                url: UPSTASH_VECTOR_REST_URL,\n                token: UPSTASH_VECTOR_REST_TOKEN\n            })\n\n            const obj = {\n                index: upstashIndex\n            }\n\n            const upstashStore = new UpstashVectorStore(embeddings, obj)\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = UPSTASH_VECTOR_REST_URL\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await upstashStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await upstashStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const upstashMetadataFilter = nodeData.inputs?.upstashMetadataFilter\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        const isFileUploadEnabled = nodeData.inputs?.fileUpload as boolean\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const UPSTASH_VECTOR_REST_URL = getCredentialParam('UPSTASH_VECTOR_REST_URL', credentialData, nodeData)\n        const UPSTASH_VECTOR_REST_TOKEN = getCredentialParam('UPSTASH_VECTOR_REST_TOKEN', credentialData, nodeData)\n\n        const upstashIndex = new UpstashIndex({\n            url: UPSTASH_VECTOR_REST_URL,\n            token: UPSTASH_VECTOR_REST_TOKEN\n        })\n\n        const obj: UpstashVectorStoreParams = {\n            index: upstashIndex\n        }\n\n        if (upstashMetadataFilter) {\n            obj.filter = upstashMetadataFilter\n        }\n        if (isFileUploadEnabled && options.chatId) {\n            if (upstashMetadataFilter) obj.filter += ` OR ${FLOWISE_CHATID} = \"${options.chatId}\" OR HAS NOT FIELD ${FLOWISE_CHATID}`\n            else obj.filter = `${FLOWISE_CHATID} = \"${options.chatId}\" OR HAS NOT FIELD ${FLOWISE_CHATID}`\n        }\n\n        const vectorStore = await UpstashVectorStore.fromExistingIndex(embeddings, obj)\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, obj.filter)\n    }\n}"
}

## Vectara_VectorStores

{
  "className": "Vectara_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Vectara'\n        this.name = 'vectara'\n        this.version = 2.0\n        this.type = 'Vectara'\n        this.icon = 'vectara.png'\n        this.category = 'Vector Stores'\n        this.description = 'Upsert embedded data and perform similarity search upon query using Vectara, a LLM-powered search-as-a-service'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            credentialNames: ['vectaraApi']\n        }",
  "for": "for (const file of files) {\n            const splitDataURI = file.split(',')\n            const filename = splitDataURI[splitDataURI.length - 1].split(':')[1]\n            fileNames.push(filename)\n        }",
  "if": "if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (vectaraMetadataFilter) {\n                ;(vectorStore as any).filter = vectaraFilter.filter\n            }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_credentialData": "const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n            const customerId = getCredentialParam('customerID', credentialData, nodeData)\n            const corpusId = getCredentialParam('corpusID', credentialData, nodeData).split(',')\n\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = {} as Embeddings\n            const vectaraMetadataFilter = nodeData.inputs?.filter as string\n            const sentencesBefore = nodeData.inputs?.sentencesBefore as number\n            const sentencesAfter = nodeData.inputs?.sentencesAfter as number\n            const lambda = nodeData.inputs?.lambda as number\n            const fileBase64 = nodeData.inputs?.file\n\n            const vectaraArgs: VectaraLibArgs = {\n                apiKey: apiKey,\n                customerId: customerId,\n                corpusId: corpusId,\n                source: 'flowise'\n            }\n\n            const vectaraFilter: VectaraFilter = {}\n            if (vectaraMetadataFilter) vectaraFilter.filter = vectaraMetadataFilter\n            if (lambda) vectaraFilter.lambda = lambda\n\n            const vectaraContextConfig: VectaraContextConfig = {}\n            if (sentencesBefore) vectaraContextConfig.sentencesBefore = sentencesBefore\n            if (sentencesAfter) vectaraContextConfig.sentencesAfter = sentencesAfter\n            vectaraFilter.contextConfig = vectaraContextConfig\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const vectaraFiles: VectaraFile[] = []\n            let files: string[] = []\n            if (fileBase64.startsWith('FILE-STORAGE::')) {\n                const fileName = fileBase64.replace('FILE-STORAGE::', '')\n                if (fileName.startsWith('[') && fileName.endsWith(']')) {\n                    files = JSON.parse(fileName)\n                } else {\n                    files = [fileName]\n                }\n                const chatflowid = options.chatflowid\n\n                for (const file of files) {\n                    if (!file) continue\n                    const fileData = await getFileFromStorage(file, chatflowid)\n                    const blob = new Blob([fileData])\n                    vectaraFiles.push({ blob: blob, fileName: getFileName(file) })\n                }\n            } else {\n                if (fileBase64.startsWith('[') && fileBase64.endsWith(']')) {\n                    files = JSON.parse(fileBase64)\n                } else {\n                    files = [fileBase64]\n                }\n\n                for (const file of files) {\n                    if (!file) continue\n                    const splitDataURI = file.split(',')\n                    splitDataURI.pop()\n                    const bf = Buffer.from(splitDataURI.pop() || '', 'base64')\n                    const blob = new Blob([bf])\n                    vectaraFiles.push({ blob: blob, fileName: getFileName(file) })\n                }\n            }\n\n            try {\n                if (finalDocs.length) await VectaraStore.fromDocuments(finalDocs, embeddings, vectaraArgs)\n                if (vectaraFiles.length) {\n                    const vectorStore = new VectaraStore(vectaraArgs)\n                    await vectorStore.addFiles(vectaraFiles)\n                }\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n        const customerId = getCredentialParam('customerID', credentialData, nodeData)\n        const corpusId = getCredentialParam('corpusID', credentialData, nodeData).split(',')\n\n        const vectaraMetadataFilter = nodeData.inputs?.filter as string\n        const sentencesBefore = nodeData.inputs?.sentencesBefore as number\n        const sentencesAfter = nodeData.inputs?.sentencesAfter as number\n        const lambda = nodeData.inputs?.lambda as number\n        const output = nodeData.outputs?.output as string\n        const topK = nodeData.inputs?.topK as string\n        const k = topK ? parseFloat(topK) : 5\n        const mmrK = nodeData.inputs?.mmrK as number\n        const mmrDiversityBias = nodeData.inputs?.mmrDiversityBias as number\n\n        const vectaraArgs: VectaraLibArgs = {\n            apiKey: apiKey,\n            customerId: customerId,\n            corpusId: corpusId,\n            source: 'flowise'\n        }\n\n        const vectaraFilter: VectaraFilter = {}\n        if (vectaraMetadataFilter) vectaraFilter.filter = vectaraMetadataFilter\n        if (lambda) vectaraFilter.lambda = lambda\n\n        const vectaraContextConfig: VectaraContextConfig = {}\n        if (sentencesBefore) vectaraContextConfig.sentencesBefore = sentencesBefore\n        if (sentencesAfter) vectaraContextConfig.sentencesAfter = sentencesAfter\n        vectaraFilter.contextConfig = vectaraContextConfig\n        const mmrConfig: MMRConfig = {}\n        mmrConfig.enabled = mmrDiversityBias > 0\n        mmrConfig.mmrTopK = mmrK\n        mmrConfig.diversityBias = mmrDiversityBias\n        vectaraFilter.mmrConfig = mmrConfig\n\n        const vectorStore = new VectaraStore(vectaraArgs)\n\n        if (output === 'retriever') {\n            const retriever = vectorStore.asRetriever(k, vectaraFilter)\n            return retriever\n        } else if (output === 'vectorStore') {\n            ;(vectorStore as any).k = k\n            if (vectaraMetadataFilter) {\n                ;(vectorStore as any).filter = vectaraFilter.filter\n            }\n            return vectorStore\n        }\n        return vectorStore\n    }\n}\n\nconst getFileName = (fileBase64: string) => {\n    let fileNames = []\n    if (fileBase64.startsWith('[') && fileBase64.endsWith(']')) {\n        const files = JSON.parse(fileBase64)\n        for (const file of files) {\n            const splitDataURI = file.split(',')\n            const filename = splitDataURI[splitDataURI.length - 1].split(':')[1]\n            fileNames.push(filename)\n        }\n        return fileNames.join(', ')\n    } else {\n        const splitDataURI = fileBase64.split(',')\n        const filename = splitDataURI[splitDataURI.length - 1].split(':')[1]\n        return filename\n    }\n}"
}

## Weaviate_VectorStores

{
  "className": "Weaviate_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor() {\n        this.label = 'Weaviate'\n        this.name = 'weaviate'\n        this.version = 3.0\n        this.type = 'Weaviate'\n        this.icon = 'weaviate.png'\n        this.category = 'Vector Stores'\n        this.description =\n            'Upsert embedded data and perform similarity or mmr search using Weaviate, a scalable open-source vector database'\n        this.baseClasses = [this.type, 'VectorStoreRetriever', 'BaseRetriever']\n        this.credential = {\n            label: 'Connect Credential',\n            name: 'credential',\n            type: 'credential',\n            description: 'Only needed when using Weaviate cloud hosted',\n            optional: true,\n            credentialNames: ['weaviateApi']\n        }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "if": "if (weaviateFilter) {\n            weaviateFilter = typeof weaviateFilter === 'object' ? weaviateFilter : JSON.parse(weaviateFilter)\n        }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "outsideClass_weaviateScheme": "const weaviateScheme = nodeData.inputs?.weaviateScheme as string\n            const weaviateHost = nodeData.inputs?.weaviateHost as string\n            const weaviateIndex = nodeData.inputs?.weaviateIndex as string\n            const weaviateTextKey = nodeData.inputs?.weaviateTextKey as string\n            const weaviateMetadataKeys = nodeData.inputs?.weaviateMetadataKeys as string\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const weaviateApiKey = getCredentialParam('weaviateApiKey', credentialData, nodeData)\n\n            const clientConfig: any = {\n                scheme: weaviateScheme,\n                host: weaviateHost\n            }\n            if (weaviateApiKey) clientConfig.apiKey = new ApiKey(weaviateApiKey)\n\n            const client: WeaviateClient = weaviate.client(clientConfig)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const obj: WeaviateLibArgs = {\n                //@ts-ignore\n                client,\n                indexName: weaviateIndex\n            }\n\n            if (weaviateTextKey) obj.textKey = weaviateTextKey\n            if (weaviateMetadataKeys) obj.metadataKeys = JSON.parse(weaviateMetadataKeys.replace(/\\s/g, ''))\n\n            try {\n                if (recordManager) {\n                    const vectorStore = (await WeaviateStore.fromExistingIndex(embeddings, obj)) as unknown as VectorStore\n                    await recordManager.createSchema()\n                    const res = await index({\n                        docsSource: finalDocs,\n                        recordManager,\n                        vectorStore,\n                        options: {\n                            cleanup: recordManager?.cleanup,\n                            sourceIdKey: recordManager?.sourceIdKey ?? 'source',\n                            vectorStoreName: weaviateTextKey ? weaviateIndex + '_' + weaviateTextKey : weaviateIndex\n                        }\n                    })\n                    return res\n                } else {\n                    await WeaviateStore.fromDocuments(finalDocs, embeddings, obj)\n                    return { numAdded: finalDocs.length, addedDocs: finalDocs }\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        },\n        async delete(nodeData: INodeData, ids: string[], options: ICommonObject): Promise<void> {\n            const weaviateScheme = nodeData.inputs?.weaviateScheme as string\n            const weaviateHost = nodeData.inputs?.weaviateHost as string\n            const weaviateIndex = nodeData.inputs?.weaviateIndex as string\n            const weaviateTextKey = nodeData.inputs?.weaviateTextKey as string\n            const weaviateMetadataKeys = nodeData.inputs?.weaviateMetadataKeys as string\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n            const recordManager = nodeData.inputs?.recordManager\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const weaviateApiKey = getCredentialParam('weaviateApiKey', credentialData, nodeData)\n\n            const clientConfig: any = {\n                scheme: weaviateScheme,\n                host: weaviateHost\n            }\n            if (weaviateApiKey) clientConfig.apiKey = new ApiKey(weaviateApiKey)\n\n            const client: WeaviateClient = weaviate.client(clientConfig)\n\n            const obj: WeaviateLibArgs = {\n                //@ts-ignore\n                client,\n                indexName: weaviateIndex\n            }\n\n            if (weaviateTextKey) obj.textKey = weaviateTextKey\n            if (weaviateMetadataKeys) obj.metadataKeys = JSON.parse(weaviateMetadataKeys.replace(/\\s/g, ''))\n\n            const weaviateStore = new WeaviateStore(embeddings, obj)\n\n            try {\n                if (recordManager) {\n                    const vectorStoreName = weaviateTextKey ? weaviateIndex + '_' + weaviateTextKey : weaviateIndex\n                    await recordManager.createSchema()\n                    ;(recordManager as any).namespace = (recordManager as any).namespace + '_' + vectorStoreName\n                    const keys: string[] = await recordManager.listKeys({})\n\n                    await weaviateStore.delete({ ids: keys })\n                    await recordManager.deleteKeys(keys)\n                } else {\n                    await weaviateStore.delete({ ids })\n                }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const weaviateScheme = nodeData.inputs?.weaviateScheme as string\n        const weaviateHost = nodeData.inputs?.weaviateHost as string\n        const weaviateIndex = nodeData.inputs?.weaviateIndex as string\n        const weaviateTextKey = nodeData.inputs?.weaviateTextKey as string\n        const weaviateMetadataKeys = nodeData.inputs?.weaviateMetadataKeys as string\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n        let weaviateFilter = nodeData.inputs?.weaviateFilter\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const weaviateApiKey = getCredentialParam('weaviateApiKey', credentialData, nodeData)\n\n        const clientConfig: any = {\n            scheme: weaviateScheme,\n            host: weaviateHost\n        }\n        if (weaviateApiKey) clientConfig.apiKey = new ApiKey(weaviateApiKey)\n\n        const client: WeaviateClient = weaviate.client(clientConfig)\n\n        const obj: WeaviateLibArgs = {\n            //@ts-ignore\n            client,\n            indexName: weaviateIndex\n        }\n\n        if (weaviateTextKey) obj.textKey = weaviateTextKey\n        if (weaviateMetadataKeys) obj.metadataKeys = JSON.parse(weaviateMetadataKeys.replace(/\\s/g, ''))\n        if (weaviateFilter) {\n            weaviateFilter = typeof weaviateFilter === 'object' ? weaviateFilter : JSON.parse(weaviateFilter)\n        }\n\n        const vectorStore = (await WeaviateStore.fromExistingIndex(embeddings, obj)) as unknown as VectorStore\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, weaviateFilter)\n    }\n}"
}

## Zep_VectorStores

{
  "className": "Zep_VectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor(embeddings: Embeddings, args: IZepConfig & Partial<ZepFilter>) {\n        super(embeddings, args)\n        this.filter = args.filter\n        this.args = args\n    }",
  "for": "for (const filterKey in _filters) {\n            let filterVal = _filters[filterKey]\n            if (typeof filterVal === 'string') filterVal = `\"${filterVal}",
  "catch": "catch (err) {\n            if (err instanceof Error) {\n                if (err.name === 'NotFoundError') {\n                    await this.createNewCollection(args)\n                }",
  "if": "if (filter && this.filter) {\n            throw new Error('cannot provide both `filter` and `this.filter`')\n        }",
  "initializeCollection": "initializeCollection(args: IZepConfig & Partial<ZepFilter>) {\n        this.client = await ZepClient.init(args.apiUrl, args.apiKey)\n        try {\n            this.collection = await this.client.document.getCollection(args.collectionName)\n        }",
  "createNewCollection": "createNewCollection(args: IZepConfig & Partial<ZepFilter>) {\n        if (!args.embeddingDimensions) {\n            throw new Error(\n                `Collection ${args.collectionName}",
  "outsideClass_baseURL": "const baseURL = nodeData.inputs?.baseURL as string\n            const zepCollection = nodeData.inputs?.zepCollection as string\n            const dimension = (nodeData.inputs?.dimension as number) ?? 1536\n            const docs = nodeData.inputs?.document as Document[]\n            const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n\n            const zepConfig: IZepConfig = {\n                apiUrl: baseURL,\n                collectionName: zepCollection,\n                embeddingDimensions: dimension,\n                isAutoEmbedded: false\n            }\n            if (apiKey) zepConfig.apiKey = apiKey\n\n            try {\n                await ZepVectorStore.fromDocuments(finalDocs, embeddings, zepConfig)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const baseURL = nodeData.inputs?.baseURL as string\n        const zepCollection = nodeData.inputs?.zepCollection as string\n        const zepMetadataFilter = nodeData.inputs?.zepMetadataFilter\n        const dimension = nodeData.inputs?.dimension as number\n        const embeddings = nodeData.inputs?.embeddings as Embeddings\n\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n\n        const zepConfig: IZepConfig & Partial<ZepFilter> = {\n            apiUrl: baseURL,\n            collectionName: zepCollection,\n            embeddingDimensions: dimension,\n            isAutoEmbedded: false\n        }\n        if (apiKey) zepConfig.apiKey = apiKey\n        if (zepMetadataFilter) {\n            const metadatafilter = typeof zepMetadataFilter === 'object' ? zepMetadataFilter : JSON.parse(zepMetadataFilter)\n            zepConfig.filter = metadatafilter\n        }\n\n        const vectorStore = await ZepExistingVS.fromExistingIndex(embeddings, zepConfig)\n\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, zepConfig.filter)\n    }\n}\n\ninterface ZepFilter {\n    filter: Record<string, any>\n}\n\nfunction zepDocsToDocumentsAndScore(results: IDocument[]): [Document, number][] {\n    return results.map((d) => [\n        new Document({\n            pageContent: d.content,\n            metadata: d.metadata\n        }),\n        d.score ? d.score : 0\n    ])\n}\n\nfunction assignMetadata(value: string | Record<string, unknown> | object | undefined): Record<string, unknown> | undefined {\n    if (typeof value === 'object' && value !== null) {\n        return value as Record<string, unknown>\n    }\n    if (value !== undefined) {\n        console.warn('Metadata filters must be an object, Record, or undefined.')\n    }\n    return undefined\n}",
  "outsideClass__filters": "const _filters = filter ?? this.filter\n        const ANDFilters = []\n        for (const filterKey in _filters) {\n            let filterVal = _filters[filterKey]\n            if (typeof filterVal === 'string') filterVal = `\"${filterVal}\"`\n            ANDFilters.push({ jsonpath: `$[*] ? (@.${filterKey} == ${filterVal})` })\n        }\n        const newfilter = {\n            where: { and: ANDFilters }\n        }\n        await this.initializeCollection(this.args!).catch((err) => {\n            console.error('Error initializing collection:', err)\n            throw err\n        })\n        const results = await this.collection.search(\n            {\n                embedding: new Float32Array(query),\n                metadata: assignMetadata(newfilter)\n            },\n            k\n        )\n        return zepDocsToDocumentsAndScore(results)\n    }\n\n    static async fromExistingIndex(embeddings: Embeddings, dbConfig: IZepConfig & Partial<ZepFilter>): Promise<ZepVectorStore> {\n        const instance = new this(embeddings, dbConfig)\n        return instance\n    }\n}"
}

## Zep_CloudVectorStores

{
  "className": "Zep_CloudVectorStores",
  "vectorStoreMethods": {},
  "init": "[Function: init]",
  "constructor": "constructor(embeddings: Embeddings, args: IZepConfig & Partial<ZepFilter>) {\n        super(embeddings, args)\n        this.filter = args.filter\n        this.args = args\n    }",
  "for": "for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }",
  "catch": "catch (e) {\n                throw new Error(e)\n            }",
  "if": "if (zepMetadataFilter) {\n            zepConfig.filter = typeof zepMetadataFilter === 'object' ? zepMetadataFilter : JSON.parse(zepMetadataFilter)\n        }",
  "outsideClass_zepCollection": "const zepCollection = nodeData.inputs?.zepCollection as string\n            const docs = nodeData.inputs?.document as Document[]\n            const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n            const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n            const flattenDocs = docs && docs.length ? flatten(docs) : []\n            const finalDocs = []\n            for (let i = 0; i < flattenDocs.length; i += 1) {\n                if (flattenDocs[i] && flattenDocs[i].pageContent) {\n                    finalDocs.push(new Document(flattenDocs[i]))\n                }\n            }\n            const client = new ZepClient({\n                apiKey: apiKey\n            })\n            const zepConfig = {\n                apiKey: apiKey,\n                collectionName: zepCollection,\n                client\n            }\n            try {\n                await ZepVectorStore.fromDocuments(finalDocs, new FakeEmbeddings(), zepConfig)\n                return { numAdded: finalDocs.length, addedDocs: finalDocs }\n            } catch (e) {\n                throw new Error(e)\n            }\n        }\n    }\n\n    async init(nodeData: INodeData, _: string, options: ICommonObject): Promise<any> {\n        const zepCollection = nodeData.inputs?.zepCollection as string\n        const zepMetadataFilter = nodeData.inputs?.zepMetadataFilter\n        const credentialData = await getCredentialData(nodeData.credential ?? '', options)\n        const apiKey = getCredentialParam('apiKey', credentialData, nodeData)\n\n        const zepConfig: IZepConfig & Partial<ZepFilter> = {\n            apiKey,\n            collectionName: zepCollection\n        }\n        if (zepMetadataFilter) {\n            zepConfig.filter = typeof zepMetadataFilter === 'object' ? zepMetadataFilter : JSON.parse(zepMetadataFilter)\n        }\n        zepConfig.client = new ZepClient({\n            apiKey: apiKey\n        })\n        const vectorStore = await ZepExistingVS.init(zepConfig)\n        return resolveVectorStoreOrRetriever(nodeData, vectorStore, zepConfig.filter)\n    }\n}\n\ninterface ZepFilter {\n    filter: Record<string, any>\n}"
}
